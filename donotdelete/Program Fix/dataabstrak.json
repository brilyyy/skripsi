[
    [
        "Identifikasi Ruang Terbuka Hijau Daerah Surakarta Dengan Metode Otsu Melalui Citra Satelit",
        "Menghadapi pemanasan global dan perubahan iklim serta berkurangnya ruang terbuka hijau di Indonesia, pemerintah mengeluarkan peraturan dalam bentuk Undang-undang, Peraturan Menteri, dan Peraturan Daerah serta peraturan yang lainnya untuk mengatur akan keberadaan dan keberlangsungan Ruang Terbuka Hijau (RTH) di Indonesia. Salah satu upaya untuk mengetahui kondisi suatu wilayah adalah memanfaatkan citra dari satelit. Tujuan dari penelitian ini adalah mengidentifikasi RTH Kota Surakarta dengan menerapkan metode Otsu terhadap citra yang didapat dari satelit. Dalam prosesnya citra tersebut terlebih dahulu akan dilakukan filterisasi menggunakan Linear Filter dan dilakukan proses grayscaling sebelum diterapkan metode Otsu. Dari penerapan metode Otsu untuk mencari RTH Kota Surakarta melalui citra satelit\u00a0 didapatkan hasil berupa selisih antara nilai rata-rata total RTH asli dengan RTH Otsu dan RTH Otsu dengan filter yaitu 32.79% untuk Otsu dengan RTH asli, 36.49% untuk Otsu ditambah filter Laplacian dengan RTH asli, 24.94% untuk Otsu ditambah filter Mean dengan RTH asli dan 26.81% untuk Otsu ditambah filter Gaussian dengan RTH asli. Hasil proses dengan selisih terendah yaitu 1.44?n selisih tertinggi yaitu 63.87%.Kata Kunci: Ruang Terbuka Hijau, Linear Filter, Grayscaling, Otsu, Surakarta\u00a0",
        "0"
    ],
    [
        "Ontology - Based Reasoning Berdasarkan Holland Codes  Untuk Pendukung Keputusan Pemilihan Bidang Studi",
        "Pemilihan pendidikan merupakan hal yang cukup serius untuk menentukan masa depan suatu individu terutama pada pemilihan bidang studi pada masa perkuliahan. Individu akan berkembang dengan maksimal apabila berada dilingkungan yang tepat, sehingga dapat memaksimalkan seluruh potensi. Pemilihan bidang studi untuk calon mahasiswa seharusnya mempertimbangkan faktor utama dari potensi diri yaitu minat dan bakat.\u00a0 Dampak kesesuaian lingkungan\u00a0 pendidikan\u00a0 dengan\u00a0 minat\u00a0 dan\u00a0 bakat\u00a0 dari\u00a0 individu\u00a0 yaitu\u00a0 pada motivasi\u00a0 belajar, pengembangan potensi, dan pencapaian akademik. Penelitian ini membangun sebuah Sistem Pendukung Keputusan dengan pendekatan Tes Minat Bakat berdasarkan Holland Codes untuk membantu calon mahasiswa menemukan bidang studi yang sesuai dengan minat dan bakat. Penelitian ini menggunakan metode Ontology Based Reasoning. Pembangunan Ontology Based Reasoning menggunakan pendekatan SABiO yang telah disesuaikan dengan kebutuhan sistem. Tujuan lain adalah untuk pemanfaatan ontology sebagai representasi domain pengetahuan pada teknologi semantik sehingga dapat digunakan kembali dan digunakan bersama. Hasil dari penelitian ini menunjukkan\u00a0 bahwa pembangunan\u00a0 Ontology Based\u00a0 Reasoning dalam Sistem Pendukung Keputusan Pemilihan Bidang Studi dengan Pendekatan Holland Codes memberikan rekomendasi yang sesuai dengan minat bakat calon mahasiswa pada tingkat akurasi rekomendasi Diterima (86%) dan Ditolak (14%) dengan rata - rata nilai confidence 65,60%.Kata Kunci : Holland Codes, Ontology, Ontology Based Reasoning, SABiO, Sistem Pendukung Keputusan.",
        "1"
    ],
    [
        "Rekomendasi Makanan Bagi Pasien Hiperlipidiemia Berdasarkan Hasil Klasifikasi Menggunakan Metode Naive Bayes dan Decision Tree",
        "Makanan merupakan kebutuhan manusia untuk memenuhi nutrisi dalam keberlangsungan hidup. Namun setiap orang perlu memperhatikan makanan yang dikonsumsi karena akan memengaruhi kondisi tubuh. Salah satu zat dalam tubuh manusia yang perlu diperhatikan ketika mengonsumsi makanan adalah lemak. Penelitian terkait hubungan konsumsi makanan dengan kadar lemak dalam tubuh sudah banyak dilakukan. Terbukti terdapat jenis makanan yang dapat memengaruhi kesehatan tubuh karena menyebabkan zat lemak yang berlebihan. Penelitian yang dilakukan kali ini adalah klasifikasi data kebutuhan gizi dengan membandingkan algoritma na\u00efve bayes dan decision tree di mana hasil klasifikasi di antara kedua algoritma tersebut akan digunakan untuk memberikan rekomendasi makanan yang sesuai untuk dikonsumsi oleh orang yang menderita hiperlipidemia, yakni kondisi di mana kadar lemak dalam tubuh berlebihan. Penelitian dimulai dari pengumpulan data, pra-proses data dengan normalisasi, klasifikasi dengan beberapa model na\u00efve bayes dan algoritma decision tree, menganalisis hasil klasifikasi dengan confusion matrix, dan melakukan implementasi rekomendasi makanan berdasarkan hasil model klasifikasi yang paling optimal. Didapatkan hasil bahwa model ComplementNB memiliki akurasi tinggi dibanding model lain namun secara keseluruhan algoritma decision tree lebih stabil dibanding na\u00efve bayes.Kata kunci \u2013 Decision Tree, Hiperlipidemia, Klasifikasi, Kolesterol, Na\u00efve Bayes, Rekomendasi Makanan.\u00a0",
        "2"
    ],
    [
        "Integrasi Knowledge Graph dari Data Terstruktur, Photo, dan File dengan Metode Wu Palmer Similarity dan Direct Mapping",
        "Seiring dengan banyaknya implementasi dari knowledge graph dengan penggunaan data yang besar dari berbagai sumber dan jenis data, maka integrasi data tersebut menjadi tantangan utama dalam pengembangannya. Beberapa penelitian yang telah melakukan mapping berbagai data ke dalam knowledge graph, belum melakukan integrasi data tersebut pada level konteks. Dengan demikian, pada penelitian ini dirancang algoritma yang secara otomatis mengintegrasikan berbagai jenis data menjadi knowledge graph. Proses integrasi dilakukan dengan tahap matching data menggunakan metode Wu Palmer Similarity yang memanfaatkan descriptive metadata pada setiap file data. Data yang berhasil di-matching kemudian di-mapping ke dalam format knowledge graph dengan metode Direct Mapping. Pada integrasi data relational database, file pdf, dan photo, proses matching diperoleh akurasi sebesar 58,23% untuk matching atribut dan property. Hasil akurasi menunjukkan jumlah property dan atribut yang memiliki keterkaitan dengan ontology. Nilai akurasi yang rendah tersebut dikarenakan belum dapat memilih synset WordNet secara tepat sesuai dengan term yang di-matching. Selain itu, juga dikarenakan tidak adanya padanan kata yang tepat dalam ontology DBpedia yang digunakan. Akurasi sebesar 97,74% untuk matching data RDB terhadap instances DBpedia. Akurasi sebesar 16,79% untuk matching descriptive metadata terhadap data RDB. Artinya, sebesar 16,79?ta RDB memiliki keterkaitan dengan data descriptive metadata. Hasil tersebut dikarenakan keterbatasan informasi pada descriptive metadata yang diambil. Namun demikian, algoritma yang dibuat dapat menghasilkan knowledge graph yang valid dari integrasi berbagai jenis data.",
        "3"
    ],
    [
        "Penerapan Deep Learning pada Kasus Sistem Penilaian Esai Otomatis Bahasa Indonesia",
        "Esai adalah salah satu jenis ujian untuk menilai kemampuan hasil belajar siswa. Tetapi hambatan terbesar pengerjaan esai adalah menilai jawaban esai itu sendiri, karena membutuhkan waktu dan tenaga yang cukup besar untuk memeriksa satu persatu setiap jawaban dari siswa yang tidak sedikit jumlahnya. Penelitian ini mecoba membuat sistem penilaian esai otomatis Bahasa Indonesia menggunakan 2 layer long short term memory (LSTM) yang dilatih menggunakan dataset yang sudah dibersihkan dan dilatih dengan algoritma Word2Vec. Dataset yang digunakan pada penelitian ini terdiri dari 3,561 soal esai Bahasa Indonesia yang didapat dari kompetisi Automated essay scoring di Kaggle dan diterjemahkan menggunakan Google terjemahan. Hasil penelitian ini diukur menggunakan Quadratic Weighted Kappa (QWK) dengan nilai tertinggi yang didapat mecapai 0.9174 kappa. Hasil penelitian ini menunjukkan pendekatan baru untuk menyelesaikan permasalahan penilaian esai otomatis dalam Bahasa Indonesia jika melihat belum ada penelitian sebelumnya yang menggunakan deep learning.",
        "4"
    ],
    [
        "Rekonstruksi Citra Berderajat Keabuan-Tersisipi-Warna Menggunakan Convolutional Vision Transformer",
        "Citra berderajat keabuan-tersisipi-warna atau yang biasa disebut color-embedded-grayscale image merupakan salah satu permasalahan ill-posed inverse imaging. Kualitas dari citra berwarna keabuan-tersisipi-warna yang dipulihkan seringkali kurang memuaskan karena distorsi warna dan juga adanya checkerboard artifacts. Penelitian ini mengusulkan pendekatan yang berbasis Feature Engaging Convolution Vision Transformer (CVT) dengan menyisipkan Multi-Branch Residual Module (MBRM) untuk merekonstruksi citra berderajat keabuan-tersisipi-warna. Hasil penelitian ini diukur menggunakan Peak Signal to Noise Ratio (PSNR) dan Structural Similarity Index (SSIM). Pada penelitian ini training dan testing dilakukan dengan dataset DIV2K dan dataset Kodak dengan nilai rata-rata PSNR 30.43 dB dan SSIM 0.8373. Hasil dari penelitian ini menunjukkan bahwa metode yang diusulkan memberikan hasil yang paling baik dibandingkan metode Deep Convolutional Network.Kata Kunci: Color-Embedded-Grayscale, Deep Learning, Feature Engaging Convolutional Vision Transformer, Ill-posed Inverse Imaging, Multi-Branch Residual Module",
        "5"
    ],
    [
        "Sistem Pendukung Keputusan Seleksi Beasiswa Kartu Indonesia Pintar (KIP) Menggunakan Metode AHP dan VIKOR",
        "Beasiswa Kartu Indonesia Pintar (KIP) adalah bantuan pendidikan dari pemerintah kepada mahasiswa yang merupakan program lanjutan beasiswa Bidikmisi. Pendaftar Bidikmisi Universitas Sebelas Maret Surakarta (UNS) pada tahun ajaran 2018/2019 tercatat sebanyak kurang lebih 2.000 pendaftar, sedangkan kuota penerima kurang dari 1.000 mahasiswa. Proses seleksi penerimaan beasiswa KIP UNS saat ini menggunakan metode pembobotan kriteria, tetapi belum adanya proses pengecekan konsistensi. Pengecekan konsistensi ini penting dilakukan guna menghindari masalah subjektivitas. Selain itu, proses seleksi penerimaan beasiswa KIP dilakukan menggunakan software Microsoft Excel mengakibatkan aksesibilitas dan availability data yang terbatas oleh pihak yang melakukan seleksi. Salah satu penyelesaian permasalahan tersebut adalah membuat sistem pendukung keputusan untuk memberikan rekomendasi penerima beasiswa KIP di Universitas Sebelas Maret. Metode penelitian yang digunakan pada penelitian ini adalah kombinasi metode AHP dan metode VIKOR untuk memberikan hasil rekomendasi penerima beasiswa KIP. Tahapan yang dilakukan pada penelitian ini meliputi pengumpulan dataset, preprocessing dataset, implementasi sistem, dan pengolahan dataset dengan menggunakan metode AHP dan VIKOR. Perhitungan dengan\u00a0 metode AHP menghasilkan pembobotan kriteria yang digunakan dalam seleksi penerima beasiswa KIP telah konsisten dengan nilai rasio konsistensi yang dihasilkan sebesar 0.0746. Kemudian perhitungan dengan metode VIKOR menghasilkan perangkingan calon penerima beasiswa KIP, yang kemudian dilakukan pengujian mengunakan metode confusion matrix. Hasil pengujian yang dilakukan menggunakan metode confusion matrix dapat menghasilkan nilai accuracy sebesar 87?n nilai error rate didapatkan nilai 13%. Berdasarkan kesesuaian tersebut, menunjukkan bahwa metode AHP dan VIKOR dapat digunakan sebagai solusi pendukung keputusan penerima beasiswa KIP.Kata kunci: KIP, AHP, VIKOR, Confusion Matrix\u00a0",
        "6"
    ],
    [
        "PENERAPAN METODE RANDOM FOREST PADA KLASIFIKASI STUDENT ACADEMICS PERFORMANCE DI UNIVERSITAS SEBELAS MARET",
        "Beberapa mahasiswa memiliki tingkat performa akademik rendah yang dapat mengakibatkan mahasiswa tersebut untuk mengalami drop out. Berbagai faktor memengaruhi tingkat performa akademik mahasiswa tersebut. Penelitian ini bertujuan untuk melakukan klasifikasi performa akademik mahasiswa di Universitas Sebelas Maret berdasarkan tiga kategori faktor yaitu faktor sosial, ekonomi, dan akademik\u00a0ke dalam 3 kategori hasil sangat baik, baik, dan kurang, dengan menggunakan seleksi fitur Information Gain\u00a0dan metode klasifikasi Random Forest. Metode seleksi fitur digunakan untuk mengeliminasi faktor yang dianggap kurang relevan, yang kemudian dilanjutkan dengan proses klasifikasi menggunakan Random Forest\u00a0dengan metode evaluasi model k-folds cross validation. Tingkat Akurasi \u00a0Random Forest setelah penerapan seleksi fitur Information Gain meningkat sebanyak 0,4% serta 1,8% yaitu menjadi 90,8?n 90,7% \u00a0untuk masing-masing nilai k=5 dan nilai k=10.",
        "7"
    ],
    [
        "Penerapan Metode Naive Bayes Classifier Dengan Laplacian Correction Untuk Analisis Sentimen Terhadap Stasiun Televisi Nasional",
        "Televisi merupakan salah satu media informasi yang sudah umum di kalangan masyarakat saat ini. Masyarakat dapat dengan mudah mendapatkan beragam informasi dan hiburan yang disajikan oleh stasiun televisi melalui berbagai acara televisi yang dapat dikonsumsi oleh anak-anak, remaja, maupun dewasa. Pada penelitian kali ini, dilakukan analisis sentimen masyarakat terhadap beberapa stasiun televisi nasional yaitu MetroTV, NET., RCTI, SCTV, dan tvOne. Analisis dilakukan pada sentimen masyarakat yang datanya diambil dari twitter. Penelitian dilakukan dengan menerapkan metode Na\u00efve Bayes Classifier dengan Laplacian Correction untuk mengetahui pengaruh penggunaan Laplacian Correction. Laplacian Correction merupakan salah satu teknik smoothing dengan menambahkan nilai 1 (satu) dalam perhitungan probabilitas sehingga hasil probabilitas tidak sama dengan 0 (nol). Hasil analisis kemudian dihitung nilai accuracy, precision, dan recall untuk mengetahui perbandingan penggunaan metode Na\u00efve Bayes Classifier dengan Laplacian Correction dan tanpa Laplacian Correction. Hasil yang didapat menunjukkan bahwa nilai akurasi untuk metode Na\u00efve Bayes Classifier dengan Laplacian Correction lebih tinggi yaitu sebesar 0.7075223766901543 dibandingkan dengan tanpa Laplacian Correction yang memiliki nilai akurasi sebesar 0.5358630102202755.Kata kunci: Analisis Sentimen, Laplacian Correction, Na\u00efve Bayes Classifier, Stasiun Televisi\u00a0",
        "8"
    ],
    [
        "Prototype Sistem Parkir Berbasis Internet of Things (IoT)",
        "Pertumbuhan populasi manusia berjalan seiring dengan adanya perkembangan teknologi, tidak terkecuali dalam bidang transportasi. Peningkatan jumlah kendaraaan ini menyebabkan lahan parkir sekarang menjadi kebutuhan bagi setiap pemilik kendaraan. Permasalahan yang ada yaitu jumlah lahan yang terkadang tidak mencukupi untuk kendaraan yang hendak parkir di tempat tersebut. Selain itu, masalah lain yang ditimbulkan adalah saat pencarian tempat parkir, akan menyebabkan antrian panjang dan kemacetan lalu lintas.Pada tugas akhir ini dibuat smart parking system yang berbasis Internet of Things (IoT) untuk menyelesaikan permasalahan di atas. Sistem ini bertujuan untuk memudahkan pengguna dalam mencari slot parkir yang terdekat dari pintu masuk sebuah bangunan. Pada tugas akhir ini, digunakan sensor jarak ultrasonik untuk mengukur jarak ground clearance kendaraan yang ada di slot parkir, yang kemudian akan digunakan untuk mendeteksi apakah ada atau tidak sebuah kendaraan dalam sebuah slot parkir. Metode blackbox testing dan performance testing digunakan untuk pengujian sistem dalam tugas akhir ini.Hasil dari sistem ini dapat menampilkan hasil slot parkir tersedia yang diurutkan dari yang terdekat dari pintu masuk bangunan. Sementara itu, untuk hasil performance testing menunjukkan bahwa jumlah slot parkir maksimum yang dapat ditampung oleh sistem berjumlah 2100 dengan presentase threshold sebesar 4,76?n waktu akses 700 ms, sedangkan jumlah pintu masuk parkir maksimum yang dapat ditampung oleh sistem berjumlah 10 dengan presentase threshold sebesar 5?n waktu akses 1500 ms.Kata kunci: sistem parkir, sensor jarak ultrasonik\u00a0",
        "9"
    ],
    [
        "Analisis Sentimen Masyarakat Terhadap Operator Seluler Menggunakan Metode Support Vector Machine",
        "Saat ini masyarakat cenderung menggunakan media sosial untuk mengungkapkan segala sesuatu termasuk memberikan opini terhadap suatu produk, salah satunya Twitter. Provider telekomunikasi menjadi salah satu yang juga membuat akun resmi untuk berinteraksi serta mengetahui tanggapan mengenai produk yang disediakan. Penelitian ini bertujuan untuk melakukan klasifikasi tweet opini masyarakat terhadap 3 provider telekomunikasi besar di Indonesia, yaitu Indosat, Telkomsel, dan XL dengan menggunakan metode Support Vector Machine atau SVM pada media sosial Twitter. Metode Support Vector Machine yang digunakan adalah SVM Multiclass dengan teknik One-vs- One kernel RBF. Melalui pengujian dalam penelitian ini dapat diketahui bahwa tahapan preprocessing berpengaruh pada proses klasifikasi, sehingga klasifikasi dilakukan dengan melalui semua tahap preprocessing. Didapatkan hasil akurasi sebesar 0.92832 untuk provider Indosat, 0.95770 untuk provider Telkomsel, dan 0.94444 untuk provider XL. Dan dari hasil evaluasi dapat dianalisa bahwa sistem dapat mengklasifikasi kelas negatif dengan baik untuk semua provider. Dan sebaliknya untuk kelas yang paling susah diprediksi oleh sistem adalah kelas netral. Dari data hasil klasifikasi, diperoleh beberapa kata yang paling berkontribusi di setiap kelas, sehingga dapat diketahui apa yang banyak dikeluhkan dan banyak membuat masyarakat puas terhadap ketiga provider.Kata kunci:\u00a0\u00a0 Analisis\u00a0\u00a0 Sentimen,\u00a0\u00a0 Preprocessing,\u00a0\u00a0 Provider\u00a0\u00a0 Telekomunikasi,Support Vector Machine\u00a0",
        "10"
    ],
    [
        "Penerapan Gamifikasi pada Prototipe E-Learning ",
        "Sistem e-learning yang digunakan pada universitas di Indonesia kebanyakan menggunakan Sistem Pembelajaran Daring (SPADA) tak terkecuali pada Universitas Sebelas Maret Surakarta (UNS). E-learning yang kebanyakan dipakai memang sudah membantu perkuliahan, namun berdasarkan penelitian sebelumnya, sistem e-learning masih ada kekurangan terutama dalam motivasi mahasiswa untuk menggunakan SPADA UNS. Sehingga diperlukan sebuah pembaharuan pada sistem e-learning. Penelitian dimulai dari analisis kebutuhan, tahap rancangan gamifikasi, tahap produksi gamifikasi e-learning dan yang terakhir adalah tahap validasi akhir. Didapatkan hasil bahwa gamifikasi dapat diimplementasikan pada e-learning. Memasukan unsur gamifikasi kepada e-learning diantaranya poin, reward, leaderboard, dan badge. Hasil unit testing menunjukan sistem telah sesuai dengan yang dirancang. Kemudian hasil validasi akhir kepada responden yang menyatakan bahwa konsep prototipe gamifikasi e-learning lebih disukai dibandingan dengan konsep pada SPADA UNS.Kata kunci \u2013 E-learning, Gamifikasi, Kriteria Mahasiswa, Motivasi Mahasiswa, Performa Mahasiswa, SPADA\u00a0",
        "11"
    ],
    [
        "Klasifikasi Keluhan Pengguna Shopee Menggunakan Metode Support Vector Machine dan Particle Swarm Optimization",
        "Penanganan keluhan merupakan salah satu hal yang paling penting dalam sebuah perusahaan. Shopee dengan official akunnya, @shopeecare khusus digunakan untuk menangani keluhan secara langsung dengan pengguna melalui Twitter. Karena ketidakterbatasan dari Twitter ini, pengguna bisa mengungkapkan semua kepada Shopee dan membuat struktur data yang tidak beraturan yang menghambat penanganan keluhan. Maka dari itu, dibutuhkan metode untuk mengelompokkan data menjadi beberapa kategori seperti aplikasi, pembatalan dan pengembalian, pencairan, pembayaran, pengiriman, voucher dan promosi, serta shopeepay. Metode yang digunakan dalam penelitian ini adalah ekstrasi fitur menggunakan Term Frequency\u2013Inverse Document Frequency (TF-IDF)\u00a0 dan klasifikasi dengan menggunakan Support Vector Machine serta Particle Swarm Optimization. Penelitian yang dilakukan menghasilkan akurasi sebesar 82,05% untuk SVM dan 82,56% untuk kombinasi SVM-PSO dengan menggunakan split 0.2. Nilai Precision, Recall dan f1-score untuk SVM-PSO adalah 83%, 84%, dan 84%. Dari hasil tersebut, dapat disimpulkan bahwa PSO dapat meningkatkan akurasi dari SVM.Kata kunci: keluhan, klasifikasi, Particle Swarm Optimization, Support Vector Machine, Twitter\u00a0",
        "12"
    ],
    [
        "Prediksi Kepribadian Dark Triad Personality Traits Melalui Analisis Twitter Menggunakan Metode Support Vector Machine",
        "Kepribadian adalah kombinasi dari karakteristik dan perilaku seseorang dalam kondisi tertentu. Ada beberapa model kepribadian yang dapat digunakan untuk memprediksi kecenderungan kepribadian, salah satunya adalah kepribadian yang memiliki sisi gelap atau substansi negatif yang disebut dengan Dark Triad personality. Kepribadian ini terbagi menjadi 3 sifat yaitu Machiavellianism (sifat manipulatif), Narcissism (narsistik), and Psychopath (antisosial).Dalam penelitian kali ini akan dilakukan klasifikasi Dark Triad personality dengan menggunakan data dari kuesioner Dirty Dozen dan data dari Twitter. Kuesioner Dirty Dozen akan dibagikan secara umum menggunakan Google Form, dimana hasilnya akan digunakan sebagai label awal dari kepribadian Dark Triad. Sedangkan data Twitter akan diambil (crawl) menggunakan API Twitter dengan RStudio. Hasil klasifikasi dari data Twitter akan dibandingkan dengan label awal dari hasi kuesioner.Klasifikasi dilakukan dengan menggunakan Metode Support Vector Machine sesuai dengan kelompok kata yang didapatkan dari hasil pemrosesan data training, sedangkan data testing digunakan sebagai proses pengujian.Dari hasil penelitian didapatkan klasifikasi dengan akurasi tertinggi sebesar 73,3% yang diperoleh dari hasil skenario 2 yaitu perbandingan data training dan data testing sebesar 80:20. Dengan menggunakan Metode Suppoert Vector Machine, penelitian ini dapat menghasilkan klasifikasi yang cukup baik dalam memprediksi adanya kecenderungan kepribadian Dark Triad melalui analisis Twitter.Kata kunci: Dark Triad Personality, Support Vector Machine, Twitter\u00a0",
        "13"
    ],
    [
        "Sistem Pendukung Keputusan Pemilihan Mata Kuliah Pilihan Dengan Metode AHP DAN Promethee (Studi Kasus : Program Studi Informatika Universitas Sebelas Maret)",
        "Pemilihan mata kuliah pilihan sering kali menjadi hal yang sulit bagi mahasiswa. Telah dilakukan survei awal terhadap 18 mahasiswa Program Studi Informatika UNS Angkatan 2015 \u2013 2018. Hasil survei menunjukkan 88,9% mahasiswa membutuhkan sistem yang dapat membantu dalam pemilihan mata kuliah pilihan. Sistem pendukung keputusan pada penelitian ini menghasilkan urutan rekomendasi mata kuliah pilihan sesuai dengan inputan mahasiswa. Pada penelitian ini digunakan kombinasi metode AHP dan PROMETHEE. Metode AHP digunakan dalam pembobotan kriteria yang kemudian dipakai pada pemeringkatan dengan metode PROMETHEE. Dilakukan pemeringkatan mata kuliah pilihan secara parsial menggunakan PROMETHEE I dan pemeringkatan alternatif mata kuliah pilihan secara lengkap dengan metode PROMETHEE II. Berdasarkan pengujian akurasi, hasilnya pemeringkatan dengan menggunakan metode AHP dan PROMETHEE I (skenario 1) adalah sebesar 67.4%, sedangkan pemeringkatan dengan AHP dan PROMETHEE II (skenario 2) menghasilkan akurasi 60.4%.Kata Kunci: AHP, Mata Kuliah Pilihan, PROMETHEE, Sistem Pendukung Keputusan\u00a0",
        "14"
    ],
    [
        "Peningkatan Kualitas Citra Hasil Companding Menggunakan Deep Learning dan  Stationary Wavelet Transform",
        "Image Companding merupakan salah satu teknik untuk meningkatkan kualitas citra terkompresi yang sangat bermanfaat dalam situasi bandwidth terbatas. Pada saat citra dikenai companding, Beberapa informasi yang hilang selama proses ekstraksi citra terkompresi. Untuk mengatasi hal tersebut, diusulkan sebuah arsitektur neural network yang terdiri dari dua network, Subband Network (Subband) dan Pixel Network (PixNet). SubNet memanfaatkan efektivitas dari Stationary Wavelet Transform (SWT) dan Convolutional Neural Network (CNN) untuk memulihkan informasi yang hilang pada basis subband wavelet. sedangkan bagian PixNet menerapkan CNN dengan identity mapping untuk meningkatkan kualitas citra rekonstruksi awal yang diperoleh dari SubNet. Metode yang diusulkan memiliki hasil yang lebih baik dibandingkan metode image companding sebelumnya. Metode yang diusulkan meningkatkan kualitas citra yang direkonstruksi dalam beberapa langkah sederhana yang dapat dibuktikan dengan rata - rata nilai PSNR dan SSIM yaitu 35.11 dan 0.926. Lebih baik dibandingkan hasil terbaik metode sebelumnya yang memiliki nilai 32.53 dan 0.882.",
        "15"
    ],
    [
        "Analisis Sentimen pada Komentar Youtube Mengenai Vaksin Covid - 19 dengan Menggunakan Metode Support Vector Machine",
        "Youtube is one of the media social platforms that are the most used in 2021. Social Media is not only for uploading entertainment videos but source information. With covid - 19 pandemic, this platform gives us much information about the pandemic, new variant information, and some vaccines that are distributed to the public. Responses about vaccines are very diverse from the public, from positif to negatif responses which are commonly referred to as sentiments. However, to know the contents of the response, an analysis is needed to understand the sentiment better. This study aims to determine the performance of the Support Vector Machine algorithm in classifying based on comments from the Indonesian people. The data source is taken from the Youtube site by utilizing the existing comment feature. The model test was carried out using the python library, namely SVC. Three scenarios were carried out on the test data, namely the distribution of training data and test data of 90:10, 80:20, and 70:30 which were carried out randomly on the data. The test was carried out 10 times on each. The evaluation was carried out using Cross-Validation and each obtained an accuracy of 86 %, 85 %, and 84 %.",
        "16"
    ],
    [
        "DETEKSI JALUR JALAN DENGAN VARIASI KONDISI CUACA HUJAN DAN ILUMINASI MALAM HARI MENGGUNAKAN HOUGH TRANSFORM",
        "Deteksi jalur adalah suatu teknik untuk mendeteksi garis jalur atau area jalur yang diambil dari kamera atau LiDAR pada kendaraan otonom. Pada saat ini yang masih menjadi tantangan dalam penelitian deteksi jalur adalah bagaimana mendeteksi jalur pada berbagai variasi kondisi agar kendaraan otonom tetap dapat mendeteksi jalur dengan benar. Hal ini dikarenakan terdapat berbagai variabel yang mempengaruhi deteksi jalur, seperti kabut, hujan, variasi iluminasi, dan oklusi parsial. Variabel tersebut memiliki kemungkinan untuk mempengaruhi hasil akhir deteksi jalur. Penelitian ini akan membahas metode untuk deteksi jalur jalan pada kondisi cuaca hujan dan malam hari menggunakan hough transform. Terdapat enam langkah untuk mendeteksi jalur jalan pada kondisi cuaca hujan dan malam hari menggunakan hough transform, yaitu konversi citra dari RGB ke grayscale, pengurangan derau dengan median filter, peningkatan kontras dengan Contrast Limited Adaptive Histogram Equalization (CLAHE), deteksi tepi canny, pemilihan Region of Interest (RoI), dan deteksi garis dengan hough transform. Metode yang diusulkan berhasil mendeteksi garis jalan dengan akurasi sebesar 85.9% pada 1553 frame video pada kondisi hujan dan 946 frame video pada kondisi malam hari.",
        "17"
    ],
    [
        "Salt and Pepper Noise Image Denoising dengan Menggunakan Metode Convolutional Vision Transformer (CvT)",
        "Convolutional Neural Network (CNN) telah banyak digunakan pada dataset yang tidak terstruktur salah satunya adalah image denoising. Image denoising merupakan proses rekonstruksi citra berderau yang bertujuan untuk mengurangi derau tambahan yang terjadi dari citra derau dengan berbagai strategi. Image denoising memiliki permasalahan yaitu beberapa metode image denoising memerlukan beberapa pengetahuan sebelumnya tentang informasi mengenai derau, seperti model derau, distribusi derau, dan tingkat derau, untuk mengurangi derau pada citra. Untuk mengatasi permasalahan tersebut digunakan arsitektur gabungan Convolutional Vision Transformer (CvT) dan Residual Networks (ResNet) yang dinamakan Residual Transformer Fusion Network (RTF-Net). Secara umum proses pada arsitektur ini dapat dibagi menjadi dua bagian, Noise Suppression Network (NSN) dan Structure Enhancement Network (SEN). Residual Block digunakan pada NSN dan digunakan untuk mempelajari peta derau pada citra, sedangkan CvT digunakan pada SEN dan digunakan untuk mempelajari detail yang perlu ditambahkan pada citra hasil pemrosesan oleh Noise Supression Network. Model dilatih dengan menggunakan dataset DIV2K Training Set, dan validasi menggunakan DIV2K Validation Set. Setelah dilakukan penelitian, model diuji dengan menggunakan citra Lena, Bridge, Pepper, dan BSD300 dengan tingkat derau 30%, 50%, dan 70?n hasil PSNR dibandingkan dengan metode PARIGI, NLSF, NLSF-MLP dan NLSF-CNN. Rata-rata hasil pengujian menunjukkan bahwa metode yang diajukan (33.52 dB) 14.30% lebih unggul daripada metode terbaik sebelumnya yaitu NLSF-CNN (29.32).",
        "18"
    ],
    [
        "Multilevel Thresholding pada Citra Berwarna Berdasarkan Modified Whale Optimalization Algorithm dengan Chaotic Number dan Levy Flight",
        "Thresholding dibedakan menjadi dua yaitu bi-level thresholding dan multilevel thresholding. Multilevel thresholding merupakan metode untuk membagi citra dengan menggunakan dua atau lebih nilai threshold. Nilai-nilai threshold digunakan untuk membagi citra menjadi beberapa bagian berbeda, tidak seperti proses thresholding biasa (bi-level thresholding) dimana citra dibagi hanya menjadi 2 bagian saja. Hasil dari multilevel thresholding memberikan objek yang lebih menarik dan bermakna. Pada penelitian ini berfokus pada multilevel thresholding citra berwarna berdasarkan algoritma Whale Optimization Algorithm (WOA) yang dimodifikasi dengan penambahan chaotic number, levy flight, dan faktor korelasi. Dalam proses thresholding, keberhasilan thresholding tergantung pada pemilihan nilai threshold yang optimal. Hal ini dapat memakan waktu yang cukup lama pada multilevel thresholding. Oleh karena itu, algoritma yang diusulkan pada penelitian ini bertujuan untuk memperoleh nilai threshold yang optimal dengan waktu yang tidak terlalu lama. Selain itu juga digunakan otsu\u2019s class-variance criterion dan kapur\u2019s entropy criterion sebagai fitness function pada algoritma WOA yang dimodifikasi pada penelitian ini. Modifikasi ini memberikan keseimbangan yang tepat antara fase eksplorasi dan eksploitasi serta menghindari masalah optimalisasi lokal. Performa algoritma yang diusulkan dibandingkan dengan algoritma Genetic Algorithm (GA), Particle Swarm Optimization (PSO), Artificial Bee Colony (ABC), Cuckoo Search (CS), Whale Optimization Algorithm (WOA), dan Modified Whale Optimization Algorithm (MWOA) dilihat dari segi konvergensi, PSNR, dan running time. Hasil thresholding dari algoritma MWOA chaotic dengan fitness function otsu\u2019s class-variance criterion memiliki PSNR tertinggi sebesar 20,3078 db. Sedangkan MWOA levy flight dengan fitness function kapur\u2019s entropy criterion memiliki nilai PSNR tertinggi sebesar 20,7290 db. Selain itu, algoritma MWOA chaotic yang diusulkan lebih cepat konvergen ke solusi optimal serta memiliki running time tercepat sebesar 0,0523 s.\u00a0",
        "19"
    ],
    [
        "Clustering   Tugas Akhir  Program Studi Informatika Universitas Sebelas  Maret  (UNS) Menggunakan Metode Hierarchical K-Means",
        "Setiap\u00a0\u00a0 tahunnya\u00a0\u00a0 Program\u00a0\u00a0 Studi\u00a0\u00a0 Informatika\u00a0\u00a0 meluluskan\u00a0\u00a0 mahasiswa dengan penelitian tugas akhir yang beragam.\u00a0 Semakin\u00a0 bertambahnya\u00a0 penelitian tugas akhir dengan mata kuliah terbatas menyebabkan semakin banyak pula mahasiswa yang mengambil penelitian yang mirip tema, objek, atau metode penelitian\u00a0 dengan\u00a0 penelitian\u00a0 sebelumnya.\u00a0 Hal inilah yang mendasari\u00a0 penelitian untuk melakukan clustering pada tugas akhir Program Studi Informatika sehingga bisa\u00a0 dikelompokkan\u00a0 berdasarkan\u00a0 kemiripan\u00a0 tema\u00a0 yang\u00a0 diambil.\u00a0 Penelitian\u00a0 i ni menggunakan\u00a0 metode Hierarchical K-means Clustering.\u00a0 Berdasarkan\u00a0 clustering yang dilakukan pada tugas akhir Program Studi Informatika ini menghasilkan 16 cluster dengan tema yang berbeda-beda. Hasil dari 16 cluster dianalisa keterkaitan antar dokumen dan diperkirakan tema dari setiap cluster. Pada 16 cluster tersebut ada 12 cluster yang memiliki persentase tema lebih dari 80% yang dianggap tema spesifik, 1 cluster yang memiliki persentase tema kurang dari 80% dianggap tema belum spesifik. Hasil clustering divalidasi oleh Divisi Tugas Akhir Program Studi Informatika.Keywords : Clustering, K-means, Hierarchical, TF-IDF",
        "20"
    ],
    [
        "Clustering Berita Online Mengenai Covid-19 Menggunakan Hierarchical Clustering dan K-Means",
        "Penelitian ini melakukan clustering pada berita mengenai Covid-19 karena clustering pada berita dapat memberi penjelasan pada subtopik yang terdapat pada berita. Metode yang digunakan\u00a0 dalam\u00a0 penelitian\u00a0 ini\u00a0 adalah\u00a0 Hierarchical\u00a0 Clustering\u00a0 dan\u00a0 K-Means.\u00a0 Kombinasi antara\u00a0 Hierarchical\u00a0 Clustering\u00a0 dan K-Means\u00a0 Clustering\u00a0 bertujuan\u00a0 agar mendapatkan\u00a0 hasil clustering\u00a0 yang\u00a0 lebih\u00a0 baik.\u00a0 Pusat\u00a0 cluster\u00a0 akan\u00a0 ditentukan\u00a0 melalui\u00a0 metode\u00a0 hierarchical clustering,\u00a0 dan kemudian\u00a0 akan dilanjutkan\u00a0 dengan menggunakan\u00a0 k-means\u00a0 clustering.\u00a0 Pada penelitian\u00a0 ini penulis\u00a0 menggunakan\u00a0 228 berita\u00a0 yang diambil\u00a0 dari cnnindonesia.com\u00a0 untuk kemudian dikelompokkan menjadi cluster. Hasil cluster dihitung kualitasnya dengan menggunakan average intra similarity dan average inter similarity yang diperoleh dari penghitungan\u00a0 similaritas antar dokumen menggunakan\u00a0 Cosine Similarity. Berdasarkan\u00a0 hasil dari clustering yang dilakukan pada berita mengenai Covid-19, terbentuk cluster dengan 12 cluster dengan rata-rata intra cluster similarity 0.7911, rata-rata inter cluster similarity 0.3311.Kata kunci : Berita, Covid, Hierarchical Clustering, K-Means Clustering\u00a0",
        "21"
    ],
    [
        "Sistem Deteksi Ketersediaan Lahan Parkir Menggunakan You Only Look Once  (Yolo)",
        "<!--[if gte mso 9]><xml> </xml><![endif]--><!--[if gte mso 9]><xml> Normal 0 false false false ZH-CN ZH-CN X-NONE </xml><![endif]--><!--[if gte mso 9]><xml> </xml><![endif]--><!--[if gte mso 10]> <style> /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0cm 5.4pt 0cm 5.4pt; mso-para-margin:0cm; mso-para-margin-bottom:.0001pt; mso-pagination:widow-orphan; font-size:10.0pt; font-family:DengXian; mso-ascii-font-family:DengXian; mso-ascii-theme-font:minor-latin; mso-fareast-font-family:DengXian; mso-fareast-theme-font:minor-fareast; mso-hansi-font-family:DengXian; mso-hansi-theme-font:minor-latin;} </style> <![endif]-->Perkembangan teknologi transportasi menyebabkan harga dari kendaraan pribadi menjadi semakin murah. Hal tersebut menyebabkan jumlah kendaraan pribadi meningkat secara masif. Besarnya jumlah kendaraan pribadi terkadang menyebabkan pengendara kesulitan untuk menemukan lahan parkir yang kosong. Penyedia layanan parkir terus berinovasi untuk memberikan kemudahan bagi pengguna layanan parkir dalam menemukan ketersediaan lahan parkir. Berbagai macam solusi telah dicoba mulai dari counter-based, sensor-based sampai image-based. Sistem yang dibangun dalam penelitian ini memberikan informasi tentang jumlah dan lokasi lahan parkir yang kosong. Sistem yang dibangun akan memberikan solusi dengan menggunakan metode You Only Look Once (YOLO) versi 5. Sistem akan menggunakan gambar lahan parkir di Federal University of Parana, Curitiba, Brasil sebagai data untuk melatih model deteksi objek. Pada penelitian ini, sistem berhasil menentukan jumlah dan lokasi lahan parkir yang kosong dengan akurasi sebesar 99,048?n nilai mAP sebesar 99,25%.",
        "22"
    ],
    [
        "Convolutional Vision Transformer (CvT) untuk Peningkatan Kualitas Citra Hasil Inverse Halftoning",
        "Permasalahan dalam pengolahan citra yang sering ditemui adalah Inverse Halftoning. Secara sederhana, inverse halftoning adalah proses rekonstruksi citra yang memiliki derau halftone, yaitu derau continuous tone baik dalam bentuk titik maupun piksel hingga membentuk suatu pola gambar tertentu. Pada penelitian ini, arsitektur baru dikembangkan dengan memanfaatkan arsitektur Convolutional Vision Transformer (CvT) disebut CvT embedded Multi Layer Contour Enhancement (MLCE-CvT). Arsitektur ini dikembangkan untuk memberikan hasil rekonstruksi citra inverse halftoning yang lebih baik dibandingkan pada metode-metode sebelumnya berdasarkan nilai Peak Signal to Noise Ratio (PSNR). Eksperimen dilakukan dengan memanfaatkan dataset Div2K yang digunakan untuk training dan validation serta citra uji Barbara, Bear, Cactus, Koala, Pepper dan Shop. Dengan metode yang diajukan mampu menyelesaikan permasalahan dengan nilai rata-rata PSNR 34.97 dB. Eksperimen menunjukkan arsitektur yang diusulkan memberikan hasil yang paling baik dibandingkan dengan ALLM dengan 24.27 dB, MAP dengan 24.48 dB, LPA-ICI dengan 25.84 dB, GLDP dengan 25.92 dB, LLDO dengan 26.48 dB, CNN inverse dengan 27.69 dB, SWD dengan 29.95 dB, dan DRCNN dengan 29.77 dB.",
        "23"
    ],
    [
        "Pengenalan Bahasa Isyarat ASL  (American Sign Language) menggunakan Convolutional Neural Network dan Mediapipe Hand Tracking",
        "Sebagian besar pekerjaan sebelumnya terkait dengan pengenalan Bahasa isyarat memerlukan perangkat keras khusus, seperti. sensor kedalaman. Solusi lain tidak cukup ringan untuk dijalankan secara real time dan dengan demikian terbatas pada platform yang dilengkapi dengan sumber daya yang kuat. Oleh karena itu, penelitian ini mengusulkan klasifikasi bahasa isyarat secara realtime menggunakan mediapie hands untuk mengekstrak feature landmark dari gambar RGB tanpa alat tambahan dan 1D CNN yang dapat bekerja dengan kompleksitas komputasi yang lebih rendah serta nilai akurasi yang tinggi. Penelitian dimulai dengan mengekstraksi features 21 landmark tangan 3D pada gambar ASL oleh mediapipe hands kemudian dilakukan seleksi pada gambar dataset. Dilakukan cleaning data sehingga data yang digunakan selanjutnya adalah data yang memiliki bentuk landmark tangan sesuai dengan bentuk tangan pada gambar yang diberikan. Dilakukan penyesuaian dimensi pada data bersih yang diperoleh, kemudian\u00a0 diklasifikasikan menggunakan algoritma 1D CNN. pada penelitian ini didapatkan hasil berupa tingkat akurasi dan nilai F1-Score yang sangat baik yaitu F1-Score sebesar 99,9881276 dan akurasi sebesar 0,99988129. pada data yang tidak disertakan pada proses pelatihan didapatkan hasil yang sangat baik yaitu F1-Score sebesar 99,1425085 dan akurasi sebesar 0,99153439. Dilakukan juga pengujian terhadap video untuk mensimulasikan penggunaan secara realtime. Didapatkan nilai F1-Score sebesar 99,3535477 dan akurasi sebesar 0,99444444.\u00a0",
        "24"
    ],
    [
        "Analisa Sentimen KOmentar terhadap Kebijakan Pemerintah dalam Pendidikan  Awal Pandemi Covid-19 dengan Penerapan Algoritma Support Vector Machine  menggunakan Perbandingan Kernel",
        "Kebijakan Pemerintah Indonesia untuk penanganan Pandemi Covid-19 di bidang pendidikan menuai banyak pro dan kontra karena berpengaruh pada banyak aspek dari peserta didik hingga orang tua dan guru. Penelitian ini membahas sentimen masyarakat terhadap kebijakan yang diambil pemerintah Indonesia dalam bidang pendidikan. Klasifikasi dilakukan menggunakan Support vector machine menjadi 3 kelas positif, negatif dan netral. Tahap pada penelitian ini yaitu pengambilan data yang diambil dari komentar sosial media Youtube kemudian di sortir menjadi 2019 data, Text Preprocessing, Pembobotan TF-IDF, pembagian data menggunakan train test split dan klasifikasi, pada SVM pemilihan kernel sangat berpengaruh pada jalanya algoritma secara optimal sehingga dilakukan perbandingan akurasi pada kernel yang digunakan. Kernel RBF memiliki akurasi tertinggi sebesar 70.54% sedangkan akurasi terendah Kernel Polynomial sebesar 66.08%. Hasil dari klasifikasi sentimen yang ada menunjukkan sentimen positif dengan rata rata sebesar 48.51%, pada keempat kernel yang dan total 2019 data yang diolah sedangkan sentimen negatif bernilai 36.54?n 14.94% pada sentimen netral",
        "25"
    ],
    [
        "Perbandingan Metode Backpropagation dan Support Vector Machine pada Klasifikasi Penyakit Retinopati Diabetes",
        "Dewasa ini transisi pola penyakit bergeser dari penyakit infeksi menular ke penyakit tidak menular atau penyakit degenaratif. Salah satu penyakit degeneratif adalah Diabates Retinopati dan saat ini banyak ahli medis yang kesulitan dalam melakukan deteksi dini. Salah satu alasannya adalah kesulitan dalam mendeteksi gejala awal yang muncul dikarenakan penyakit ini sulit untuk di kenali. Agar penyakit ini dapat terdeteksi secara dini, diperlukan metode klasifikasi yang akurat. Data mining merupakan salah satu alternatif dalam melakukan klasifikasi. Penelitian ini dilakukan untuk mencari model klasifikasi mana yang lebih baik antara metode Support Vector Machine dan Backpropagatiaon berdasarkan dataset diabetes retinopati. Hasil penelitian menunjukkan bahwa diantara kedua metode tersebut penerapan metode Support Vector Machine lebih unggul digunakan dimana nilai akurasi mencapai nilai 74,85?ngan luas AUC 0,823 dibandingkan dengan metode Backpropagation dengan akurasi hanya 71,96?n luas AUC 0,791.Kata Kunci: Backpropagation Neural Network , Diabetes retinopati, Klasifikasi , Support vector machine (SVM)\u00a0",
        "26"
    ],
    [
        "Klasifikasi Relevansi Trending Topic Dengan  Konten Twitter Menggunakan Support Vector Machine (SVM)",
        "Twitter adalah media sosial yang sangat berpengaruh belakangan ini, bahkan dapat dikatakan menjadi portal informasi yang cukup penting. Untuk dapat melihat berita yang sedang populer, pengguna dapat menggunakan fitur trending topik atau hashtag yang populer. Namun karena popularitas twitter, trending topik seringkali berbeda dengan konten yang disuarakan. Banyak pengguna memanfaatkan trending topik untuk mendapat perhatian publik lebih banyak, dengan asumsi banyak orang melihat trend. Untuk mengetahui korelasi tersebut, melihat jika konten tweet tersebut relevan atau tidak dengan trending topiknya, dilakukan dengan klasifikasi teks. Klasifikasi dilakukan dengan metode Support Vector Machine. Langkah penelitian adalah membersihkan data teks, kemudian melakukan pembobotan dengan TF-IDF dan klasifikasi dengan SVM. Dalam penelitian ini, SVM dapat mengklasifikasikan data tweet dengan baik. Hasil klasifikasi menunjukkan nilai rata-rata akurasi sebesar 86%. Hasil rata-rata precision adalah 65%\u00a0 untuk data relevan dan 85?ta tidak relevan, recall 46% untuk data relevan dan 98% untuk data tidak relevan, F1-Measure 50?ta relevan dan 89% untuk tidak relevan.Kata kunci : Confusion Matrix, SVM, TF-IDF, Trending Topic\u00a0",
        "27"
    ],
    [
        "Analisa Perbandingan Pemodelan TF-IDF dan WORD2VEC Untuk  Klasifikasi Emosi Pengguna Transjakarta dan Commuterline  pada Data Twitter Menggunakan Metode Support Vector Machine",
        "Peranan angkutan umum menjadi salah satu aspek yang menjadi perhatian khusus karena menyangkut hajat hidup orang banyak, terkhusus juga pada pemerintah DKI Jakarta. Beberapa angkutan umum yang mudah dijumpai di Jakarta saat ini yaitu commuterline dan Transjakarta. Berbagai komentar tentang tingkat kepuasan layanan pengguna kedua angkutan umum tersebut disampaikan melalui medial social, salah satunya adalah Twitter. Tweet mengenai kepuasan layanan dapat berupa emosi atau tidak, hal ini dapat diketahui melalui klasifikasi. Klasifikasi dilakukan dengan metode Support Vector Machine (SVM). Dalam tahap klasifikasi dilakukan 2 tahap yaitu tahap pertama untuk tweet yang mengandung emosi dan tidak mengandung emosi kemudian dilanjutkan tahap kedua untuk tweet yang mengandung emosi dibagi menjadi 5 jenis emosi yaitu senang, marah, sedih, takut dan terkejut. Sebelum tahao klasifikasi dilakukan pemodelan terlebih dahulu dengan menggunakan TF-IDF pada tahap pertama dan kedua sedangkan pemodelan Word2Vec hanya pada tahap pertama agar dapat diketahui hasil klasifikasi terbaik dengan menggunakan kedua pemodelan tersebut. Hasil klasifikasi tahap pertama menunjukan SVM dengan TF-IDF mempunyai nilai akurasi lebih baik dibandingkan dengan SVM dengan Word2Vec yaitu dengan data commuterline sebesar 85.17%, data Transjakarta sebesar 84.40?n data campuran sebesar 82.78%. Selanjutnya pada tahap kedua hasil klasifikasi mempunyai nilai akurasi data commuterline sebesar 94%, data Transjakarta sebesar 93.90?n data campur sebesar 88.80%.Keywords: Confussion Matrix, Support Vector Machine, TF-IDF, Word2Vec\u00a0",
        "28"
    ],
    [
        "Sistem Rekomendasi Pemilihan Jurusan Sekolah Menengah Kejuruan (Smk) Menggunakan Metode Fuzzy Multi-Attribute Decision Making (Fmadm) Model Yager",
        "AbstrakPertumbuhan teknologi dan pengetahuan yang semakin pesat membutuhkan upaya untuk meningkatkan sumber daya manusia, salah satunya meningkatkan kualitas pada pendidikan vokasi. Pendidikan vokasi adalah penyelenggaraan jalur pendidikan formal yang diselenggarakan pada pendidikan tinggi salah satunya adalah Sekolah Menengah Kejuruan (SMK). Lulusan SMK dengan potensi yang berkualitas dapat meningkatkan sumber daya manusia unggul. Permasalahan yang dihadapi adalah siswa yang ingin memasuki SMK, sering kesulitan dalam memilih jurusan yang sesuai dengan potensinya, kesalahan dalam memilih jurusan menyebabkan siswa yang telah masuk SMK menjadi lulusan yang kurang unggul. Salah satu\u00a0 penyelesaian\u00a0 permasalahan\u00a0 tersebut\u00a0 adalah\u00a0 membuat\u00a0 sistem\u00a0 yang\u00a0 dapat merekomendasikan jurusan yang sesuai dengan potensi siswa. Metode yang digunakan dalam perhitungan penelitian ini adalah metode Fuzzy Multi-Attribute Decision Making (FMADM) Model Yager untuk memberikan hasil rekomendasi jurusan yang sesuai dengan potensi siswa. Atribut yang digunakan dalam pemilihan jurusan tersebut adalah nilai akademik, nilai bakat, nilai minat, nilai Intellegence Quotient (IQ), tingkat dukungan orang tua, motivasi berprestasi, sikap anak, kemandirian anak, dan kesehatan anak. Pengujian sistem rekomendasi pemilihan jurusan SMK menggunakan metode FMADM Model Yager didapatkan pada skenario satu hasil rekomendasi pada tingkat sepuluh besar dihasilkan nilai kesesuaian yang sesuai sebesar 95.00?n tidak sesuai 5.00%. Pada skenario dua hasil rekomendasi pada tingkat tiga besar dihasilkan nilai kesesuaian yang sesuai sebesar 82.50?n tidak sesuai sebesar 17.50%. Berdasarkan kesesuaian tersebut, metode FMADM Model Yager dapat diimplementasikan dan menghasilkan rekomendasi yang sesuai dengan potensi siswa.Kata Kunci: Sistem Rekomendasi, Fuzzy Multi-Attribute Decision Making, Fmadm, Model Yager, Jurusan Smk, Sistem Perangkingan\u00a0",
        "29"
    ],
    [
        "Penghilangan Derau Salt-And-Pepper Menggunakan Kerangka Kerja Residual Learning Pada Citra Berwarna",
        "AbstrakSebagian besar metode penghilangan derau salt-and-pepper masih memanfaatkan pendekatan median filter. Akan tetapi, hasil pemulihan yang didapatkan masih belum bisa menyiasati kekurangan median filter untuk menghilangkan noise pada kontaminasi tinggi. Oleh karena itu, penelitian ini mengusulkan metode pemulihan kontaminasi salt-and-pepper yang sepenuhnya menggunakan pendekatan convolutional\u00a0\u00a0 neural\u00a0\u00a0 network\u00a0\u00a0 (CNN).\u00a0\u00a0 CNN\u00a0\u00a0 diimplementasikan\u00a0\u00a0 menggunakan kerangka kerja residual learning dengan pre-activation residual unit agar pelatihan neural network dapat lebih cepat mencapai konvergen. Proses denoising diformulasikan\u00a0 sebagai\u00a0 image translation\u00a0 problem\u00a0 yang\u00a0 mentransformasikan\u00a0 citra terkontaminasi (noisy image) mejadi citra yang bebas kontaminasi (denoised image) dan dilakukan tanpa menggunakan pra-pemrosesan citra. Oleh karena itu, arsitektur neural\u00a0 network\u00a0 hanya\u00a0 membutuhkan citra\u00a0 yang\u00a0 terkontaminasi\u00a0 sebagai\u00a0 input\u00a0 dan menghasilkan output berupa citra yang telah terpulihkan (denoised image). Berdasarkan hasil eksperimen, rata-rata nilai PSNR yang didapatkan mampu melampaui nilai PSNR usulan-usulan metode denoising sebelumnya pada tiap rasio noise yang dipertimbangkan. Terlebih pada pengujian menggunakan citra Kodak Image Dataset, arsitektur yang dikembangkan memperoleh peningkatan nilai PSNR hingga 7 dB dari usulan metode sebelumnya pada rasio noise 30%. Secara visual, arsitektur yang diusulkan dapat menyajikan pemulihan citra dengan sangat baik.Keywords : Image Denoising, Salt And Pepper Noise, Convolutional Neural Networks, Residual Learning, Deep Learning.\u00a0",
        "30"
    ],
    [
        "Implementasi Algoritma Improvised Prioritized Deadline Scheduling Algorithm (Ipdsa) Pada Grid Environment Menggunakan  PVM3",
        "AbstrakResource\u00a0 Scheduling adalah\u00a0 salah\u00a0 satu\u00a0 bagian\u00a0 yang\u00a0 menantang\u00a0 dalam komputasi grid.\u00a0 Sejumlah algoritma telah dirancang dan dikembangkan untuk membuat resource scheduling yang efektif. Disini kami menggunakan algoritma improvised prioritized deadline scheduling algorithm (IPDSA) menggunakan parallel virtual machine versi 3 (PVM3) untuk eksekusi task yang efisien dengan batasan deadline dari setiap task. PVM3 merupakan library perangkat lunak yang mengoptimalkan sumber daya secara fleksibel dan heterogen pada komputer yang saling berhubung dengan beragam arsitektur secara paralel sehingga dapat menyelesaikan tasks dengan baik meskipun berukuran sangat besar dan kompleks. Penelitian ini mengimplementasikan algoritma IPDSA untuk mengoptimalkan penjadwalan dan sumber daya Grid pada suatu lab komputer sebagai grid environment dimana komputer \u2013 komputer tersebut sebagai sumber daya Grid. Penelitian ini juga mengembangkan algoritma IPDSA dengan memberikan prioritas pada setiap task dan diimplementasikan menggunakan PVM3. Seperti yang terdapat pada hasil percobaan, algoritma IPDSA berhasil diimplementasikan menggunakan PVM3 sehingga Average Tardiness menunjukkan nilai yang stabil dan mendapatkan nilai Non-Delayed Task diatas 94%, karena sumber daya dan task yang dikerjakan didistribusikan secara merata sesuai dengan jumlah host yang digunakan.Keywords: Grid\u00a0 Computing, Resource Scheduling, Two-Level Hierarchy Scheduling Model, Pvm3, Ipdsa.\u00a0",
        "31"
    ],
    [
        "Deteksi Penyakit Tanaman Tomat Melalui Tekstur Daun Dengan Metode Gabor Filter",
        "AbstrakTomat merupakan salah satu bahan pokok dalam membuat makanan di Indonesia dan merupakan komoditas hortikultura populer ke-5. Pada tahun 2018 total produksi tomat mencapai 0.98 juta ton, namun dibalik angka produksi yang mencapai hampir 1 juta ton tomat di Indonesia sempat mengalami penurunan produksi pada tahun2013 hingga 2015 dan peningkatan yang kurang signifikan di tahun berikutnya. Hal ini disebabkan oleh salah satu faktornya yaitu penyakit pada tanaman itu sendiri. Penyakit pada tanaman merupakan masalah yang cukup serius dikalangan petani di Indonesia, kurangnya keahlian dalam membedakan ciri daun berpenyakit dan jenisnya merupakan permasalahan yang berakibat keterlambatan penanganan dan bedampak pada penurunan produktifitas. Dalam menyelesaikan permasalahan tersebut, maka dibuatlah suatu sistem untuk mendeteksi penyakit pada tanaman tomat melalui tekstur daun agar mempermudah petani di Indonesia dalam mendeteksi penyakit pada tanaman tomat sedini mungkin. Penelitian dimulai dengan ekstraksi feature warna dengan citra daun asli dan citra yang telah disegmentasi dengan multi otsu threshold, dilanjutkan dengan ekstraksi feature tekstur berupa ciri dari sisi dan garis objek daun di berbagai sudut dan juga frekuensi dengan gabor filter, lalu diklasifikasikan menggunakan algoritma SVM dengan kernel RBF.\u00a0 Penelitian ini memiliki kesimpulan bahwa gabor filter dapat melakukan deteksi\u00a0 penyakit melalui tekstur dengan cukup baik dan ditambah adanya tekstur warna menghasilkan rata - rata specificity 98.83%, sensitivity 90.37%, precision90.36%,\u00a0 f1-score\u00a0 90.34%,\u00a0 accuracy\u00a0 97.92%\u00a0 dan\u00a0 accuracy\u00a0 keseluruhan\u00a0 mencapai 90.37%.Kata kunci: Gabor Filter, Machine Learning, Support Vector Machine, Radial Basis Function Kernel, Image Classification , Texture Analysis, Tomato Disease Detection.\u00a0",
        "32"
    ],
    [
        "Modifikasi Algoritma Density-Based Spatial Clustering of Applications With Noise ( Dbscan )  Untuk Reduksi Data Pada Intrusion Detection Evaluation Dataset",
        "AbstrakPertumbuhan implementasi teknologi digital yang semakin luas menciptakan permasalahan baru yaitu keamanan data. Untuk menjaga kerahasiaan data, mendorong terciptanya sebuah sistem hybrid keamanan baru, yaitu Intrusion Detection System ( IDS ) dan klasifikasi machine learning. Dalam proses klasifikasi untuk membuat model diperlukan proses data learning. Proses learning dalam klasifikasi akan sebanding dengan jumlah data yang diproses. Semakin besar data maka akan membutuhkan waktu dan resource yang semakin tinggi. Terkait dengan upaya untuk mengatasi masalah resource yang tinggi dapat dilakukan dengan teknik reduksi data. Beberapa penelitian yang dilakukan memiliki beberapa kekurangan, diantaranya pengambilan sampel dapat mengecualikan data yang mungkin tidak homogen dengan data yang diambil. Pada penelitian ini mengusulkan metode pendekatan density dengan modifikasi algoritma Density-Based Spatial Clustering of Applications with Noise ( DBSCAN ). Pendekatan density dipilih yang bertujuan untuk mengatasi permasalahan homogenitas data setelah direduksi terhadap data aslinya. Modifikasi yang dilakukan yaitu menambahkan satu parameter minNeighborhood yang digunakan untuk menentukan jarak kepadatan terhadap titik pusat cluster, yang selanjutnya akan ditandai untuk dihapus. Dilakukan 2 skenario percobaan pemisahan label untuk mengetahui pengaruh pemisahan label pada proses reduksi data, didapatkan bahwa modifikasi DBSCAN dapat mengatasi permasalahan inkonsistensi perbandingan rasio data yang mungkin terjadi. Modifikasi DBSCAN yang dilakukan memberikan hasil baik yang ditunjukan dengan dapat mempertahankan akurasi klasifikasi diatas 90%. Dari 8 skenario percobaan reduksi data pada data terendah yaitu 80%, akurasi dapat dipertahankan dari 99.364% menjadi\u00a0 92.28%.Keywords\u00a0\u00a0 \u00a0: Network Intrusion Detection, Density-Based Spatial Clustering Of Applications With Noise, Reduksi Data\u00a0",
        "33"
    ],
    [
        "Perbandingan Metode Seleksi Dalam Algoritma Genetika Pada Kasus Multi Travelling Salesman Problem  (Studi Kasus: UD Sumber Jaya Utama)",
        "AbstrakMulti Travelling Salesman Problem (M-TSP) merupakan suatu metode yang digunakan untuk mencari rute jarak terpendek yang harus dilewati oleh beberapa orang sales dalam mengunjungi beberapa tempat tujuan dari suatu tempat asal. Algoritma genetika cukup bagus diaplikasikan dalam menyelesaikan masalah TSP.. Dalam algoritma genetika terdapat proses yang dinamakan seleksi, dimana beberapa kromosom dipilih menjadi parent. Beberapa metode seleksi pada algoritma genetika antara lain : roulette wheel, tournament selection, rank selection. Penelitian ini menguji ketiga metode seleksi di atas untuk mendapatkan metode seleksi terbaik, dan mencari rute terpendek untuk perbandingan cost pada pendistribusian sepatu pada UD. Sumber Jaya Utama. Metode yang dilakukan berupa pengumpulan data, perancangan M-TSP, implementasi algoritma genetika, perancangan program, implementasi program dan analisis program. Hasil pada penelitian ini, metode roulette wheel mendapatkan hasil rata-rata jarak sebesar 902 km dengan generasi optimal 215 generasi, lalu metode rank selection sebesar 918 km dengan 212 generasi, dan tournament selection sebesar 932 km dengan 186 generasi. Hasil tersebut menunjukkan metode seleksi terbaik adalah roulette wheel. Sistem juga berhasil mengurangi biaya distribusi UD. Sumber Jaya Utama sebesar Rp 35.470,- per minggu.Kata kunci : Multi Travelling Salesman Problem, Genetic algorithm, Roulette Wheel Selection, Rank Selection, Tournament Selection, UD Sumber Jaya Utama\u00a0",
        "34"
    ],
    [
        "Meningkatkan Hasil Question Answering System Dengan Metode Semantic Similarity Berbasis Hierarki Dalam Ontology ",
        "AbstrakBeberapa penelitian seperti QUERIX merupakan QAS berbasis ontology yang bergantung pada dialog klarifikasi jika terjadi ambiguitas. Penelitian \u2018QAS Menggunakan Semantic Web dan Algoritma Porter sebagai Stemmer kata\u2019 merupakan open domain QAS yang bersifat sintaksis. QAS tersebut dibangun menggunakan knowledge-base berbasis ontology dbpedia, namun belum dapat mencari kedekatan semantik ketika melakukan query. Pengolahan kalimat hanya dengan kedekatan sinstaksis saja belum tentu dapat memberikan jawaban yang memuaskan pengguna. Oleh karena itu, perlu melihat kalimat pertanyaan dengan kedekatan semantik. QASSOMI adalah Question Answering dengan metode Semantic Similarity berbasis hierarki pada Ontology Makanan Indonesia. Dengan menerapkan metode Semantic Similarity pada QAS maka dapat meningkatkan hasil jawaban yang dapat memuaskan pertanyaan pengguna. QAS dibangun berbasis Web Semantik dengan menggunakan Ontology sebagai pengetahuan dengan penelusuran berbasis hierarki. Berdasarkan pengujian, sistem memiliki precision sebesar 74,44?n recall sebesar 74,44%. . Dengan menerapkan metode Semantic Similarity, hasil jawaban QAS dapat ditingkatkan hingga 60%.Kata Kunci: Question Answering System, Natural Language Processing, Semantic Web, Ontology, Semantic Similarity\u00a0",
        "35"
    ],
    [
        "Implementasi Business Intelligence dan Data Warehouse Menggunakan Metode Nine-Step Kimball Untuk Pendukung Mutu Layanan Rumah Sakit",
        "AbstrakRumah sakit merupakan fasilitas kesehatan umum untuk masyarakat. Fasilitas kesehatan memiliki standar tertentu sebagai ukuran kualitas pelayanan terbaik untuk menunjang kesehatan masyarakat. Kementerian kesehatan Indonesia memiliki Standar Pelayanan Minimal untuk mengukur kelayakan suatu rumah sakit. RSUD Ir. Soekarno Sukoharjo, pengukuran serta penyajian data rekam medik yang digunakan dalam penyajian Standar Pelayanan Minimal masih menggunakan cara manual, sehingga dalam pelaporan sulit memperoleh gambaran kualitas pelayanan dengan cepat, akurat dan aktual maka dari itudiperlukan seubah sistem informasi yang dapat memberikan informasi yang cepat, akurat dan aktual. Sistem tersebut biasa disebut dengan Business Intelligence. Untuk membangun sistem tersebut digunakan pendekatan data warehouse, untuk membangun sistem tersebut menggunakan pendekatan data warehouse, dengan menggunakan metode sembilan langkah (nine step methodology). Penerapan metode tersebut menunjukkan nilai hasil persentase dalam satu tahun pada penganganan lifesaving memperoleh nilai sebesar 92,46?ri 100%, pelayanan kegawat daruratan bersertifikat memperoleh 64,08?ri 100%, kematian pasien ? 24 jam terpenuhi dibulan Oktober sebesar 0,001, kematian pasien > 48 jam terpenuhi dibulan April sebesar 2,71% & Mei sebesar 2,69%. Sedangkan pelayanan lainnya memenuhi standar minimal yang ditentukan. Hasil pengujian Black Box menunjukkan bahwa setiap fungsional aplikasi dapat berjalan dengan baik dan memberikan hasil yang sesuai dengan harapan. Dari implementasi Business Intelligence dengan pendekatan data warehouse menggunakan metode nine step methodology dapat diterapkan untuk mendukung penyajian informasi Standar Pelayanan Minimal. Dari penelitian ini dapat diperoleh hasil dari aplikasi yang dibuat bahwa di RSUD Ir. Soekarno Sukoharjo ada beberapa indikator yang belum mencapai nilai Standar Pelayanan Minimal.Kata kunci : Business Intelligence, data warehouse, nine step methodology.\u00a0",
        "36"
    ],
    [
        "Penerapan Metode Particle Swarm Optimization Pada Jaringan Saraf Tiruan Menggunakan Dataset Kanker Payudara  ",
        "AbstrakJaringan saraf tiruan merupakan suatu sistem komputasi yang terinspirasi dari sel saraf biologis di dalam otak. Kelebihan dari metode jaringan adalah proses pembelajarannya, dimana setiap neuron mewakili input akan diproses sedemikian sehingga menghasilkan output yang sesuai atau mirip dengan data testing. Supaya mendapatkan hasil yang lebih optimal pada proses pembelajaran dapat diterapkan metode baru baik dari segi kecepatan eksekusi maupun nilai akurasi. Penelitian ini mencoba menerapkan algoritma particle swarm optimization pada jaringan saraf tiruan. Hasil yang diharapkan nantinya adalah PSO sebagai metode optimasi dapat meningkatkan hasil keluaran jaringan saraf tiruan.\u00a0\u00a0 \u00a0Dataset yang akan digunakan adalah database penderita kanker payudara yang diunduh dari UCI repository. 699 data yang terdapat pada database kanker payudara akan dibagi menjadi 66?ta pelatihan dan 34?ta pengujian. Beberapa faktor yang akan digunakan sebagai pembanding adalah waktu eksekusi dan nilai akurasi. Waktu eksekusi diperoleh dari catatan waktu dimulai dan berakhirnya satu kali proses running. Untuk nilai akurasi didapat dari penghitungan confusion matrix. Kondisi penelitian kali ini adalah 30x running dan 500 iterasi. Sedangkan untuk jaringan saraf tiruan yang dioptimasi oleh JST hanya menggunakan 25 iterasi dan 20 populasi. Penggunaan populasi inilah yang membedakan antara jaringan saraf tiruan sebelum dan sesudah optimasi.\u00a0Setelah dilakukan penerapan PSO pada jaringan saraf tiruan, rata-rata waktu eksekusi selama satu kali proses running mengalami penurunan menjadi lebih cepat dan nilai akurasi mengalami peningkatan menjadi lebih akurat. Sehingga dapat disimpulkan bahwa algoritma PSO berhasil meningkatkan kinerja jaringan saraf tiruan baik dari segi waktu eksekusi dan nilai akurasi.Kata Kunci - Jaringan Saraf Tiruan, Particle Swarm Optimization, kanker payudara\u00a0",
        "37"
    ],
    [
        "Implementasi Algoritma Load Balancing PLBA untuk  Komputasi Grid Pada Lab Environment Menggunakan PVM3 ",
        "AbstrakLoad balancing adalah salah satu bagian utama pada penjadwalan sumber daya Grid. Salah satu model load balancing pada sumber daya Grid yaitu model hierarki yang memiliki kelebihan hanya memerlukan biaya komunikasi yang sedikit antara sumber daya satu dengan sumber daya lainnya. Algoritma load balancing PLBA menggunakan model hierarki dengan nilai threshold yang didapatkan secara dinamis sehingga dapat menyesuaikan keadaan pada suatu waktu, baik keadaan sumber daya, keadaan jaringan komputer, dan penerima atau client. PVM3 adalah sistem perangkat lunak yang mampu mengoptimalkan sumber daya yang heterogen sehingga sumber daya dapat bekerja secara parallel dalam menyelesaikan tasks dengan baik meskipun tasks tersebut merupakan tasks yang sangat besar dan kompleks. Penelitian ini mengimplementasikan algoritma load balancing PLBA untuk mengoptimalkan sumber daya Grid yang berasal dari suatu lab komputer di mana komputer \u2013 komputer yang ada di lab tersebut dijadikan sebagai sumber daya Grid. Penelitian ini juga sedikit mengembangkan algoritma load balancing PLBA dengan mengubah argument untuk NPEList sehingga sumber daya dapat dikelompokkan dengan lebih optimal. Seperti yang terdapat pada bagian hasil experimental, algoritma load balancing PLBA berhasil dikembangkan dengan memodifikasi argument untuk NPEList sehingga running time yang diperlukan untuk menyelesaikan tasks yang diberikan lebih singkat, karena sumber daya dapat dikelompokkan dengan lebih optimal.\u00a0Keywords: Grid Computing, Load Balancing, Hierarchical Load Balancing Model, Virtual Machine, PVM3.\u00a0",
        "38"
    ],
    [
        "Multi  Friendly Secret Image Sharing  Berdasarkan Pada Operasi Boolean  dengan Basis (N,N)",
        "AbstrakDalam beberapa tahun terakhir, kemajuan dalam bandwidth jaringan dan perkembangan pesat dalam komunikasi digital telah mendorong tren yang berkembang untuk transmisi data digital. Gambar adalah salah satu tipe data yang paling sering digunakan secara mendunia. Namun, terdapat beberapa isu dalam mentransmisi gambar melalui internet. Beberapa gambar ada yang rahasia yaitu gambar yang hanya boleh diketahui oleh pihak-pihak tertentu saja. Tetapi jika hanya satu pihak yang diberikan akses ke data, maka kehilangan gambar yang disengaja\u00a0 atau\u00a0 tidak\u00a0 disengaja\u00a0 dapat\u00a0 terjadi.\u00a0 Di\u00a0 sisi\u00a0 lain,\u00a0 jika\u00a0 beberapa pihak mendapatkan\u00a0 bagian\u00a0 dari\u00a0 secret image, maka kerjasama mereka semua adalah kelemahan untuk rekonstruksi secret image. Metode SIS (Secret Image Sharing) dikembangkan\u00a0 untuk\u00a0 mengatasi\u00a0 masalah\u00a0 tersebut.\u00a0 Pada\u00a0 penelitian sebelumnya metode MSIS (Multi Secret Image Sharing) dengan basis (n,n) threshold dengan operasi boolean telah dikembangkan, yaitu dengan input sebanyak n secret image dan\u00a0 menghasilkan\u00a0 n\u00a0 shared\u00a0 image\u00a0 dengan\u00a0 makna yang tersembunyikan. Pada penelitian tersebut terdapat kekurangan yaitu penyerang dapat mengetahui bahwa data tersebut disembunyikan. Untuk mengatasi masalah tersebut metode MFSIS (Multi Friendly Secret Image Sharing) diajukan. Metode tersebut merupakan penggabungan dari MSIS dan FSS(Friendly Secret Sharing) sehingga menghasilkan shared image yang familiar dan sulit diidentifikasi oleh penyerang. Skema\u00a0\u00a0 MFSIS\u00a0\u00a0 dapat\u00a0\u00a0 mengatasi\u00a0\u00a0 masalah\u00a0\u00a0 yang\u00a0\u00a0 terdapat\u00a0\u00a0 pada\u00a0\u00a0 penelitian sebelumnya yang dimana hasil dari sharing mampu menyembunyikan makna sebuah image tersembunyi.Keywords : Secret Image Sharing, Image Processing, Data Security, Friendly SecretSharing\u00a0",
        "39"
    ],
    [
        "Peningkatan Kualitas Citra Color-Embedded-Grayscale Menggunakan Deep Convolutional Networks  ",
        "AbstrakColor recovery merupakan ill-posed inverse problem yaitu masalah terbalik yang tidak punya solusi yang unik. Pada banyak kasus, kualitas dari citra hasil restorasi warna tidak memuaskan dikarenakan distorsi warna dan checkerboard artifact. Untuk mengatasi permasalahan tersebut, diusulkan metode berbasis deep learning untuk peningkatan kualitas citra hasil restorasi warna. Metode ini menggunakan Convolutional Neural Networks (CNN) untuk proses post color recovery. Metode yang diusulkan memberikan hasil yang lebih bagus dibandingakan dengan metode-metode sebelumnya berdasarkan penilaian PSNR dan SSIM dengan nilai tertinggi 29.57 dB untuk\u00a0 PSNR dan 0.9331 SSIM.Keywords: Image Quality Improvement, Convolutional Neural Network, Ill-Posed Inverse Problem, Color-Embedded-Grayscale\u00a0",
        "40"
    ],
    [
        "Permasalahan false positive pada skema image sharing yang berdasarkan singular value decomposition dan fourier transform",
        "False positive problem adalah permasalahan yang terjadi pada proses watermarking yang berdasarkan Singular Value Decomposition. Dengan adanya permasalahan ini, ketika seseorang mencoba untuk mengekstrak gambar yang telah terwatermark, maka akan diperoleh gambar terekstrak yang mirip dengan gambar sembarang bukan gambar watermark yang telah disisipkan sebelumnya.\u00a0\u00a0 Hal ini dikarenakan ketika seseorang menyisipkan gambar sembarang kedalam gambar terwatermark, diperoleh sebuah side information yang merupakan kunci untuk melakukan watermark extraction. Kunci ini memiliki informasi gambar eigenimage dari gambar sembarang. Oleh sebab itu dalam penelitian ini, skema image sharing yang telah diajukan oleh Singh, Raman dan Misra tahun 2017 akan diuji apakah skema ini akan mengalami permasalahan false positive. Dalam penelitian ini akan dibangun ulang skema image sharing semirip mungkin dengan skema yang telah diajukan. Dimana terdapat proses enkripsi menggunakan Shamir Secret Sharing (SSS) serta proses watermarking menggunakan Singular Value Decomposition (SVD) dan Fourier Transform (FT). Hasil dari penelitian menunjukkan bahwa skema image sharing yang telah diajukan memiliki permasalahan false positive",
        "41"
    ],
    [
        "Low Rank Minimization Pada Gambar Berwarna Untuk Image Denoising",
        "Tujuan dari penelitian ini adalah mempresentasikan metode Low Rank Minimization untuk melakukan denoising pada gambar berwarna. Proses pendekomposisian gambar berwarna dilakukan dengan memisahkan masing-masing warna primer dalam gambar berdasarkan warna RGB (merah, hijau, dan biru). Masing-masing channel warna hasil pendekomposisian kemudian diproses dengan patch grouping, rank minimization via singular value decomposition, dan aggregation. Metode iterative regularization juga diaplikasikan untuk mereduksi residu noise yang tersisa pada denoised image. Seluruh channel warna RGB yang telah diproses kemudian dikombinasikan kembali sehingga menjadi satu gambar berwarna yang utuh. PSNR kemudian digunakan untuk menghitung kualitas gambar hasil proses denoising. Hasil dari percobaan menunjukkan bahwa dengan nilai sigma yang sama pada AWGN, nilai PSNR pada gambar berwarna sedikit lebih rendah dibandingkan dengan gambar grayscale-nya, tetapi nilai antar keduanya tidak terpaut jauh.Kata Kunci: Image Denoising, Rank Minimization, Additive White Gaussian Noise, Singular Value Decomposition\u00a0",
        "42"
    ],
    [
        "Perbandingan Teknik Undersampling dan Oversampling pada Klasifikasi Data Pasien Diabetes Mellitus (Dm) Dengan Menggunakan Algoritma Naive Bayes Classifier (NBC)",
        "ABSTRAK\u00a0Ketidakseimbangan data merupakan masalah serius dalam suatu proses klasifikasi. Sebagian besar algoritma klasifikasi cenderung hanya melakukan klasifikasi pada data anggota kelas mayor sehingga mengabaikan proses klasifikasi pada data anggota kelas minor. Hal ini dapat berpengaruh terhadap perolehan nilai presisi dan recall pada data anggota kelas minoritas sehingga menjadi sangat kecil. Untuk menyelesaikan permasalahan ketidakseimbangan data yang terjadi, maka pada penelitian ini akan dilakukan baik proses undersampling maupun proses oversampling untuk menyeimbangkan data. Proses undersampling dilakukan menggunakan teknik Spreadsubsample, sedangkan proses oversampling dilakukan menggunakan Synthetic Minority Oversampling Technique (SMOTE). Data yang digunakan pada penelitian ini adalah data pasien Diabetes Mellitus (DM). Teknik lain yang juga digunakan dalam penelitian yang diusulkan ini adalah Backward Greedy Stepwise untuk melakukan pencarian terhadap atribut yang berpengaruh positif terhadap hasil klasifikasi dan algoritma Naive Bayes Classifier (NBC) untuk melakukan klasifikasi data. Hasil dari penelitian yang telah dilakukan adalah nilai rata- rata akurasi tertinggi yang diberikan oleh data latih dari data pasien DM yang diproses dengan metode undersampling lebih tinggi dibandingkan dengan akurasi data latih yang diproses dengan metode oversampling, meskipun nilai rata- rata tertinggi pada nilai presisi dan nilai recall yang diberikan oleh data latih yang diproses dengan metode undersampling lebih rendah. Nilai rata- rata tertinggi akurasi, presisi, dan recall dari data uji yang dikenai proses oversampling lebih tinggi dibandingkan dengan nilai rata- rata tertinggi data uji yang dikenai proses undersampling.Keywords : undersampling; oversampling; Spreadsubsample; SMOTE; BackwardGreedy Stepwise; NBC",
        "43"
    ],
    [
        "Sistem rekomendasi calon pembimbing tugas akhir Program Studi Informatika Universitas Sebelas Maret  menggunakan self organizing map (som",
        "Tugas Akhir merupakan karya ilmiah yang disusun oleh mahasiswaberdasarkan hasil penelitian laboratorium, penelitian lapangan dan atau kajian suatuteori dengan bimbingan pembimbing, untuk dipertahankan di hadapan pengujisebagai syarat untuk memperoleh gelar sarjana. Maka dari itu, peran dosenpembimbing tugas akhir tentunya sangat penting. Dosen pembimbing harusmenguasai bidang pada tugas akhir mahasiswa agar proses bimbingan dapatberjalan lancar. Proses seorang dosen menjadi pembimbing tugas akhir mahasiswayaitu sebelumnya harus menjadi penguji pada seminar proposal tugas akhir.Penelitian ini bertujuan untuk membangun sistem rekomendasi dosen penguji untukseminar proposal tugas akhir dengan memertimbangkan beban kerja dosen.Penelitian ini menerapkan teknik Content-based Filtering untuk perekomendasiandan mengunakan metode Self Organizing Map (SOM) dengan tujuan mereduksijumlah perbandingan pada saat proses prediksi. Hasil penelitian menunjukkanbahwa hasil rekomendasi dengan akurasi tertinggi terdapat pada inisialisasi SOMmatriks dengan ukuran 14x14 dengan nilai akurasi 51,19% mengunakan subset dan89% menggunakan expert judgment.\u00a0\u00a0\u00a0Kata Kunci: Sistem Rekomendasi, Self-Organizing Map, Content-Based\u00a0Filtering, Silhouette Coefficient",
        "44"
    ],
    [
        "Pengembangan question answering system berbasis ontologi menggunakan metode rule based pada tanaman obat tradisional Indonesia",
        "Indonesia dengan beribu suku dan etnis memiliki keberagaman budaya, termasuk pengetahuan lokal dan cara tradisional dalam menggunakan tanaman obat. Peluang untuk menjadikan tanaman obat tradisional sebagai bahan obat masih banyak. Dari 9.600 spesies tanaman yang memiliki potensi menjadi bahan obat, baru 300 spesies yang telah digunakan sebagai bahan obat. Perlu adanya sosialisasi dan penyajian informasi terkait tanaman obat tradisional Indonesia sebagai solusi industri farmasi di Indonesia. Oleh karena itu, Question Answering System atau sistem tanya jawab dibuat untuk menjawab pertanyaan dari pengguna terkait tanaman obat. Sistem yang diberi nama Tanaman Obat Tradisional Indonesia (TOTI) ini menggunakan metode rule based untuk penelusuran jawaban berdasarkan pertanyaan dan ontologi sebagai pengetahuan dari tanaman obat tradisional Indonesia untuk mendukung keabsahan atau validitas jawaban yang diberikan. Waktu respon membuka sistem rata-rata sebesar 701,67 ms dan persentase respon rata-rata sebesar 84,02%. Akurasi sistem berdasarkan pengujian tercatat sebesar 95,96%.Kata Kunci: Traditional medicinal plants, Question Answering System, Ontology",
        "45"
    ],
    [
        "Prototipe smart home dalam prediksi hujan menggunakan algoritma jaringan saraf tiruan",
        "Perubahan cuaca yang tidak menentu merupakan suatu keadaan dimanakondisi cuaca mengalami perubahan yang sulit diprediksi. Hal ini menimbulkanpermasalahan bagi manusia dalam melakukan aktivitasnya terutama dalam halmenjemur pakaian. Salah satu solusi untuk menyelesaikan permasalahan tersebutadalah dengan menerapkan sistem teknologi smart home yang mampu memprediksicuaca. Sistem ini menggunakan lima atribut utama dalam memprediksi cuaca,antara lain suhu, kelembaban, tekanan udara, kecepatan angin, dan intensitascahaya. Data yang dikumpulkan dari kelima atribut tersebut diproses menggunakanalgoritma Jaringan Saraf Tiruan Backpropagation. Sistem dimodelkan denganprototipe atap rumah dan sebuah servo sebagai prototipe dari penggerak jemuran.Apabila cuaca tidak hujan maka servo akan menggerakkan jemuran ke luar dariatap rumah dan apabila kondisi cuaca berubah menjadi hujan maka servo akan\u00a0menggerakan jemuran untuk berada di bawah atap. Hasil dari penelitian ini adalah\u00a0kemampuan sistem dalam memprediksi hujan dengan pengujian yang dilakukanmenghasilkan nilai akurasi sebesar 0.72456 dan 0.82622 untuk data kelas \u201cTidakHujan \u2013 Akan Hujan\u201d dan data kelas \u201cHujan \u2013 Tidak Hujan\u201d.Kata kunci: smart home, sistem prediksi hujan, jaringan saraf tiruan,backpropagation",
        "46"
    ],
    [
        "Klasifikasi leukosit terinfeksi virus demam berdarah dengue pada citra mikroskopis dengan support vector machine berdasarkan histogram citra  ",
        "ABSTRAKDeteksi virus dengue metode imunistiokimia streptavidin biotin complex yang diaplikasikan pada apusan darah tebal dan tipis memiliki masalah pada awal infeksi karena jumlah leukosit yang rendah di hari pertama infeksi. Untuk membantu pendeteksian infeksi virus, penelitian ini mengembangkan sistem otomatis untuk menghitung leukosit dan mengklasifikasi leukosit terinfeksi pada citra mikroskopis menggunakan support vector machine berbasis histogram citra. Pengolahan citra digunakan untuk mendeteksi sel dengan menggunakan Gram-Schmidt Orthogonalization sebagai konversi citra ke grayscale berkontras tinggi, median filter untuk pelembutan citra, Otsu threshold untuk proses segmentasi, morfologi citra dan circularity filter untuk pembersihan noise yang tidak diinginkan pasca segmentasi. Selanjutnya klasifikasi sel terinfeksi menggunakan support vector machine menggunakan vektor ciri dari histogram citra setiap sel. Hasil penelitian ini adalah support vector machine berbasis histogram citra dapat mengklasifikasi leukosit terinfeksi dengan akurasi sebesar 83.94%.Kata kunci: Leukosit terinfeksi virus dengue, Immunositokimia SBPC, Pengolahan Citra, Support Vector Machine\u00a0",
        "47"
    ],
    [
        "Undersampling Majority Class pada Kasus Imbalanced Dataset dan Aplikasinya Pada Deteksi Anomali Transaksi Kartu Kredit",
        "ABSTRAKKartu kredit adalah salah satu sistem pembayaran yang banyak digunakan di seluruh dunia. Tetapi sistem keamanan kartu kredit masih rentan terjadi fraud. Salah satu cara untuk mengatasi fraud adalah menggunakan machine learning dengan metode anomaly detection. Anomaly detection adalah metode pencarian pola yang janggal pada suatu keadaan. Metode tersebut dapat dilakukan dengan menggunakan algoritma klasifikasi. Masalah yang sering terjadi dalam klasifikasi adalah terjadinya imbalanced dataset, yaitu keadaan class tujuan yang diklasifikasi tidak seimbang rasionya. Masalah ini dapat menyebabkan hasil klasifikasi menjadi bias karena classifier lebih sering mendeteksi kelas mayoritas dibanding kelas minoritas. Imbalanced dataset dapat diatasi dengan menggunakan metode undersampling. Penelitian ini bertujuan untuk menangani imbalanced dataset dengan metode undersampling K Nearest Neighbors-Undersampling pada deteksi anomali transaksi kartu kredit dengan classifier Support Vector Machine dan K-Nearest Neighbors agar menghasilkan performa prediksi yang optimal. K Nearest Neighbors-Undersampling mengurangi kelas mayoritas dari 199013 menjadi 367, 661, 949, 1244, dan 1574 dengan variasi nilai K 4, 8, 12, 16, dan 20 secara berturut-turut. Metode K Nearest Neighbors mampu meningkatkan nilai true positive dan mengurangi nilai false negative. Hasil penelitian menunjukkan performa terbaik dihasilkan 20NN-Und + Support Vector Machine parameter C = 1 bekerja paling optimal dengan nilai precision 0.95 dan recall 0.75 dalam waktu 4.51 detik.Kata kunci : anomaly detection, undersampling, imbalanced dataset, fraud",
        "48"
    ],
    [
        "Klasifikasi keluhan pelanggan berbasis twitter menggunakan metode Support Vector Machine(SVM) (Studi kasus : Pos Indonesia)",
        "\u00a0Penanganan keluhan merupakan hal yang mutlak pada sebuah perusahaan. Pos\u00a0 Indonesia\u00a0 merupakan\u00a0 BUMN\u00a0 yang\u00a0 bergerak\u00a0 dalam\u00a0 jasa\u00a0 pengiriman\u00a0 barang yang\u00a0 memanfaatkan\u00a0 twitter\u00a0 sebagai\u00a0 salah\u00a0 satu\u00a0 media\u00a0 layanan\u00a0 customer\u00a0 service. Disini admin akan menjawab dan menyelesaikan keluhan pelanggan yang mention atau\u00a0 direct\u00a0 message\u00a0 ke\u00a0 akun\u00a0 twitter\u00a0 @PosIndonesia\u00a0 secara\u00a0 manual.\u00a0 Salah\u00a0 satu kelemahan penyampaian keluhan melalui twitter adalah tweet berbentuk teks digital yang\u00a0 tidak\u00a0 terstruktur\u00a0 sehingga\u00a0 menyulitkan\u00a0 untuk\u00a0 menyalurkan\u00a0 ke\u00a0 bidang permasalahan\u00a0 yang\u00a0 ada\u00a0 untuk\u00a0 segera\u00a0 ditangani.\u00a0 Belum\u00a0 lagi\u00a0 banyaknya\u00a0 jumlah keluhan dan terdapatnya keluhan yang bermaksud sama dari beberapa pelanggan. Berdasarkan permasalahan tersebut, penelitian ini bertujuan mengelompokkan data tweet\u00a0 menjadi\u00a0 beberapa\u00a0 kategori\u00a0 keluhan\u00a0 yaitu\u00a0 keterlambatan,\u00a0 kesalahan\u00a0 sistem, gagal\u00a0 kirim,\u00a0 jaminan\u00a0 barang,\u00a0 pelayanan\u00a0 petugas,\u00a0 dan\u00a0 kecepatan\u00a0 respon.\u00a0 Metode yang\u00a0 digunakan\u00a0 pada\u00a0 penelitian\u00a0 ini\u00a0 yaitu\u00a0 feature\u00a0 extraction\u00a0 menggunakan\u00a0 term frequency\u2013inverse\u00a0 document\u00a0 frequency\u00a0 (TF-IDF)\u00a0 dan\u00a0 klasifikasi\u00a0 menggunakan Support\u00a0 Vector\u00a0 Machine\u00a0 (SVM).\u00a0 Kemudian\u00a0 dibandingkan\u00a0 kernel\u00a0 linear, polynomial, dan RBF serta mencari parameter terbaik pada masing- masing kernel. Pengujian menggunakan 10-fold cross validation dengan mencari akurasi, presisi, recall,\u00a0 dan\u00a0 f1-score\u00a0 menggunakan\u00a0 confussion\u00a0 matrix.\u00a0 Hasil\u00a0 percobaan menunjukkan\u00a0 bahwa\u00a0 nilai\u00a0 rata-rata\u00a0 akurasi\u00a0 tertinggi\u00a0 menggunakan\u00a0 kernel\u00a0 linear yaitu\u00a0 81,26%\u00a0 \u00a0 diikuti\u00a0 oleh\u00a0 kernel\u00a0 RBF\u00a0 81,44%\u00a0 dan\u00a0 terakhir\u00a0 polynomial\u00a0 67,12%. Sedangkan untuk precision, recall,\u00a0 dan f1-score nilai tertinggi yaitu menggunakan kernel\u00a0 linear\u00a0 yaitu\u00a0 masing-\u00a0 masing\u00a0 90%,\u00a0 89%,\u00a0 dan\u00a0 89%.\u00a0 Sehingga\u00a0 dapat\u00a0 ditarik kesimpulan\u00a0 bahwa\u00a0 data\u00a0 keluhan\u00a0 pada\u00a0 tweet\u00a0 akun\u00a0 Pos\u00a0 Indonesia\u00a0 dapat diklasifikasikan dengan baik menggunakan kernel linear.\u00a0 \u00a0Kata kunci: klasifikasi text, twitter, keluhan, Support Vector Machine. tf-idf\u00a0",
        "49"
    ],
    [
        "Prediksi prestasi dan waktu kelulusan mahasiswa menggunakan algoritma c4.5",
        "Evaluasi prestasi mahasiswa diwakili dengan nilai Indeks Prestasi\u00a0 Kumulatif (IPK) dan lamanya mahasiswa menyelesaikan masa studi. Prediksi prestasi mahasiswa yang diwakili oleh IPK dan waktu kelulusan menjadi penting bagi universitas dikarenakan universitas dapat mengantisipasi mahasiswa yang membutuhkan pembelajaran tambahan sejak dini (tahun pertama) guna meningkatkan kinerja mahasiswa. Penelitian ini dilakukan untuk menyelidiki akurasi penggunaan algoritma C4.5 dalam membangun model decision tree prediksi kelas prestasi (IPK) dan kelas waktu kelulusan mahasiswa.Parameter data yang digunakan adalah data demografis dan Indeks Prestasi (IP) tahun ajaran pertama mahasiswa Universitas Sebelas Maret. Data dibagi berdasarkan rumpun ilmunya, yaitu ilmu pengetahuan alam dan ilmu pengetahuan sosial karena setiap ilmu pengetahuan memiliki ukuran standar penilaian yang berbeda. Model dibangun dengan data training\u00a0 hasil kombinasi dari (1) kelas prediksi Indeks Prestasi Kumulatif (IPK), (2)\u00a0 kelas prediksi waktu kelulusan, (3) data mahasiswa ilmu sains, (4) data mahasiswa ilmu sosial. Data training memiliki imbalanced class sehingga teknik oversampling dan pruning diimplementasikan ke dalam kombinasi data training. Sehingga, data training yang digunakan berjumlah sebanyak 8 jenis data. Hasil pengujian sebelum dan setelah oversampling dan pruning akan dibandingkan untuk mencari pengaruh terhadap akurasi model decision tree.\u00a0Hasil penelitian menunjukkan model decision tree terbaik untuk mengklasifikasikan kelas IPK dibangun menggunakan data mahasiswa sains. Model data sains untuk klasifikasi kelas ipk (akurasi: 72.94%, precision : 0.700, recall : 0.729. Sedangkan untuk model decision tree terbaik untuk mengklasifikasikan kelas waktu kelulusan adalah data mahasiswa sosial. Model data sosial untuk klasifikasi kelas lulus (akurasi : 75.45%, precision : 0.739, dan recall : 0.755).\u00a0 Penelitian ini menunjukkan penggunaan oversampling menurunkan nilai akurasi. Namun sebaliknya, penggunaan pruning pada model berhasil menaikan nilai akurasi model decision tree.\u00a0Kata Kunci : C4.5, data mining, kelulusan mahasiswa, klasifikasi, prestasi mahasiswa",
        "50"
    ],
    [
        "Perbandingan kinerja k-means dan  s-k-means clustering untuk data berdimensi tinggi",
        "\u00a0Penelitian yang dilakukan Chakraborty & Das pada tahun 2017 menjelaskan mengenai berbagai synthetic\u00a0 dan\u00a0 real-life\u00a0 data set yang mengindikasikan bahwa hasil simulasi S-k-means\u00a0 memiliki performa lebih baik dibandingkan dengan K- means konvensional (K-means dengan metrik Euclidean distance) dan W-k-means (K-means\u00a0 dengan\u00a0 penambahan boot/weight)\u00a0 pada situasi tertentu. Sehingga pada penelitian ini dilakukan perbandingan kinerja K-means\u00a0 konvensional\u00a0 dan\u00a0 S-k- means\u00a0 pada beberapa data.\u00a0 Data yang diuji coba merupakan data dengan jumlah atribut\u00a0 yang\u00a0 lebih banyak.\u00a0 Perbandingan kinerja dilakukan dengan evaluasi Adjusted Rand Index (ARI). Hasilnya, data set yang memiliki jumlah atribut yang sama dengan penelitian sebelumnya, S-k-means\u00a0 memiliki kinerja lebih baik dibandingkan dengan K-means\u00a0 berdasarkan nilai maksimum\u00a0 ARI\u00a0 yang didapat. Sedangkan, pada data set dengan jumlah atribut yang lebih besar, kinerja K-means dengan\u00a0 S-k-means\u00a0 tidak jauh berbeda\u00a0 berdasarkan nilai maksimum\u00a0 ARI yang didapat. Kata Kunci: S-distance, S-k-means clustering, Adjusted Rand Index (ARI)\u00a0",
        "51"
    ],
    [
        "Analisis pemodelan topik pada artikel berita menggunakan metode latent dirichlet allocation",
        "ABSTRAK Berita\u00a0 merupakan\u00a0 sebuah\u00a0 informasi\u00a0 berupa\u00a0 fakta\u00a0 atau\u00a0 pendapat\u00a0 seseorang\u00a0 yang berasal dari sebuah kejadian/peristiwa yang sifatnya menarik untuk diketahui dan dimuat\u00a0 melalui\u00a0 media\u00a0 massa,\u00a0 termasuk\u00a0 portal\u00a0 online\u00a0 berita.\u00a0 Dalam\u00a0 menemukan topik tersembunyi yang terdapat dalam kumpulan artikel berita salah satu metode yang\u00a0 cepat\u00a0 dan\u00a0 efisien\u00a0 adalah\u00a0 pemodelan\u00a0 topik,\u00a0 dan\u00a0 Latent\u00a0 Dirichlet\u00a0 Allocation (LDA)\u00a0 merupakan\u00a0 salah\u00a0 satunya.\u00a0 Tahap-tahap\u00a0 dalam\u00a0 penelitian\u00a0 ini\u00a0 antara\u00a0 lain pengumpulan\u00a0 data,\u00a0 text\u00a0 preprocessing,\u00a0 pemodelan\u00a0 topik,\u00a0 dan\u00a0 analisis\u00a0 hasil. Pemodelan topik dengan metode LDA mengasilkan 8 topik sebagai jumlah topik terbaik berdasarkan nilai perplexity terendah dengan nilai perplexity 3087,927 dan berdasarkan\u00a0 hasil\u00a0 analisa\u00a0 model\u00a0 dari\u00a0 dua\u00a0 eksperimen\u00a0 yang\u00a0 dilakukan\u00a0 yaitu eksperimen\u00a0 terkait\u00a0 dengan\u00a0 jumlah\u00a0 passes\u00a0 dan\u00a0 eksperimen\u00a0 terkait\u00a0 dengan\u00a0 jumlah topik.\u00a0Kata kunci: pemodelan topik, Latent Dirichlet Allocation\u00a0",
        "52"
    ],
    [
        "Low rank minimization pada gambar berwarna untuk image denoising",
        "Tujuan dari penelitian ini adalah mempresentasikan metode Low Rank Minimization untuk melakukan denoising pada gambar berwarna. Proses pendekomposisian gambar berwarna dilakukan dengan memisahkan masing-masing warna primer dalam gambar berdasarkan warna RGB (merah, hijau, dan biru). Masing-masing channel warna hasil pendekomposisian kemudian diproses dengan patch grouping, rank minimization via singular value decomposition, dan aggregation. Metode iterative regularization juga diaplikasikan untuk mereduksi residu noise yang tersisa pada denoised image. Seluruh channel warna RGB yang telah diproses kemudian dikombinasikan kembali sehingga menjadi satu gambar berwarna yang utuh. PSNR kemudian digunakan untuk menghitung kualitas gambar hasil proses denoising. Hasil dari percobaan menunjukkan bahwa dengan nilai sigma yang sama pada AWGN, nilai PSNR pada gambar berwarna sedikit lebih rendah dibandingkan dengan gambar grayscale-nya, tetapi nilai antar keduanya tidak terpaut jauh.Kata Kunci: Image Denoising, Rank Minimization, Additive White Gaussian Noise, Singular Value Decomposition",
        "53"
    ],
    [
        "Sistem Rekomendasi Peminjaman Buku di UPT Perpustakaan UNS dengan Metode Item-Based Collaborative Filtering dan Rating Implisit",
        "ABSTRAKPerpustakaan merupakan salah satu penunjang penting dalam institusi pendidikan. Pelayanan utama perpustakaan adalah memfasilitasi transaksi peminjaman buku. Untuk memudahkan para anggotanya menemukan buku yang tepat, perpustakaan seringkali dilengkapi dengan sistem pencarian buku. Tetapi sistem pencarian buku saja tidak cukup membantu untuk menemukan buku yang tepat bagi anggota yang belum menentukan buku yang akan dipinjam. Masalah tersebut dapat diatasi dengan sistem rekomendasi. Item-based Collaborative Filtering merupakan salah satu metode sistem rekomendasi yang dapat memberikan rekomendasi secara personal bagi user. Pada penelitian ini, Item-based Collaborative Filtering dengan menggunakan rating implisit diterapkan untuk membuat sistem rekomendasi peminjaman buku di UPT Perpustakaan UNS. Pengujian dilakukan dengan mengosongkan rating mulai dari 10%, 20%, 30%, 40%, dan 50%, dengan 40 kali perulangan percobaan pada setiap pengosongan rating. Berdasarkan hasil pengujian,\u00a0 metode\u00a0 Item-based\u00a0 Collaborative\u00a0 Filtering\u00a0 dengan\u00a0 menggunakan rating implisit menghasilkan rata-rata accuracy, precision, dan recall masing- masing 0,9640; 0,5028; dan 0,5264 pada setiap level pengosongan rating.Kata kunci: Item-based Collaborative Filtering, Na\u00efve Bayes, Rating Implisit, Sistem Rekomendasi Peminjaman Buku\u00a0",
        "54"
    ],
    [
        "Symmetrical Singular Value Decomposition RepresentationpPada Citra Wajah Iluminasi Berbasis Gabor Filter untuk Pengenalan Wajah",
        "ABSTRAK\u00a0Tujuan dari penelitian ini yaitu mempresentasikan metode Symmetrical Singular Value\u00a0 Decomposition\u00a0 Representation\u00a0 (SSVDR)\u00a0 dengan\u00a0 Gabor\u00a0 Filter\u00a0 sebagai Feature Extraction pada citra wajah illuminasi untuk pengenalan wajah. Metode SSVDR\u00a0 dilakukan\u00a0 untuk\u00a0 menormalisasi\u00a0 citra wajah\u00a0 yang\u00a0 gelap\u00a0 akibat\u00a0 dari\u00a0 efek illuminasi dengan memunculkan sebagian ciri wajah yang gelap sesuai dengan citra wajah yang simetris dengan memanfaatkan Singular Value Decomposition (SVD). Untuk melakukan pengenalan wajah dilakukan dengan teknik Principal Component Analysis (PCA) dan Linear Discriminant Analysis (LDA) dengan metode klasifikasi menggunakan Nearest Neighbor. Teknik PCA dan LDA digunakan untuk merepresentasikan\u00a0 data\u00a0 dimensi\u00a0 tinggi\u00a0 ke\u00a0 dalam\u00a0 dimensi\u00a0 yang\u00a0 lebih\u00a0 rendah, sedangkan metode Nearest Neighbor digunakan untuk mengidentifikasi seseorang berdasarkan jarak data terdekat. Hasil pengenalan citra wajah menggunakan SSVDR berbasis Gabor Filter dengan metode PCA diperoleh akurasi sebesar 91.86%. Sedangkan pengenalan citra wajah menggunakan SSVDR berbasis Gabor Filter dengan metode LDA diperoleh akurasi sebesar 91.57%.Keywords: Face Recognition, SSVDR, Gabor Filter.\u00a0",
        "55"
    ],
    [
        "Sukoharjo Dengan Process Mining",
        "ABSTRAK\u00a0Suatu bidang usaha perlu melakukan evaluasi untuk mengembangkan pelayanan dan dapat beradaptasi dengan perubahan lingkungan. Evaluasi proses bisnis merupakan salah satu cara untuk melakukan pengembangan bisnis. Makalah ini memberikan laporan tentang penelitian terhadap proses pelayanan BPJS Rawat Jalan di RSUD Sukoharjo dengan menggunakan process mining untuk mendapatkan model proses yang objektif. Kami melakukan implementasi pendekatan Inductive Miner- infrequent dan melakukan analisis terhadap model proses dengan conformance checking serta performance analysis. Hasil evaluasi dapat dimanfaatkan oleh para pemangku kepentingan di RSUD Sukoharjo sebagai bahan pertimbangan untuk mengetahui kondisi pelayanan BPJS rawat jalan RSUD Sukoharjo serta sebagai bahan pertimbangan dalam melakukan pengembangan pelayanan. Dapat diketahhui bahwa alur proses pelayanan rawat jalan pasien BPJS Sukoharjo sudah sesuai dengan prosedur administrasi namun terdapat persoalan dalam penyimpanan data di sistem informasi. Terdapat juga risiko bottleneck pada (1) antrean registrasi pasien dengan rata-rata waktu 1,5-2 jam, (2) antrean pelayanan poliklinik dengan rata-rata waktu 1-2 jam, dan (3) antrean waktu tunggu pelayanan farmasi dengan rata-rata waktu 0,5\u20131 jam.Kata kunci\u2014 evaluasi, process mining, proses bisnis\u00a0",
        "56"
    ],
    [
        "Analisis Sentimen Masyarakat pada Media Sosial Twitter terhadap Pilkada Dki Jakarta 2017 dengan Pendekatan Prediktif dan Deskriptif",
        "ABSTRAKTujuan utama dari penelitian ini adalah untuk menganalisis sentimen dari Pilkada DKI Jakarta 2017 pada media sosial Twitter dengan pendekatan prediktif dan deskriptif. Dataset diambil dari Twitter dengan menggunakan username Twitter dari tiap calon gubernur sebagai search query. Untuk pendekatan prediktif, algoritma machine learning seperti Multinomial Naive Bayes dan Support Vector Machine digunakan untuk mengklasifikasi dataset. Sedangkan untuk pendekatan deskriptif, grafik time- series dan wordclouds digunakan untuk mendapatkan gambaran lebih dalam dari dataset dan menemukan hubungan keterkaitan antara sentimen pada Twitter dengan hasil dari Pilkada itu sendiri. Untuk pendekatan prediktif, hasil terbaik diperoleh saat menggunakan Support Vector Machine (dengan menggunakan seluruh fitur), dengan akurasi sebesar 69.11%. Sedangkan untuk pendekatan deskriptif, diperoleh beberapa keterkaitan antara grafik time-series dan wordcloud dengan hasil dari pilkada.Keywords: Sentiment Analysis, Natural Language Processing, Machine Learning, Data Mining\u00a0",
        "57"
    ],
    [
        "Aplikasi Peramalan Jumlah Kunjungan Pasien Poliklinik Paru RSUD Sukoharjo Menggunakan Double Exponential Smoothing Holt",
        "ABSTRAKPada RSUD Sukoharjo seringkali terjadinya antrian panjang pasien poliklinik paru karena terbatasnya sumber daya manusia dalam menangani jumlah pasien yang terus meningkat. Untuk mengatasi hal ini diperlukan pengambilan keputusan yang baik terhadap pemenuhan kebutuhan sumber daya manusia yang dapat didukung dengan diketahuinya ramalan jumlah kunjungan pasien pada periode mendatang. Penelitian ini membangun aplikasi peramalan dengan metode Double Exponential Smoothing (DES) Holt yang nilai awal pemulusannya dapat ditentukan melalui empat cara berbeda, dimana hasil dari aplikasi berupa ramalan banyak kunjungan pasien poliklinik paru RSUD Sukoharjo pada periode mendatang beserta dengan akurasinya yang diukur menggunakan MAE, MSE, dan MAPE. Penggunaan dari empat cara penentuan nilai awal pemulusan tersebut memberikan hasil peramalan yang berbeda. Diperoleh model peramalan dengan tingkat kesalahan MAE, MSE, dan MAPE terendah pada penggunaan cara penentuan nilai awal pemulusan 4, sedangkan prediction error yang diukur menggunakan MAPE menunjukkan nilai terendah pada cara penentuan nilai awal pemulusan 2.Kata Kunci: Peramalan, Double Exponential Smoothing (DES) Holt\u00a0",
        "58"
    ],
    [
        "Implementasi Algoritma Apriori untuk Menganalisa Pola Data Awal Siswa dengan Nilai Ujian Akhir Siswa dan Kemampuan Agamanya. (Studi Kasus: SMPIT Nur Hidayah Surakarta)",
        "ABSTRAKSetiap tahunnya SMPIT Nur Hidayah menerima dan meluluskan siswa yang jumlahnya tidak sedikit. Data tersebut akan semakin bertambah dan tidak memiliki nilai yang strategis apabila tidak dianalisa secara maksimal.\u00a0\u00a0 Dalam penelitian ini mencari pola-pola menarik dalam data tersebut sehingga dapat digunakan untuk meningkatkan kualitas pendidikan.Dalam penelitian ini digunakan data mining, menggunakan metode Association\u00a0 Rule\u00a0 Mining\u00a0 dengan\u00a0 Algoritma\u00a0 Apriori\u00a0 digunakan\u00a0 untuk mendapatkan pola hubungan antara keadaan orang tua dan nilai anak. Data yang digunakan\u00a0 merupakan\u00a0 data\u00a0 orang\u00a0 tua\u00a0 dan\u00a0 data\u00a0 siswa\u00a0 angkatan\u00a0 2012,\u00a0 ketika mereka masuk dan lulus dari sekolah.Dari penelitian ini Ada 53 rule yang terbentuk, yang terdiri dari 50 rule yang confidencenya mulai dari 0,7 sampai dengan 0,8 dan tiga rule diatas 0,8 dengan consequent PAI A, PAI B, UAN A dan UAN B. Setelah dilakukan eliminasi diperoleh 19 rule yang consequent-nya terkait PAI dan 23 rule yang consequent-nya terkalit UAN. Dengan network analysis diperoleh informasi sebagai berikut: 1) bila dilihat dari nodenya pendidikan ibu B dan PAI B merupakan atribut yang banyak kemunculannya dan dominan dalam rule yang muncul. 2) Kemudian dilihat dari kuat edgenya diperoleh hubungan yang dominan dalam rule yang ada, diantaranya PAI_B dengan Laki-laki, Pendidikan ibu B dengan UAN_A, Baca Qur\u2019an Ayah B dengan UAN_A,\u00a0 Perempuan dengan UAN A, Asal SD A dengan UAN A, jarak B dengan Asal SD A, Gaji orang tua B dengan Perempuan.Kata kunci\u00a0 \u2013 Apriori,\u00a0 Association Rule, Data Orang Tua, Data Siswa,\u00a0 DataMining\u00a0",
        "59"
    ],
    [
        "Klasifikasi Emosi Konsumen Menggunakan Metode Na\u00efve Bayes Classifier (Studi Kasus: Natasha Skin Care)",
        "ABSTRAKDewasa ini konsumen dapat dengan mudah menyampaikan review atau pendapatnya terhadap suatu produk atau jasa dari Natasha Skin Care melalui mentions @NatashaSkinCare. Dari mentions tersebut dapat dikenali emosi konsumen setelah menggunakan produk atau jasa dari Natasha Skin Care. Penelitian ini bertujuan untuk melakukan klasifikasi emosi menurut Ekman yaitu joy, surprise, anger, fear, sad, dan disgust dengan menggunakan Na\u00efve Bayes Classifier. Na\u00efve Bayes Classifier dipilih karena memiliki kelebihan yaitu sederhana, cepat, dan berakurasi tinggi. Dataset pada penelitian ini berjumlah 19.253 dengan pembagian untuk setiap kelasnya adalah 804 joy, 43 surprise,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 154 anger, 61 fear, 287 sad, 167 disgust, dan 17736 no-emotions. Hasil penelitian menunjukkan bahwa metode Na\u00efve Bayes Classifier memiliki kinerja yang baik untuk mengklasifikasikan emosi konsumen Natasha Skin Care melalui jejaring sosial twitter. Rata-rata tingkat accuracy pada dataset tanpa kelas no-emotions adalah 80,19%. Rata-rata pada klasifikasi emosi tanpa melibatkan kelas\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 no-emotions menunjukkan nilai recall tertinggi pada kelas joy yaitu sebesar 92,21%. Nilai precision tertinggi pada kelas surprise yaitu sebesar 97,77?n nilai F1-Measure tertinggi terdapat pada kelas joy sebesar 89,14%. Sedangkan rata-rata pada dataset dengan kelas no-emotions adalah 88,58%. Walaupun accuracy pada dataset dengan kelas no-emotions lebih tinggi, tetapi nilai precision dan recall-nya sangatlah rendah yaitu mencapai nilai 0%. Setelah menggunakan algoritma resampling ROS, rata-rata nilai precision, recall, dan\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 F1-Measure tertinggi terdapat pada kelas no-emotions. Yaitu precision bernilai 96,64%, recall bernilai 76,36%, dan F1-Measure bernilai 85,93%.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0Kata kunci: klasifikasi emosi, na\u00efve bayes classifier, resampling\u00a0",
        "60"
    ],
    [
        "Perbandingan Algoritma Rsa dan Elgamal pada Keamanan Data Sidik Jari",
        "\u00a0ABSTRAKAnalisis Algoritma membantu kinerja sebuah program melalui uji dengan mengukur running proses dan kemanan menentukan operasi dan fungsi yang dominan digunakan. Pada Penelitian tugas akhir yang dibahas adalah membandingkan keamanan RSA dan Elgamal yang diimplementasikan pada data sidik jari, enkripsi RSA dan Elgamal digunakan untuk menjaga keamanan dan kerahasiaan data. Dalam tugas akhir ini, dibahas perbandingan kinerja antara algoritma RSA dan Elgamal dengan data sidik jari 20,41,62,85 dan 100, dalam runtime algoritma RSA lebih efisien dari pada algoritma Elgamal. RSA membutuhkan waktu enkripsi dan dekripsi 0,061 detik dan 0,084 detik, sedangkan algoritma elgamal memerlukan waktu enkripsi 0,155 detik dan dekripsi 0,298 detik dengan menjalankan 20 data sidik jari. Serangan Cracking digunakan untuk menguji kedua algoritma dan ditemukan bahwa kedua algoritma keamanan plaintext tidak dapat melindungi data sidik jari.\u00a0Kata Kunci : Algoritma RSA, Elgamal, Running Time, Keamanan dan sidik jari.\u00a0",
        "61"
    ],
    [
        "Sistem Rekomendasi dengan Metode Content-Based Filtering untuk Wisata Kuliner pada Aplikasi Mangan",
        "Wisata kuliner menjadi salah satu tren masa kini di dalam dunia kuliner. Banyaknya informasi yang beredar tidak serta merta membuat para wisatawan kuliner menjadi semakin mudah dalam menentukan pilihan menu hidangan yang diinginkan. Penggunaan mesin pencarian saja dirasa masih belum cukup, sehingga diperlukan sebuah sistem rekomendasi yang dapat memberikan saran sesuai dengan kebutuhan pengguna.Metode content-based filtering mampu menghasilkan rekomendasi yang bersifat user independence, sehingga cocok digunakan untuk penyedia informasi kuliner yang sedang berkembang seperti pada studi kasus aplikasi MANGAN dimana jumlah penggunanya masih sedikit dan data kulinernya akan selalu bertambah. Metode ini merekomendasikan beberapa objek berdasarkan kemiripan objek yang dipilih dengan objek yang direkomendasikan. Kemiripan objek dihitung dengan menggunakan fungsi cosine similarity berdasarkan item profile yang dibentuk dari fitur konten sebuah restoran.Pengujian dilakukan terhadap hasil rekomendasi dengan tiga threshold yang berbeda, didapatkan rata-rata nilai presisi sebesar 0,8915 dan rata-rata nilai akurasi sebesar 0,5118. Rendahnya nilai akurasi, disebabkan karena adanya kesalahan sistematika. Hasil dari penelitian ini adalah metode content-based filtering dapat digunakan untuk membantu pengguna dalam memilih restoran berdasarkan kemiripan item profile dari suatu restoran.\u00a0",
        "62"
    ],
    [
        "Deteksi Plagiarisme Skripsi Mahasiswa dengan Metode Single-Link Clustering dan Jaro-Winkler Distance",
        "Maraknya plagiarisme adalah salah satu dampak negatif dari perkembangan teknologi informasi dan komunikasi. Plagiarisme dapat terjadi di mana saja salah satu contohnya adalah perguruan tinggi dengan objek plagiarisme tugas akhir mahasiswa. Sehingga dibutuhkan sistem untuk mendeteksi plagiarisme sehingga dapat menekan adanya plagiarisme di lingkungan perguruan tinggi. Dalam mendeteksi kemiripan suatu tulisan akan lebih cepat apabila tulisan telah dikelompokkan sebelum dibandingkan satu sama lain, Single-link clustering dipilih karena memiliki algoritma yang sederhana dan dapat diimplementasikan tanpa inisial cluster. Dalam melakukan plagiarisme penjiplak biasanya mengubah susunan kalimat sehingga terlihat berbeda jaro-winkler distance dipilih karena dapat mendeteksi kemiripan pada paragraf yang telah diubah susunan kalimatnya karena jaro-winkler distance memiliki indexing yang fleksibel dengan jarak teoritis agar suatu kata atau karakter dianggap sama. Tahap-tahap dalam penelitian ini antara lain pengumpulan data, preprocessing, mengelompokkan tulisan dengan Single-link clustering, membandingkan tulisan dengan jaro-winkler distance, dan testing dengan precision dan recall. Setelah dilakukan pengujian diperoleh nilai rata-rata precision sebesar 84.37?n recall sebesar 84.37?ngan tingkat plagiarisme sebesar 99.1%.<!--[if gte mso 9]><xml>    </xml><![endif]--><!--[if gte mso 9]><xml>  Normal 0     false false false  EN-US X-NONE AR-SA                         </xml><![endif]--><!--[if gte mso 9]><xml>                                                                                                                                            </xml><![endif]--><!--[if gte mso 10]> <style> /* Style Definitions */ table.MsoNormalTable {mso-style-name:\"Table Normal\"; mso-tstyle-rowband-size:0; mso-tstyle-colband-size:0; mso-style-noshow:yes; mso-style-priority:99; mso-style-parent:\"\"; mso-padding-alt:0cm 5.4pt 0cm 5.4pt; mso-para-margin-top:0cm; mso-para-margin-right:0cm; mso-para-margin-bottom:8.0pt; mso-para-margin-left:0cm; line-height:107%; mso-pagination:widow-orphan; font-size:11.0pt; font-family:\"Calibri\",\"sans-serif\"; mso-ascii-font-family:Calibri; mso-ascii-theme-font:minor-latin; mso-hansi-font-family:Calibri; mso-hansi-theme-font:minor-latin; mso-bidi-font-family:Arial; mso-bidi-theme-font:minor-bidi;} </style> <![endif]-->",
        "63"
    ],
    [
        "Fitur Rekomendasi Artikel Ilmiah pada Open Journal System Menggunakan Content-Based Filtering",
        "Open Journal System (OJS) adalah sebuah platform jurnal online bersifat opensource\u00a0yang saat ini banyak digunakan oleh perguruan tinggi karena mudah\u00a0diimplementasikan. OJS memiliki fitur seperti manajemen editorial, online\u00a0submission, pengindeksan artikel, dan lain sebagainya. Namun, pada OJS belum\u00a0tersedia fitur rekomendasi untuk memberikan rekomendasi artikel yang sesuai bagi\u00a0pengguna. Penelitian ini bertujuan untuk membuat dan menambahkan fitur\u00a0rekomendasi pada OJS yang sudah ada untuk memberikan rekomendasi artikel\u00a0yang sesuai bagi pengguna menggunakan pendekatan Content-based Filtering yang\u00a0berfokus pada similaritas konten. Bagian artikel ilmiah seperti judul, kata kunci,\u00a0dan scope jurnal digunakan sebagai data referensi rekomendasi. Penelitian\u00a0menggunakan K-Means clustering dan Cosine Similarity sebagai matching method\u00a0dan hasil rekomendasi akan dibandingkan untuk mengetahui metode yang tepat\u00a0digunakan pada fitur rekomendasi. Hasil menunjukkan bahwa rekomendasi denganmatching method K-Means clustering memiliki rata-rata nilai precision lebih besar\u00a0dibandingkan menggunakan Cosine Similarity. Rekomendasi menggunakan KMeans\u00a0clustering menghasilkan rata-rata precision sebesar 68?n rata-rata recall\u00a0sebesar 64%. Dan hasil rekomendasi menggunakan Cosine Similarity memiliki\u00a0rata-rata precision sebesar 44.15?n rata-rata recall sebesar 64%.\u00a0",
        "64"
    ],
    [
        "Sistem Rekomendasi Berbasis Ontologi untuk Menu Harian MP-ASI Berdasarkan Kebutuhan Gizi Menggunakan Metode Topsis dan Na\u00efve Bayes ",
        "Asupan gizi bayi dan anak perlu diperhatikan sedari usia 0 bulan demi mencapai tumbuh kembang yang optimal. Pada usia 6 bulan, bayi mulai diberikan makanan pendamping ASI (MP-ASI) sampai usia 24 bulan. MP-ASI yang diberikan perlu disesuaikan dengan kebutuhan gizi sesuai usia bayi demi memenuhi kebutuhan gizi bayi. Penyesuaian ini tentu memerlukan ketelitian dan usaha yang tidak mudah apalagi jika dilakukan secara rutin setiap hari. Oleh karena itu, diperlukan sistem rekomendasi yang menentukan menu harian bayi yang sesuai dengan kebutuhan gizi bayi. Pada penelitian ini, dibangun sistem rekomendasi menu harian MP-ASI yang mempertimbangkan keseimbangan karbohidrat, protein, dan lemak, serta berdasarkan preferensi pengguna terhadap bahan makanan dengan implementasi metode TOPSIS dan Na\u00efve Bayes. Sistem diuji oleh pengguna yang terdiri dari ibu yang sudah berpengalaman dengan bayi usia 6 \u2013 24 bulan dan ibu dari bayi berusia 6 \u2013 24 bulan. Hasil usability testing sistem menggunakan SUS menunjukan tingkat kepuasan pengguna akan sistem baik dengan nilai sebesar 76.92 dan masuk ke dalam kategori grade B. Informasi yang diberikan sistem dinilai sudah sesuai dengan yang diharapkan dan pengguna akan berlanjut menggunakan sistem.",
        "65"
    ],
    [
        "Identifikasi Disgrafia melalui Tulisan Tangan dengan Metode Support Vector Machine",
        "Disgrafia, sebuah gangguan tulisan tangan di mana seseorang memiliki\u00a0kesulitan dalam menulis pada tingkat apa pun seperti, menulis lambat atau bentuk\u00a0huruf yang tidak dapat dibaca. Telah banyak penelitian yang dilakukan untuk\u00a0mempelajari karakteristik dan mendiagnosa disgrafia untuk pencegahan dini pada\u00a0anak-anak. Penelitian ini mengidentifikasi disgrafia pada anak-anak yang terbagikedalam 4 kelas yaitu, normal, ringan, sedang, dan berat. Aplikasi android dengan\u00a0menanamkan Handwriting-Recognition tool dibuat untuk mengumpulkan data dari\u00a0siswa sekolah dasar yang mengalami disgrafia dan yang tidak. Support Vector\u00a0Machine digunakan dalam proses klasifikasi data untuk mengidentifikasi disgrafia,\u00a0karena SVM memiliki kemampuan untuk belajar dengan baik pada data yang\u00a0terbatas dibandingkan dengan Jaringan Saraf Tiruan (JST) di banyak kesempatan.\u00a0Hasilnya, setelah menggunakan tiga kernel yang berbeda pada SVM yaitu, kernel\u00a0Linear, Polynomial, dan Radial Base Function (RBF), menunjukkan bahwa kernel\u00a0RBF menghasilkan akurasi rata-rata dan Cohen\u2019s kappa value yang lebih baik\u00a0dibandingkan dengan kernel Linear dan Polynomial. Akurasi rata-rata dari setiap\u00a0kernel yaitu, 82,51% untuk RBF, 81,40% untuk Polinomial, dan 78,56% untuk\u00a0Linear.",
        "66"
    ],
    [
        "Pembangunan Ontology Berbasis Metode Methontologi untuk Domain Tuberkulosis",
        "Tuberculosis merupakan penyakit kronik yang telah lama dikenal masyarakat luas karena\u00a0menular. Salah satu cara untuk mencegah bertambahnya pasien yang menderita penyakit\u00a0tuberculosis adalah meningkatkan pengetahuan masyarakat untuk mampu berperanmenangani kasus yang terjadi pada penyakit tuberculosis. Peningkatan pengetahuan\u00a0masyarakat terhadap pengetahuan penyakit tuberculosis dapat dilakukan dengan berbagai\u00a0cara, salah satunya dengan cara meningkatkan pengetahuan masyarakat untuk mampuberperan menangani kasus yang terjadi pada penyakit tuberculosis melalui media informasi.\u00a0Salah satu pendekatan yang memungkinkan untuk menjembatani masalah ini adalah\u00a0pemanfaatan Web Semantic yang memanfaatkan teknologi ontology. Dari berbagai macam\u00a0metodologi untuk membangun ontology, salah satunya adalah methontologi. Methontologi\u00a0dipilih karena memiliki keunggulan dalam pengembangan domain yang mandiri yang\u00a0meliputi proses pengembangan yang lebih luas dan secara terperinci dibandingkan metode\u00a0lainnya. Model ontology menggunakan methontologi ini mengambil fokus tentang penyakit\u00a0tuberculosis umum dan ekstra paru, sampai penjelasan tentang SOP tentang penanganan\u00a0pasien tuberculosis dengan kasus baru maupun pasien tuberculosis yang pernah berobat.\u00a0Disamping itu, juga diberikan pengenalan terhadap efek samping obat tuberculosis (OAT)agar masyarakat tak mudah panik dan dapat memberikan pertolongan pertama apabila terjadi\u00a0sesuatu yang tidak diinginkan. Data yang digunakan didalam penelitian ini telah divalidasi\u00a0oleh dokter spesialis paru. Dalam penelitian ini berhasil dibangun ontology tuberculosis\u00a0dengan tujuh kelas utama, yaitu: definisi_pasien, diagnosis, efekOAT, gejalaTb, jenisTb,\u00a0penanggulangan, dan pengobatan. Proses evaluasi pembangunan menggunakan Schema\u00a0metric pada Ontology Quality Analysis (OntoQA). Schema metric terdiri dari pengukuran\u00a0Relationship Richness (RR), Inheritance Richness (IR), dan Attribute Richness (AR).\u00a0Pengukuran tersebut dapat memberikan evaluasi terhadap karakteristik dan potensi\u00a0representasi pengetahuan dari rancangan ontologi. Dari hasil pengukuran, didapatkan hasil\u00a0RR 0,48, IR 3 dan AR 0,90. Nilai RR dan AR mengindikasikan rancangan ontologi masih\u00a0perlu diperbaiki sehingga potensi pengetahuan yang disampaikan dapat dimaksimalkan.Sementara nilai IR mengindikasikan rancangan ontologi mencakup bidang pengetahuan yang\u00a0cukup umum. Untuk menguji model ontology, penulis menggunakan prototype aplikasi yang\u00a0dapat digunakan untuk proses querying. Beberapa pertanyaan juga telah tersedia untuk diuji\u00a0menggunakan SPARQL. Hasil pengujian menunjukan bahwa informasi yang sudah tersedia\u00a0dapat digunakan sesuai dengan yang dibutuhkan oleh user. Dari hasil penelitian inidisimpulkan bahwa hasil ontology yang dibangun telah tervalidasi benar sesuai dengan ilmu\u00a0kedokteran pada penyakit tuberculosis sehingga dapat digunakan untuk meningkatkan\u00a0pengetahuan masyarakat awam terhadap pencegahan tuberculosis.\u00a0",
        "67"
    ],
    [
        "Pengaruh Dummy Variable dan Backward Feature Selection dengan Korelasi Pearson pada Naive Bayes Classifier untuk Diagnosa Ginekologi",
        "ABSTRAKPenggunaan Pearson correlation dan backward selection sebagai feature selection dapat dikombinasikan untuk meningkatkan hasil akurasi pada Naive Bayes Classifier. Feature selection ini dilakukan sebagai preprocessing data dan pada proses algoritma Naive Bayes Classfier. Pearson Correlation sebagai preprocessing data akan bekerja untuk mengurutkan parameter yang berpengaruh dalam proses klasifikasi penyakit kandungan dan Backward Selection akan menyeleksi parameter tersebut sesuai urutan pada preprocessing data dalam proses Naive Bayes Classfier. Sebelumnya, parameter tersebut akan diubah menjadi dummy variables karena parameter memiliki kemungkinan nilai yang muncul lebih dari dua (non-binary). Penelitian ini membahas tentang pengaruh Naive Bayes Classfier menggunakan dummy variables dan feature backward selection dengan pearson correlation dalam diagnosa penyakit kandungan. Hasil yang didapat pada penelitian ini membuktikan bahwa penggunaan dummy variables meningkatkan nilai akurasi dari 88% menjadi 88,8?n penggunaan pearson correlation sebagai preprocessing data meningkatkan nilai akurasi pada Naive Bayes Classifier dari 88,8?ngan 24 parameter menjadi 89,6?ngan 20 parameter. Penggunaan pearson correlation tidak hanya meningkatkan hasil akurasi tetapi juga meningkatkan efektivitas fitur. yang digunakan dalam proses Naive Bayes Classifier. Hal ini dapat dilihat dari peningkatan hasil akurasi dengan penggunaan jumlah parameter yang menurun. \u00a0Kata kunci : Naive Bayes Classifier, Dummy Variable, Pearson Correlation",
        "68"
    ],
    [
        "Perbandingan Cosine Similarity dan Euclidean Distance pada Sistem Rekomendasi Film Menggunakan Metode Item Based Multi Criteria Collaborative Filtering",
        "ABSTRAKHingga saat ini ada ratusan sistem rekomendasi di berbagai bidang yang melayani ribuan pengguna. Salah satu metode yang paling sukses dan terkemuka untuk digunakan pada sebuah sistem rekomendasi adalah metode collaborative filtering. Collaborative Filtering (CF) bekerja dengan membangun basis data item yang disukai oleh pengguna, sehingga dalam penelitian ini digunakanlah dasar metode collaborative filtering untuk membuat sistem rekomendasi. Namun dalam penelitian ini akan digunakan metode Item-based Multi Criteria Collaborative Filtering untuk membuat sistem rekomendasi karena metode Item-based Multi- Criteria Collaborative Filtering dianggap mampu memberikan hasil rekomendasi yang lebih akurat. Dalam penelitian ini akan digunakan rumus penghitungan Euclidean Distance dan Cosine Similarity sebagai rumus dasar untuk menghitung kemiripan antar film dan nantinya akan dibandingkan tingkat akurasi keduanya. Hasil penelitian menunjukkan bahwa rumus perhitungan Euclidean Distance dan Cosine Similarity mempunyai tingkat akurasi yang sama dengan hasil rata-rata MAE sebesar 0.83249.Kata\u00a0 kunci:\u00a0\u00a0 \u00a0Euclidean Distance, Item-based Multi-Criteria Collaborative Filtering, Mean Absolute Error, Sistem Rekomendasi\u00a0\u00a0",
        "69"
    ],
    [
        "Penerapan Algoritma Fp-Growth Untuk Menemukan Kombinasi Obat Berdasarkan Diagnosis Penyakit  (STUDI KASUS: APOTEK RAWAT JALAN RSUD SUKOHARJO)",
        "ABSTRAKRumah Sakit Umum Daerah (RSUD) Sukoharjo adalah rumah sakit milik Pemerintah Daerah Sukoharjo. RSUD Sukoharjo memiliki limabelas poliklinik. Semua poliklinik tersebut buka pada waktu yang bersamaan. Pelayanan resep obat dari semua pasien poliklinik hanya dapat dilakukan di satu apotek rawat jalan saja. Akibatnya, terjadi antrian di apotek rawat jalan yang mengakibatkan banyak keluhan dari pasien. Pembuatan paket obat diusulkan untuk memecahkan masalah ini. Dengan adanya paket obat, beberapa obat dapat disiapkan sebelum transaksi di apotek terjadi. Frequent pattern mining dengan algoritma FP-Growth digunakan untuk menemukan kombinasi obat berdasarkan diagnosis penyakit. Diagnosis penyakit yang digunakan dalam penelitian ini adalah diagnosis utama dalam bentuk kode ICD-10. Kombinasi obat yang dihasilkan dapat digunakan untuk pembuatan paket obat. Penelitian ini menggunakan data transaksi resep obat dari bulan Januari 2015 s.d. Juni 2016. Minimum support yang digunakan adalah 0,025. Hasil penelitian ini adalah kombinasi obat untuk sepuluh diagnosis penyakit yang paling sering muncul di Apotek Rawat Jalan RSUD Sukoharjo. Dari penelitian ini diketahui bahwa terdapat 21 kombinasi obat yang sama yang muncul di beberapa diagnosis penyakit.Kata kunci: FP-Growth, Frequent Pattern Mining, ICD-10\u00a0",
        "70"
    ],
    [
        "Sistem Pendukung Keputusan Pemilihan Program Studi Dengan Pendekatan Dua Arah Dan Metode Topsis",
        "ABSTRAKKekeliruan dalam memilih program studi di perguruan tinggi dapat membawa dampak yang buruk bagi calon mahasiswa. Beberapa permasalahan yang dapat muncul ketika mahasiswa merasa salah memilih program studi, antara lain : permasalahan psikologis, permasalahan akademis serta permasalahan relasional. Memilih program studi menjadi salah satu permasalahan bagi kebanyakan calon mahasiswa. Oleh karena itu, Sistem Pendukung Keputusan yang dibangun dalam penelitian ini bertujuan untuk membantu pengguna menemukan program studi yang sesuai minat dan kemampuan mereka. Sistem Pendukung Keputusan dalam penelitian ini menggunakan pendekatan dua arah, sehingga tidak hanya mempertimbangkan kondisi calon mahasiswa saja, tetapi juga mempertimbangkan kebutuhan, standar dan karakteristik dari program studi. Metode yang digunakan dalam Sistem Pendukung Keputusan ini adalah metode TOPSIS. Hasil dari penelitian ini menunjukkan bahwa hasil pendekatan dua arah dengan penggunaan threshold pada hasil penggabungan, baik tanpa normalisasi (Skenario 1) dan dengan normalisasi (Skenario 3) lebih baik jika dibandingkan dengan pendekatan satu arah yang hanya mempertimbangkan arah calon mahasiswa. Pada pendekatan dua arah, untuk Skenario 1 tingkat kesesuaiannya adalah Setuju (78,333%) dan Tidak Setuju (3,333%) untuk Skenario 3 tingkat kesesuaiannya adalah Setuju (73,333%) dan Tidak Setuju (3,333%). Sedangkan pada pendekatan satu arah tingkat kesesuaiannya adalah Setuju (66,667%) dan Tidak Setuju (18,333%).Kata Kunci : Pendekatan Dua Arah, Program Studi, Sistem Pendukung Keputusan, TOPSIS\u00a0\u00a0",
        "71"
    ],
    [
        "Perbandingan Metode K-Nearest Neighbor (K-Nn) dan Support Vector Machine (Svm) dalam Klasifikasi Dokumen Multi-Label (Studi Kasus Tugas Akhir Mahasiswa S1 Informatika UNS)",
        "Klasifikasi adalah proses pengelompokkan objek yang memiliki karakteristik atau ciri yang sama ke dalam beberapa kelas. Klasifikasi dokumen dapat dilakukan dengan menggunakan ciri atau fitur kata yang muncul pada dokumen latih. Namun apabila suatu ciri yang menjadi ciri dari satu dokumen merupakan ciri dari dokumen lainnya maka dokumen tersebut memiliki lebih dari satu topik atau disebut multi-label. Penelitian ini membandingkan metode klasifikasi K-Nearest Neighbor dengan Support Vector Machine dalam klasifikasi dokumen multi-label. Menggunakan metode pendekatan Problem Tranformation yaitu Binary Relevance (BR) dan Label Powerset (LP) untuk mengadaptasi metode K-Nearest Neighbor dan Support Vector Machine dalam membangun klasifikasi. Dataset yang digunakan adalah skripsi mahasiswa S1 Informatika UNS. Penelitian ini diuji dengan menggunakan validasi 10-fold cross validation. Sehingga nilai peforma terbaik untuk accuracy dan hamming loss pada SVM sebesar 0.66 dan 0.14 sedangkan untuk KNN sebesar 0.64 dan 0.17. Menurut hasil tersebut, metode SVM memiliki peforma yang lebih baik dari pada metode KNN.Kata kunci: klasifikasi, multi-label, k-nearest neighbor, support vector machine, problem Tranformation, skripsi.\u00a0",
        "72"
    ],
    [
        "Sistem Validasi Dokumen Tugas Akhir Universitas Sebelas Maret Dengan Metode Forward Chaining",
        "ABSTRAKUniversitas Sebelas Maret (UNS) memiliki berbagai jenis koleksi dokumen online termasuk koleksi dokumen tugas akhir yang dikelola oleh Unit Pelaksana Teknik (UPT) Perpustakaan UNS. Mahasiswa yang akan mengikuti wisuda wajib mengumpulkan dokumen tugas akhir untuk mendapatkan surat keterangan bebas pinjaman perpustakaan. Sistem yang berjalan saat ini belum melakukan verifikasi isi dokumen. Penelitian ini mengusulkan sebuah sistem validasi untuk melakukan validasi dokumen tugas akhir menggunakan metode Forward Chaining. Dataset yang digunakan berupa heading dan subheading berdasarkan aturan penulisan tugas akhir dari fakultas dan program studi di UNS, kemudian disimpan dalam database untuk digunakan sebagai rule base system. Pengujian sistem ini dilakukan berdasarkan pengecekan 269 data dan membandingkannya dengan rule base yang telah ditentukan sebelumnya. Akurasi hasil pengujian sistem ini adalah 100%, dihitung dengan membandingkan hasil pengujian dengan output dari sistem validasi. Sistem ini cukup terpercaya.Kata Kunci: Sistem Validasi, Forward Chaining, Rule Base System\u00a0",
        "73"
    ],
    [
        "Decision Support System Berbasis Expert System Dalam Pemilihan Mobil Bekas Dengan Menggunakan Metode Analytical Hierarchy Process Dan Forward Chaining",
        "ABSTRAKPembelian mobil bekas yang berkualitas harus disertai dengan pengalaman dan pengetahuan mengenai mesin, suku cadang, bodi kendaraan, kelistrikan mobil, dan lainnya. Di sisi lain, pembeli seringkali bingung dengan pilihan mobil yang ingin dibeli. Maka dari itu, diperlukan sebuah sistem penunjang keputusan berbasis sistem pakar dalam pemilihan mobil bekas. Tiga variabel penting masuk ke dalam sistem pakar diantaranya dokumen mobil, mesin, dan bodi/rangka kendaraan. Metode Forward Chaining digunakan dalam sistem pakar ini, dimana metode ini cocok digunakan karena dilakukan pengumpulan premis dan berakhir pada suatu bentuk kesimpulan. Pengetahuan dari pakar diakuisisi ke dalam sistem. Hasil dari sistem pakar ini kemudian menjadi variabel input ke dalam sistem penunjang keputusan. Di sisi lain, sistem penunjang keputusan memperhitungkan enam variabel tambahan diantaranya tahun produksi, harga, nilai desain, nilai warna, plat dan bobot hasil dari sistem pakar. Dalam prosesnya diterapkan metode Analytical Hierarchy Process (AHP) dikarenakan konsistensinya pada bobot. Pengujian yang dilakukan terhadap sistem ini menggunakan metode blackbox testing menunjukkan bahwa sistem telah berjalan dengan baik dan evaluasi kepuasan user didapatkan dari segi user interface, fungsi expert system dan DSS, dan overall. Dari sepuluh user, semua memberikan mayoritas nilai rating 4 dari skala penilaian 1-5 kepada setiap parameter penilaian, kecuali untuk parameter overall yang mendapatkan mayoritas nilai rating 5.Keywords: AHP, Decision Support System, Expert System, , Forward Chaining\u00a0",
        "74"
    ],
    [
        "Customer critique analysis system untuk twitter PT Kereta Commuter Indonesia menggunakan Support vector machine",
        "ABSTRAKCommuter Line merupakan salah satu pilihan utama bagi pengguna angkutan umum di Jakarta. Commuter Line di Indonesia dikelola oleh PT. Kereta Komuter\u00a0 Indonesia\u00a0 (PT.\u00a0 KCI).\u00a0 PT.\u00a0 KCI\u00a0 memiliki\u00a0 akun\u00a0 Twitter\u00a0 resmi\u00a0 yaitu @CommuterLine. Tujuan penelitian ini adalah membangun aplikasi Customer Critique Analysis System dengan data dari Twitter PT Kereta Commuter Indonesia menggunakan metode Support Vector Machine(SVM). Metode perancangan sistem yang digunakan adalah Component-Based Software Engineering(CBSE). Aplikasi yang dibangun menggunakan komponen/library yaitu Tweetsharp, LibSVM, Metronic, Kendo UI dan JQCloud. Hasil penelitian ini adalah aplikasi Analisis yang berguna untuk melakukan grabbing dan analisis data tweet dari akun Twitter @commuterline, dan sebuah dashboard untuk menampilkan hasil analisis dalam bentuk grafik. Hasil pengujian menunjukan bahwa sistem sudah memenuhi kebutuhan fungsional dan non-fungsional dari user. Pengujian fungsional dilakukan dengan menggunakan metode black-box. Sedangkan pengujian non- fungsional dilakukan dengan mengukur performance aplikasi. Performance yang diukur adalah akurasi klasifikasi dan running time dari program. Pengujian performance akurasi menghasilkan rata-rata akurasi klasifikasi sentimen sebesar 80,4%, dan akurasi klasifikasi jenis keluhan sebesar 82,3%. Sedangkan pengujian performance running time rata-rata running time yang didapatkan adalah 3 menit 25 detik.Kata Kunci: CBSE, Commuter Line, Sentimen Analysis, KCI, SVM\u00a0",
        "75"
    ],
    [
        "Klasifikasi trending topic twitter  untuk single-label menggunakan multinomial naive bayes (MNB) dan multi-label menggunakan k-nearest neighbors (KNNn)",
        "Trending Topic merupakan salah satu fitur yang terdapat dalam twitter berupa topik singkat yang sedang trend. Namun, topik yang singkat tersebut terkadang sulit dipahami penggunanya, sehingga mendorong peneliti melakukan penelitian yang bertujuan mengklasifikasikan trending topic menjadi kategori umum sehingga lebih mudah dalam memahami trending topic. Untuk mengatasi masalah tersebut digunakan pengelompokan trending topic yaitu politik, olahraga, hiburan, pariwisata, bisnis dan berita lainnya. Masalah lain yang muncul adalah adanya multi-label pada klasifikasi. Klasifikasi single-label akan mengklasifikasikan suatu trending topic kedalam satu label saja, sedangkan klasifikasi multi-label mengklasifikasikan kedalam lebih dari satu label. Pada penelitian ini dilakukan klasifikasi single-label menggunakan Multinomial Naive Bayes (MNB) dan klasifikasi multi-label menggunakan K-Nearest Neighbors (KNN). Langkah pada penelitian ini yaitu mengumpulkan data trending topic beserta tweetnya, labelling dan text preprocessing, pembobotan TF-IDF, klasifikasi single-label menggunakan MNB dan klasifikasi multi-label menggunakan KNN dengan pendekatan Binary Relevance, terakhir evaluasi dan analisa hasil. Dari hasil penelitian, Akurasi untuk single-label menggunakan MNB mendapatkan hasil terbaik yaitu 82,53% sementara untuk multi-label menggunakan KNN dengan K=3 mendapatkan hasil terbaik yaitu 88,05%.\u00a0Kata kunci: trending topic, single-label, multi-label, multinomial naive bayes, k- nearest neighbors, tf-idf, binary relevance",
        "76"
    ],
    [
        "Intelligent Tutoring System (ITS) dengan menggunakan ontologi dan Case-Based Reasoning (CBR) untuk pembelajaran sertifikasi java",
        "Berbagai pendidikan melalui pembelajaran yang berbasiskan teknologi informasi telah banyak diterapkan, misalnya pembelajaran elektronik atau yang sering disebut e-learning. Walaupun e-learning telah banyak digunakan dalam pembelajaran, tetapi sistem tersebut memiliki kekurangan yaitu pembelajarannya tidak memperhatikan keragaman dari kemampuan penggunanya secara individual. Intelligent Tutoring System (ITS) menjadi salah satu solusi untuk mendukung pembelajaran. Penelitian ini bertujuan membangun aplikasi ITS dengan pemodelan ontologi dan metode Case-Based Reasoning (CBR) untuk pembelajaran Java Programming. ITS merupakan sistem yang tidak hanya menyediakan bimbingan belajar kepada pengguna, tetapi juga menyesuaikan bimbingan belajar dengan kemampuan pengguna. Pemodelan ontologi berperan sebagai pemetaan bahan pembelajaran Java Programming dan metode CBR berperan sebagai sistem yang menyesuaikan bimbingan belajar dengan kemampuan pengguna. Hasil penelitian ini menunjukkan bahwa aplikasi ITS telah dapat membantu pengguna dalam memberikan pembelajaran yang adaptif dan user-friendly. Berdasarkan hasil evaluasi usability sistem oleh 20 pengguna, aplikasi ini dapat diterima karena nilai usability sistem mencapai angka 3,7625 dari skala 1 sampai 5.Kata kunci : Case-Based Reasoning, Intelligent Tutoring System, K-NearestNeighbor, Ontology",
        "77"
    ],
    [
        "Pengenalan tulisan tangan aksara jawa menggunakan  convolutional neural network",
        "Huruf Jawa adalah huruf tradisional yang masih digunakan di Jawa terutama daerah Solo dan Jogjakarta. Penelitian terhadap huruf Jawa masih berlanjut baik untuk membaca huruf Jawa kuno maupun modern. Terutama untuk tulisan tangan, karena terdapat perbedaan gaya tulis sehingga sulit dibaca. Dengan menggunakan pengolahan citra dan jaringan saraf tiruan pengenalan huruf Jawa dapat dilakukan. Penelian sebelumnya pernah dilakukan pada huruf cetak. Pada penelitian ini akan dibuat convolutional neural network untuk mengenali tulisan tangan huruf Jawa. Jaringan akan dilatih menggunakan data sebanyak 10601 huruf Jawa dasar. Eksperimen dilakukan dengan beberapa variasi, pertama menggunakan data normal, kedua menggunakan data augmentasi, ketiga menggunakan kernel lebih banyak dan keempat adalah pelatihan dengan jumlah epoch berbeda. Hasil penelitian menunjukan pelatihan menggunakan kernel lebih banyak menghasilkan jaringan dengan akurasi tinggi. Jaringan CNN mampu mengenali huruf Jawa pada sampel uji dengan akurasi mencapai 97,5%.Kata kunci : aksara Jawa, Convolutional neural network, Pengenalan huruf ,tensor flow\u00a0",
        "78"
    ],
    [
        "Content-Based Filtering dengan Term Frequency-Inverse Document Frequency (Tf\u2013Idf) dan Cosine Similarity untuk Rekomendasi Jurnal Elektronik",
        "ABSTRAKPeningkatan jumlah jurnal ilmiah Indonesia yang terindeks di SCOPUS pada tahun 2017 mencapai 45?n diprediksi akan terus meningkat seiring dengan dukungan pemerintah lewat kebijakan\u00a0 yang menunjang perkembangan riset dan publikasi. Peningkatan kuantitas ini perlu diimbangi dengan peningkatan kualitas pengelolaan data dan informasi dengan menyediakan akses yang mudah untuk user.Penelitian ini menggunakan metode content-based filtering untuk merekomendasikan\u00a0 jurnal\u00a0 ilmiah\u00a0 yang\u00a0 relevan,\u00a0 dengan\u00a0 memanfaatkan pembobotan TF-IDF dan metode cosine similarity untuk menentukan kemiripan antar jurnal. Pengujian yang dilakukan sebanyak 49 kali pada threshold sebesar 0,14 menghasilkan nilai rata - rata precision sebesar 66,53% sedangkan nilai rata\u2013rata recall sebesar 56,13?ngan nilai modus sebesar 100%, dimana 26 dari 49 pengujian menghasilkan nilai precision sebesar 100?n 16 dari 49 pengujian memperoleh nilai recall sebesar 100%. Jika hanya item yang nilai kemiripannya melebihi threshold\u00a0 yang dihitung, maka nilai precision dan recall rata \u2013 rata mengalami peningkatan signifikan menjadi 79,51?n 66,83%.Kata kunci : rekomendasi, content-based filtering, TF-IDF, cosine similarity",
        "79"
    ],
    [
        "Klasifikasi Tema Menggunakan Algoritma Generalized Vector Space Model (Gvsm) \u2013 Improved Knn pada Soal Ujian Nasional",
        "ABSTRAKUjian\u00a0 Nasional\u00a0 (UAN\u00a0 atau\u00a0 UNAS\u00a0 atau\u00a0 UN)\u00a0 sebagai\u00a0 alat\u00a0 ukur\u00a0 evaluasi pemerintah untuk menentukan kualitas pendidikan di Indonesia. Kualitas ditunjukkan saat siswa dapat mengerjakan soal ujian nasional berdasarkan materi sesuai dengan Standar Kompetensi Lulusan (SKL). Soal dikelompokkan ke berbagai tema. Klasifikasi tema berguna untuk mengetahui golongan soal yang ada di dalam materi Standar Kompetensi\u00a0 Lulusan\u00a0 \u00a0(SKL).\u00a0 \u00a0Penelitian\u00a0 \u00a0ini\u00a0 \u00a0bertujuan\u00a0 \u00a0untuk\u00a0 \u00a0mengetahui\u00a0 \u00a0kinerja algoritma Generalized Vector Space Model (GVSM) \u2013 improved KNN dalam melakukan klasifikasi soal berdasarkan tema. Algoritma GVSM digunakan untuk mengidentifikasi kemiripan kata yang muncul di dokumen yang satu dengan dokumen yang lain. Algoritma improved KNN ini mengklasifikasikan soal ujian nasional berdasarkan tema dalam mata pelajaran dengan menganalisa semua kata yang muncul pada soal ujian nasional. Pengujian dilakukan sebanyak 10 kali dengan metode k-fold cross validation menghasilkan nilai akurasi sebesar 0,7939, presisi sebesar 0,7771, dan recall sebesar 0,7633.Kata kunci : Ujian Nasional, Standar Kompetensi Lulus (SKL), Klasifikasi Tema,Generalized Vector Space Model, Improved KNN.",
        "80"
    ],
    [
        "Implementasi Backpropagation untuk Klasifikasi Disgrafia pada Anak",
        "ABSTRAKDisgrafia adalah sebuah gangguan yang mempengaruhi kemampuan menulis seseorang seperti menulis yang lambat atau tulisan yang tidak dapat dibaca Beberapa penelitian telah dilakukan untuk mengetahui karakteristik disgrafia dan diagnosis disgrafia. Berbeda dengan penelitian yang ada, penelitian ini mengidentifikasi disgrafia pada anak-anak yang dikategorikan menjadi empat kelas (normal, disgrafia ringan, sedang, dan berat) dan dua kelas (normal dan disgrafia). Pengumpulan data dilakukan dengan menggunakan aplikasi Android yang telah dibuat. Backpropagation digunakan untuk klasifikasi data untuk identifikasi disgrafia. Teknik SMOTE dan Feature Selection digunakan untuk memperbaik hasil klasifikasi. Penelitian ini menghasilkan akurasi terbaik sebesar 84.7% untuk kategori dua kelas, dan 82% untuk kategori empat kelas.Kata kunci: backpropagation, data mining, disgrafia, identifikas",
        "81"
    ],
    [
        "Penerapan Algoritma Particle Swarm Optimization (Pso) Pada Capacitated Vehicle Routing Problem (Cvrp) (Studi Kasus: Pt Guwatirta Sejahtera Karanganyar)",
        "ABSTRAKCapacitated Vehicle Routing Problem (CVRP) merupakan suatu permasalahan yang berkaitan dengan penentuan rute kendaraan untuk mengirimkan barang dari depot kepada sejumlah pelanggan dengan permintaan yang telah diketahui sebelumnya dan menggunakan sejumlah kendaraan dengan kapasitas tertentu. Penelitian ini, membahas konsep algoritma Particle Swarm Optimization (PSO) pada kasus CVRP untuk meminimalkan biaya distribusi di sebuah perusahaan air mineral PT Guwatirta Sejahtera. Proses algoritma PSO dimulai dengan menentukan parameter yang digunakan dalam proses perhitungan. Inisialisasi awal berupa pembangkitan sejumlah kawanan partikel, dengan posisi awal random dan kecepatan awal bernilai 0. Proses selanjutnya adalah menghitung nilai fungsi tujuan, menentukan nilai posisi terbaik dalam setiap partikel (Pbest), dan menentukan nilai posisi terbaik seluruh partikel (Gbest). Setelah didapatkan usulan rute terbaik algoritma PSO, sistem melakukan pengecekan permintaan barang setiap Agen untuk membuat rute kembalinya kendaraan menuju depot dan mengisi ulang muatan, kemudian melanjutkan perjalanannya. Sistem yang dihasilkan terbukti mampu mengurangi biaya distribusi sebesar 31.05%.Kata Kunci: Particle Swarm Optimization, Algoritma PSO, Capacitated Vehicle Routing Problem, CVRP, PT Guwatirta Sejahter",
        "82"
    ],
    [
        "Implementasi Internet of Things pada Sistem Otomatisasi dan Monitoring Hidroponik Metode Water Culture",
        "ABSTRAKDalam perawatan tanaman hidroponik manual, parameter air, pH, nutrisi, suhu, kelembaban, dan cahaya harus selalu dijaga agar perkembangan tanaman tetap stabil. Untuk membantu petani merawat tanaman mereka, maka dibangun Implementasi Internet of Things (IoT) pada tanaman hidroponik. Sistem yang dibangun memberikan informasi suhu, kelembaban, pH, EC, air, dan cahaya dari tanaman hidroponik kepada pemilik tanaman. Dalam penelitian ini dibangun sebuah prototype IoT yang dapat mengatur air, nutrisi, pH, dan cahaya pada tanaman secara otomatis. Sistem ini membantu pemilik tanaman memantau dan merawat tanaman mereka dimana saja. Dari hasil pengujian prototype didapatkan bahwa sensor dan aktuator berjalan dengan baik dan benar. Dari hasil pengujian performa konetivitas, konektivitas sistem berjalan dengan baik sampai dengan 100 node. Jika node berjumlah 200 node atau lebih maka performa konetivitas sistem akan turun sampai dengan 31%.Kata Kunci:\u00a0hidroponik, Internet of Things, monitoring, otomatis, prototype, water culture",
        "83"
    ],
    [
        "Penerapan hyperparameter optimization pada algoritma decision tree cart dan random forest untuk menemukan faktor kredit macet",
        "Pada kasus program kredit pinjaman di Bank XYZ, masalah yang sering timbul dalam pelaksanaan perjanjian kredit perbankan adalah keadaan dimana debitur lalai untuk melakukan kewajibannya, yang dapat menyebabkan adanya kredit macet. Penerapan metode klasifikasi kredit macet yang terbaik sangat dibutuhkan untuk penanggulangan dan pembatasan kredit macet di Bank XYZ. Metode klasifikasi decision tree CART dan random forest kemudian diaplikasikan pada penelitian ini. Untuk menemukan model tree yang terbaik, hyperparameter optimization diterapkan pada decision tree CART dan random forest. Sebelum melakukan klasifikasi, dilakukan data preprocessing. Namun, pada proses data preprocessing, ditemukan bahwa terdapat ketidakseimbangan kelas pada data. Untuk mengatasi permasalahan ini, metode resampling Random Over Sampling (ROS), Random Under Sampling (RUS), dan Synthetic Minority Over-sampling Technique (SMOTE) digunakan. Hasil dari penelitian ini menunjukan bahwa bila dibandingkan dengan metode resampling lain, data yang melalui tahap ROS dan SMOTE menghasilkan data yang optimal. Untuk perbandingan accuracy, precision, recall, dan f1-score, metode Random Forest dengan data ROS menunjukan hasil yang terbaik dengan n_estimators = 50 di persentase 100%,100%, 100?n 100%. Dan berdasarkan model terbaik yang telah dihasilkan, tiga faktor utama penyebab kredit macet adalah nilai taksasi agunan, jangka waktu, penghasilan; dimana banyaknya nilai dari masing-masing variabel perlu dipertimbangkan kembali untuk meminimalisir terjadinya kredit macet untuk beberapa tahun yang akan datang.Keyword:\u00a0\u00a0 Decision Tree CART, Random Forest, Hyperparameter Optimization, Resampling\u00a0",
        "84"
    ],
    [
        "Part of speech (POS) tagging bahasa Indonesia menggunakan algoritma hidden markov model-ngram & algoritma viterbi",
        "Part of Speech (POS) Tagging merupakan salah satu aplikasi dari Natural Language Processing. POS Tagging merupakan proses pemberian label kelas kata pada kalimat. Salah satu masalah dalam POS Tagging adalah ambiguitas. Ambiguitas sendiri adalah kata yang dieja sama tetapi memiliki POS Tag yang berbeda tergantung pada konteks kalimatnya. Salah satu pendekatan untuk menyelesaikan masalah ini adalah menggunakan algoritma Hidden Markov Model (HMM) N-gram dan algoritma Viterbi. Penelitian ini membahas tentang pengembangan sebuah sistem POS tagging menggunakan algoritma HMM N-gram (bigram & trigram) dan algoritma Viterbi untuk menyelesaikan masalah tersebut dan mengetahui manakah yang lebih baik antara HMM Bigram dan HMM Trigram. Oleh karena itu sebuah korpus yang sudah dilabeli secara manual bernama \u201cIndonesian Manually Tagged Corpus\u201d digunakan sebagai pengetahuan sistem. Kemudian korpus tersebut diproses menggunakan algoritma HMM N-gram untuk memperoleh aturan yang akan digunakan nanti. Kemudian data testing diproses menggunakan algoritma Viterbi menggunakan aturan yang sudah diperoleh sebelumnya untuk menentukan POS Tag yang memiliki probabilitas tertinggi. Hasil akurasi tertinggi adalah 77.56% menggunakan algoritma HMM Bigram \u2013 Viterbi dengan komposisi 9,000 data training dan 1,000 data testing. Sedangkan pada algoritma HMM Trigram \u2013 Viterbi memiliki akurasi tertinggi sebesar61.67?ngan komposisi data yang sama. Hal ini menunjukan bahwa sistem yang dibuat dapat mengatasi masalah ambiguitas tag menggunakan algoritma HMM Ngram\u2013 Viterbi dan kita juga mengetahui bahwa HMM Bigram lebih baik daripada HMM Trigram.Keywords: POS Tagging, Hidden Markov Model, N-gram, Bigram, Trigram, Viterbi",
        "85"
    ],
    [
        "Analisis perbandingan metode AHP dan FUZZY-AHP dalam menentukan Critical Success Factor (CSF) (studi kasus: E- Learning Universitas Sebelas Maret Surakarta)",
        "ABSTRAK Banyak universitas di dunia menggunakan E-learning sebagai bagian dari sistem pengajaran mereka, termasuk Universitas Sebelas Maret. Sebuah studi telah dilakukan dalam merangking CSF E-learning di Universitas Maret dengan metode AHP. Namun, metode AHP tidak bisa menangani ketidakpastian dan ketidakjelasan opini manusia yang akan membuat pengambilan keputusan dengan AHP menjadi kurang tepat. Untuk mengatasi masalah ini digunakan teori fuzzy yang digabung dengan AHP untuk meningkatkan kemampuan AHP dalam mengatasi ketidakpastian/Fuzzyness. Tujuan dari makalah ini adalah untuk menganalisis perbedaan prioritas dari AHP dan Fuzzy-AHP dari beberapa faktor yang mempengaruhi Critical Success Factor pada E-learning Universitas Sebelas Maret Surakarta. Pada penelitian ini peringkat dari AHP dan metode Fuzzy-AHP Dibandingkan dengan Korelasi Spearman, Korelasi Kendall Tau, dan Korelasi Pearson. Pada penelitian ini dikumpulkan 10 expert, 305 dosen, dan 4.195 siswa. Analisis korelasi menunjukkan bahwa korelasi antara peringkat dan berat dari AHP dan Fuzzy-AHP adalah sangat kuat, sehingga dapat disimpulkan bahwa dalam menemukan prioritas CSF E-learning UNS metode yang lebih sederhana seperti AHP sudah cukup daripada menggunakan metode yang lebih kompleks seperti Fuzzy-AHP. Akan tetapi, mempertimbangkan persimpangan perangkingan yang dihasilkan oleh kedua metode akan lebih ideal. Kata kunci: AHP, Fuzzy-AHP, CSF E-learning, Analisis Korelasi, Group Decission Making ",
        "86"
    ],
    [
        "Klasifikasi Pendaftar Beasiswa Bidikmisi Universitas Sebelas Maret dengan Algoritma C4.5",
        "AbstrakBeasiswa Bidikmisi adalah salah satu beasiswa untuk mahasiswa kurang mampu namun berprestasi. Dengan banyaknya pendaftar Bidikmisi perlu digunakan sebuah metode yang akurat untuk membantu proses seleksi penerima beasiswaBidikmisi khususnya di lingkungan Universitas Sebelas Maret (UNS). Pada penelitian ini, algoritma C4.5 diusulkan sebagai metode untuk membantu proses seleksi penerima beasiswa Bidikmisi. Dataset yang digunakan adalah datapendaftar Bidikmisi tahun 2014 dan 2015. Data pendaftar tahun 2014 digunakan sebagai data latih sedangkan data pendaftar tahun 2015 digunakan sebagai data uji. Selain itu, teknik oversampling dan undersampling juga digunakan untuk mengatasi masalah ketidakseimbangan kelas pada data training. Pada akhirnya akurasi dari pohon keputusan dari dataset hasil sampling akan dibandingkan untuk melihat teknik sampling yang lebih baik. Hasil penelitian ini menunjukkan bahwa pohon keputusan yang diuji menggunakan data pendaftar tahun 2015 memiliki nilai accuracy 79,80 ?n nilai Area Under Curve 0.5539. Sementara itu, untuk membandingkan teknik oversampling dan undersampling dipilih pohon keputusan terbaik dari masing-masing hasil sampling. Teknik oversampling menghasilkan nilai precision 82,69 %, recall 91,22 %, dan accuracy 77,16 %. Sedangkan teknik undersampling menghasilkan nilai precision 82,78 %, recall 91,22 %, dan accuracy 77,27 %. Sehingga dapat disimpulkan bahwa teknik undersampling memiliki akurasi yang lebih baik daripada teknik oversampling.Kata kunci : Algoritma C4.5, Bidikmisi, Pohon Keputusan, Oversampling, Undersampling",
        "87"
    ],
    [
        "Perbandingan performansi antara algoritma cosine similarity dengan jaccard similarity untuk pencarian pada portal jurnal",
        "ABSTRAKPembuatan artikel ilmiah menjadi prasyarat kelulusan mahasiswa Universitas Sebelas Maret. Hal tersebut menyebabkan pertumbuhan jumlah artikel dalam portal jurnal UNS terus meningkat.\u00a0 Manajemen portal jurnal yang baik sangat dibutuhkan.Fungsi pencarian merupakan fungsi yang penting dalam sebuah portal jurnal. Fungsi pencarian yang baik akan memudahkan pengguna dalam mencari jurnal yang diinginkan.Penelitian ini menggunakan metode Cosine similarity dan Jaccard similarity untuk perhitungan kemiripan pada pencarian. Metode tersebut bertujuan untuk mengetahui precision maupun recall dari fungsi search. Data yang digunakan untuk pengujian adalah kata kunci yang diambil secara acak. Dari uji coba didapatkan hasil bahwa Cosine menghasilkan hasil pencarian yang lebih baik daripada Jaccard, nilai precision Cosine yang tertinggi mencapai 67.47%, dan nilai recall tertinggi yang dicapai adalah 99.91%, sedangkan nilai precision tertinggi Jaccard adalah 53.38?n nilai recall tertingginya adalah 96.88%.Kata kunci: Jaccard similarity, Cosine similarity, pencarian\u00a0",
        "88"
    ],
    [
        "Pengelompokan Berita Online  Menggunakan Multinomial Naive Bayes",
        "AbstrakJumlah dokumen teks yang terus bertambah merupakan sumber informasi yang sangat berharga dan dapat dimanfaatkan untuk berbagai kepentingan. Analisis dokumen teks dapat dilakukan dengan text mining. Salah satu metode text mining yang bermanfaat untuk mengelompokan data yang jumlahnya sangat banyak dan sulit dilakukan apabila diproses secara manual adalah klasifikasi. Klasifikasi merupakan suatu proses pengelompokan dan pengkategorian suatu dokumen berdasarkan model terlatih yang sudah memiliki label sebelumnya.Penelitian ini bertujuan untuk mengelompokan berita dalam teks Bahasa Indonesia dengan metode klasifikasi Multinomial Naive Bayes. Untuk mendapatkan hasil yang lebih optimal, maka dilakukan proses seleksi fitur menggunakan metode Document Frequency Thresholding dan juga pembobotan dengan Term Frequency \u2013 Document Frequency (TFIDF). Hasil penelitian menunjukan bahwa penggunaan Term Frequency \u2013 Document Frequency (TFIDF) menghasilkan nilai rata-rata tertinggi mencapai 86,62 %, sementara Multinomial Naive Bayes mencapai 86,28%, Multinomial Naive Bayes dengan DF-Thresholding-TFIDF mencapai 86,15?n Multinomial Naive Bayes dengan DF-Thresholding mencapai 85,98%. Fitur seleksi dengan metode Document Frequency Thresholding cukup efektif untuk mengurangi jumlah dimensi data ditunjukan dengan hasil akurasi akhir yang tidak jauh signifikan dari metode Multinomial Naive Bayes.Kata kunci: text mining, klasifikasi, multinomial naive bayes, df-thresholding, tfidf\u00a0",
        "89"
    ],
    [
        "Sistem rekomendasi pariwisata pantai menggunakan metode content based filtering",
        "ABSTRAKNegara Indonesia memiliki potensi alam yang sangat indah dengan budaya dan adat istiadat yang melimpah dan melekat erat sebagai jati diri bangsa dan dipegang teguh oleh masyarakat Indonesia yang belum tentu dimiliki oleh negara lain. Daya tarik yang dimiliki Negara Indonesia yaitu pemandangan alam yang indah dan beraneka ragam ditunjang dengan sikap masyarakat yang memegang teguh adat Indonesia yang terkenal dengan ramah tamah menjadikan Indonesia sebagai salah satu tempat wisata yang mampu menarik wisatawan baik domestik maupun asing untuk berkunjung ke Indonesia. Salah satu tempat wisata yang menjadi favorit adalah pantai. Hal ini juga didukung dengan banyaknya pengunjung beberapa pantai terkenal di Pulau Jawa, seperti Pantai Parangtritis pada tahun 2011 sebanyak 1,338.112 wisatawan, Pantai Pangandaran pada tahun 2013 sebanyak wisatawan mancanegara sebanyak 8.587 orang dan wisatawan nusantara 1.552.153 orang, akan tetapi dari banyaknya pengunjung pantai tersebut masih terdapat pantai yang sepi, seperti Pantai Jambu di Banten, pantai ini tidak kalah indahnya dari pantai-pantai yang sudah terkenal di Pulau Jawa. Berdasarkan permasalahan yang dijelaskan diatas, metode Content Based Filtering diterapkan untuk membuat sistem rekomendasi pariwisata pantai yang dapat membantu wisatawan mendapatkan informasi pantai yang masih sepi dan indah. Pengujian precision dan recall menghasilkan nilai masing-masing 72?n 19.23%.Kata kunci: Text Proccesing, Vector Space Model, Cosine Similarity, Content Based Filtering.\u00a0",
        "90"
    ],
    [
        "Klasifikasi kecenderungan tingkah laku big five personality berdasarkan bidang studi dengan analisis Twitter menggunakan metode  support vector machine  (studi kasus: mahasiswa UNS)",
        "ABSTRAKKecenderungan tingkah laku dapat dilihat dari karakteristik atau kepribadian. Reaksi seseorang terhadap sesuatu dapat terlihat melalui Twitter, dari kata yang ditulis dalam tweets, sehingga dapat diketahui karakter atau kepribadiannya. Kepribadian dapat berubah yang dipengaruhi beberapa faktor, salah satunya adalah bidang studi. Bidang studi yang ditekuni berpengaruh dalam faktor lingkungan selama dalam proses studi, contohnya dalam lingkungan studi saat masa perkuliahan. Oleh karena itu, penelitian ini melakukan analisis twitter untuk klasifikasi kecenderungan tingkah Big Five Personality berdasarkan bidang studi. Bidang studi dikelompokkan ke tujuh kelompok yaitu art/humanities, law, economy, medicine, political science, psychology, dan science. Proses klasifikasi dilakukan dalam beberapa skenario pembagian jumlah data tweets. Hasil klasifikasi dengan nilai akurasi tertinggi pada data 300 tweets,dengan nilai akurasi SVM 80.5?n MNB 82%. Perbandingan sifat Big Five dengan penelitian sebelumnya memiliki kesamaan untuk setiap bidang studi selain bidang studi economy.Kata kunci: BFI, Bidang studi, Big Five Personality, SVM, Twitter.\u00a0",
        "91"
    ],
    [
        "Analisis sentimen pada review produk kosmetik menggunakan metode multinomial Na\u00efve Bayes dilengkapi seleksi fitur Information Gain ",
        "ndonesia, terdapat media bernama femaledaily.com yang memiliki kolom khusus untuk review produk kosmetik. Review produk dapat membantu konsumen menyimpulkan kualitas produk. Beberapa cara untuk menyimpulkan kualitas\u00a0 produk\u00a0 adalah\u00a0 dengan\u00a0 mengklasifikasikan\u00a0 review\u00a0 dan\u00a0 menghitung polaritas sentimen yang menjadi bagian dari tujuan penelitian ini. Penelitian ini bertujuan untuk mengetahui akurasi klasifikasi menggunakan metode Multinomial Na\u00efve Bayes (MNB) dilengkapi seleksi fitur Information Gain (IG) dan menganalisa polaritas sentimen masyarakat terhadap tujuh produk kosmetik populer pada Female Daily.Klasifikasi menggunakan MNB dan IG menghasilkan akurasi yang sebanding dengan akurasi klasifikasi hanya menggunakan MNB. Waktu eksekusi MNB-IG menurun separuh dari waktu eksekusi MNB. Hal ini terjadi karena IG menyebabkan berkurangnya dimensi data sehingga berpengaruh pada berkurangnya waktu yang diperlukan untuk klasifikasi. Hasil akurasi MNB-IG adalah 80,42?n klasifikasi hanya menggunakan MNB adalah 82,17?ngan waktu eksekusi sekitar 4,7 detik untuk MNB-IG dan 9,51 detik untuk MNB. Polaritas sentimen masyarakat terhadap tujuh produk kosmetik memperlihatkan bahwa polaritas tertinggi dimiliki oleh Estee Lauder dengan polaritas positif sebesar\u00a0\u00a0 94,37%.\u00a0\u00a0 Perangkingan\u00a0\u00a0 polaritas\u00a0\u00a0 ternyata\u00a0\u00a0 memberikan\u00a0\u00a0 hasil\u00a0\u00a0 yang sebanding dengan perangkingan user rating dibuktikan dengan urutan polaritas dan urutan rating yang ternyata sama. Oleh karena itu, polaritas sentimen sebenarnya dapat diajukan kepada FemaleDaily untuk dijadikan alternatif yang lebih objektif dalam perankingan",
        "92"
    ],
    [
        "Penerapan Naive Bayes Classifier (NBC) pada Sistem Rekomendasi Film dengan Metode Item-Based Collaborative Filtering",
        "Banyaknya film yang beredar membuat masyarakat sulit menemukan film yang mereka inginkan. Solusi dari permasalahan diatas adalah disediakanya suatu sistem rekomendasi yang mampu memberikan rekomendasi film kepada pengguna. Penelitian ini menggunakan metode Item-Based Collaborative Filtering pada sistem rekomendasi film yang bertujuan untuk merekomendasikan film pada seorang user berdasarkan neighborhood similarity antar item yang dihitung menggunakan algoritma cosine similarity, dan Na\u00efve Bayes untuk menghitung prediksi rating. Data yang digunakan merupakan MovieLens Datasets yang di dapat dari GroupLens Research. MovieLens Datasets memiliki data dengan skala [1-5], dimana pada umumnya nilai yang dihasilkan oleh fungsi similarity berkisar pada interval [0\u20261] atau biasa disebut data diskrit dan nilai yang berada di luar interval tersebut untuk memetakan hasil fungsinya harus di normalisasi. Hasil implementasi Item-based Collaborative Filtering dengan metode Na\u00efve Bayes Classifier menggunakan algoritma cosine similarity dengan data testing sebesar 5% menggunakan nilai threshold sebesar 0,689 sebagai batas tertinggi, dan data testing sebesar 2% menggunakan nilai threshold sebesar 0,666 sebagai batas tertinggi, dan empat nilai threshold yang berbeda yaitu 0,6, 0,5, 0,4 dan 0,3, menghasilkan akurasi, presisi, recall, dan f-measure yang tidak memiliki selisih yang berarti. Semakin kecil nilai threshold menyebabkan semakin banyaknya jumlah tetangga yang dimiliki tiap item sehingga mempengaruhi nilai akurasi, presisi, recall dan f-measure yang cenderung meningkat. Namun demikian, semakin banyaknya jumlah tetangga mengakibatkan nilai posterior saat perhitungan prediksi rating menjadi sangat kecil sehingga pada progam terdeteksi dengan nilai 0 yang menyebabkan kegagalan prediksi (zero prediction).\u00a0",
        "93"
    ],
    [
        "Sistem Keamanan Server dengan Honeypot dan Intrusion Detection System (IDS) (Studi Kasus Perusahaan Printing Somatex)",
        "Sistem keamanan jaringan menjadi hal yang sangat penting dalam menjaga sebuah jaringan, serangan yang bisa mengganggu bahkan merusak sistem koneksi antar perangkat yang terhubung akan sangat merugikan.Untuk mengatasi hal tersebut, perlu dibangun sistem keamanan server untuk mencegah serangan yang dapat menyebabkan kerugian,seperti kehilangan data.Salah satu cara yang bisa dilakukan adalah dengan membangun sistem keamanan server dengan Honeypot dan Intrusion Detection System (IDS).Honeypot adalah sebuah sistem atau komputer yang sengaja dijadikan umpan untuk menjadi target serangan dari penyerang (attacker), sehinggapenyerang akan terjebak oleh umpan Honeypot. Untuk penelitian ini digunakan Honeypot dengan jenis kippo.Intrusion Detection System (IDS) adalah sebuah sistem yang digunakan untuk mendeteksi adanya serangan pada sebuah komputer atau server. IDS merupakan pilihan yang tepat untuk dipadukan dengan Honeypot\u00a0 karena dengan perpaduan ini maka penyerang dapat terjebak oleh room palsu buatan kippo serta data dari penyerang akan dapat langsung terbaca oleh IDS. Adapun jenis IDS\u00a0 yang digunakan adalah snort.Pada penelitian ini dilakukan pengujian dengan melakukan penyerangan dengan menggunakan metode penyerangan\u00a0 scanning dan metode penyerangan brute force. Setelah dilakukan penyerangan dengan kedua metode tersebut, didapatkan bahwa penyerang dapat terperangkap oleh roompalsu buatan Honeypot serta data penyerang dapat terlacak oleh IDS .Dengan menggunakan teknik serangan bruteforce, dilakukann serangan dengan password target dengan 3 jenis karakter berbeda, dengan jenis karakter alfabet, numeric, dan karakter campur. Untuk karakter numerik diperoleh rata-rata waktu serangan\u00a0 14,68 detik , untuk karakter alfabet diperoleh rata-rata waktu 15,01 detik ,\u00a0 untuk karakter campuran diperoleh rata-rata waktu 16,19 detik , serta diperoleh rata-rata waktu keseluruhan 15,29 detik. Dari percobaan serangan terhadap ketiga jenis karakter password, diperoleh karakter campuran sebagai waktu proses terlama.\u00a0\u00a0",
        "94"
    ],
    [
        "Image Steganografi dengan Metode LSB dan SHA-512 sebagai Password untuk Penyembunyian E-Dokumen",
        "Komunikasi yang melibatkan pengirim dan penerima dokumen secara online sangat rentan terhadap kejahatan yang menyebabkan pihak yang tidak berwenang mencuri dan menyalahgunakannya. Untuk mengatasinya, diperlukan aplikasi keamanan dokumen yang dapat digunakan oleh penerima dan pengirim. Steganografi adalah metode untuk mengamankan data dengan menyembunyikan pesan pada media lain seperti image. Penelitian ini membangun aplikasiuntuk menyembunyikan dokumen kedalam image menggunakan metode Least Significant Bit (LSB) yang hanya mengubah nilai bit terakhir dengan bit pesan dan Algoritma Secure Hash (SHA) untuk perlindungan keamanan. Penggunaan kedua metode ini memberikan kombinasi keamanan dokumen yang baik. Hasil yang diperoleh oleh dokumen berhasil dimasukkan dan dapat diekstraksi secara utuh, tetapi jika gambar stego terkena serangan cropping, noise dan rotate hanya sedikit, dokumen tidak dapat diekstraksi. Nilai rata-rata kualitas gambar Mean Square Error (MSE) dari 11 sampel gambar stego adalah 0,500146 db dan Peak Signal to Noise ratio (PSNR) 51,1407502 db, semakin kecil nilai MSE, semakin baik hasil yang diperoleh pada gambar tampilan hasil, sebaliknya berlaku semakin tinggi nilai PSNR, semakin baik hasil yang diperoleh.\u00a0",
        "95"
    ],
    [
        "Pemetaan indeks kesejahteraan rakyat menggunakan metode self organizing map",
        "Kesejahteraan merupakan hak untuk setiap rakyat. Rakyat dikatakan sejahtera apabila telah terpenuhi kebutuhannya baik material, spiritual dan sosial. Salah satu indikator pengukur kesejahteraan adalah Indeks Kesejahteraan Rakyat (IKraR) yang terdiri dari 3 dimensi yaitu keadilan Sosial, Keadilan Ekonomi dan Demokrasi. Menurut data BPS, 32,53 juta jiwa (14,15%) penduduk Indonesia termasuk populasi penduduk miskin. Sehingga dibutuhkan monitoring. Salah satu upaya untuk memonitoring dan melihat pemerataan berdasarkan kemiripan adalah dengan peta dan salah satu metode yang dapat digunakan adalah metode Self Organizing Map (SOM). Penelitian ini mengambil data dari BPS, dan Statistik Profil Wisatawan Nusantara Kemenpar tahun 2016. Implementasi SOM ini dilakukan dengan pembuatan peta klaster kesejahteraan, dengan tahapan yaitu menghitung euclidean distance, menentukan winner dan neuron neighboring, memperbaharui bobot, serta memperbaharui learning rate dan radius. Hasil yang didapat dari penelitian ini berupa visualisasi empat peta klaster kesejahteraan yaitu 3 peta dimensi IKraR dan peta keluruhan indikator dari hasil klaster SOM dimana provinsi yang memiliki warna sama berada pada satu klaster. Pada penelitian ini didapatkan learning rate yang baik pada data kesejahteraan yaitu 0.4 dengan 500 iterasi, serta berdasarkan penghitungan Davies-Bouldin index didapatkan bahwa hasil cluster terbaik pada penelitian ini berada saat radius =5 dengan nilai DBI sebesar 2.137706. Dari penelitian ini, dapat di disimpulkan bahwa learning rate yang terlalu besar, akan menyebabkan hasil klaster menjadi tidak beraturan, sedangkan learning rate yang terlalu kecil membuat jumlah iterasi terlalu besar. Selain itu semakin kecil nilai DBI, maka semakin baik klaster yang diperoleh dari hasil pengelompokan.Kata kunci: Self Organizing Map, Clustering, Kesejahteraan Rakyat, Davies-Bouldin Index",
        "96"
    ],
    [
        "Analisis reliability remunerasi.uns.ac.id dengan mean time between failures (MTBF) dan metode FMEA menggunakan distribusi weibull",
        "Sistem informasi diperlukan dalam membangun sistem remunerasi yang memiliki dataset yang sangat besar, yang mana tujuannya untuk memudahkan suatu lembaga dalam mengapresiasi karyawan berupa intensif. Untuk membuat sistem informasi yang tepat diperlukan analisis yang mendalam. Dalam penelitian ini, sistem berbasis web Universitas Sebelas Maret, remunerasi.uns.ac.id, dipilih untuk dianalisis reliability-nya. Analisis reliability yang dilakukan menggunakan metode FMEA dengan Distribusi Weibull yang menjadikan MTBF sebagai parameter dari sistem akumulasi error. Berdasarkan penelitian uji reliability, sebuah sistem dapat diuji beberapa kegagalannya menggunakan Distribusi Weibull. Hasil yang didapatkan dalam penelitian ini adalah mode kegagalan yang paling tidak reliable adalah Undefined offset, dengan nilai t sebesar 19448,87 second, nilai ???? sebesar 0,55, dan nilai ? sebesar 16390,16. Kegagalan dapat terjadi pada fungsi ini karena array yang tersedia kurang dari array yang dipanggil, sehingga menyebabkan fitur tidak berfungsi. Diperlukan adanya penelitian lebih lanjut rekomendasi sistem untuk memperbaiki kode sumber.Kata kunci: remunerasi, SQA, Reliability, FMEA, MTBF, Distribusi Weibull\u00a0",
        "97"
    ],
    [
        "Klasifikasi data twitter menggunakan metode multinomial Naive bayes untuk pemetaan penyakit tropis di Indonesia",
        "ABSTRAKPenyakit Tropis adalah penyakit yang biasanya ditemukan pada daerah tropis dan sub-tropis.\u00a0 Tujuan\u00a0 dari\u00a0 penelitian\u00a0 ini\u00a0 adalah\u00a0 membuat\u00a0 peta\u00a0 penyakitberdasarkan data\u00a0 yang\u00a0 diambil\u00a0 dari\u00a0 Twitter\u00a0 untuk\u00a0 membantu\u00a0 pengambilan\u00a0 keputusan\u00a0 penting terhadap kondisi kesehatan di Indonesia. Klasifikasi data Twitter dilakukan dengan dua\u00a0 tahap,\u00a0 keduanya\u00a0 menggunakan\u00a0 metode\u00a0 Multinomial\u00a0 Naive\u00a0 Bayes.\u00a0 Tahap pertama adalahklasifikasi untuk menyaring tweet yang tidak berbahasa Indonesia dan tahap kedua adalah klasifikasi untuk mendapatkan data penyebaran penyakit. Hasilnya menunjukkan hasil akurasi tinggi pada jenis penyakit dan lokasi data yang kemudian ditampilkan dalam bentuk peta.Kata kunci: Klasifikasi, Pemetaan, Multinomial Naive Bayes, Penyakit Tropis.",
        "98"
    ],
    [
        "Penjadwalan kedatangan dan keberangkatan pesawat pada aircraft sequencing problem menggunakan algoritma greedy",
        "ABSTRAKKeterlambatan\u00a0 adalah\u00a0 bagian\u00a0 penting\u00a0 dari Aircraft\u00a0 Sequencing\u00a0 Problemyang memiliki\u00a0 pengaruh\u00a0 besar\u00a0 dalam\u00a0 dunia\u00a0 penerbangan.\u00a0 Masalah\u00a0 tersebut\u00a0 dapat dimodelkan sebagai sebuah masalah penjadwalan mesin paralel yang sama, dengan landasan menjadi mesin dan pesawat menjadi pekerjaan. Setiap pesawat memiliki tipe\u00a0 operasi,\u00a0 tipe\u00a0 pesawat,\u00a0 penalty\u00a0 (fuel\u00a0 burn), ready\u00a0 time,deadline,\u00a0\u00a0 taxi\u00a0 time, runway\u00a0 occupancy\u00a0 timedan\u00a0 pengurutan yang tergantung separation\u00a0 timeuntuk menghindari tabrakan.Aircraft\u00a0\u00a0 Sequencing\u00a0\u00a0 Problemmenugaskan\u00a0\u00a0 setiap\u00a0\u00a0 pesawat\u00a0\u00a0 untuk\u00a0\u00a0 sebuah landasan, mengurutkan\u00a0\u00a0 pesawat, serta menentukan\u00a0\u00a0 waktu\u00a0\u00a0 kedatangan\u00a0\u00a0 dan keberangkatan pesawat pada landasan terpilih.Memperkecil total delay costadalah fungsi tujuan dalam menjadwalkankedatangan dan keberangkatan pesawat sedekat mungkin dengan target time-nya. Algoritma Greedy dengan earliest deadline fisrtdan fast\u00a0 priority\u00a0 indexditerapkan\u00a0 untuk\u00a0 memperkecil total\u00a0 delay\u00a0 costdari kedatangan\u00a0 dan\u00a0 keberangkatan\u00a0 pesawat\u00a0 secara\u00a0 bersamaan.Total\u00a0 delay\u00a0 costyang dihasilkan dibandingkan\u00a0 untuk menentukan kualitas\u00a0 solusi dan kinerjanyayang dievaluasi berdasarkan waktu eksekusi.Kata kunci: Aircraft Sequencing Problem,Air Traffic Contoller,fuel burn, GreedyAlgorithms, Total Delay Cost",
        "99"
    ],
    [
        "Prediksi harga kebutuhan pokok nasional menggunakan average based fuzzy time series dengan pendekatan Song \u2013Chissom dan Markov Chain",
        "ABSTRAKKebutuhan\u00a0 pokok\u00a0 merupakan\u00a0 komoditas\u00a0 strategis\u00a0 yang\u00a0 memegang\u00a0 peranan penting dalam aspek ekonomi, sosial, bahkan politik di berbagai negara termasuk Indonesia.\u00a0 Kebutuhan pokok\u00a0 berpengaruh\u00a0 terhadap\u00a0 hajat\u00a0 hidup\u00a0 orang\u00a0 banyak dengan\u00a0 skala\u00a0 pemenuhan\u00a0 kebutuhan\u00a0 yang\u00a0 tinggi\u00a0 serta\u00a0 menjadi\u00a0 faktor\u00a0 pendukung kesejahteraan\u00a0\u00a0 masyarakat. Permasalahan\u00a0\u00a0 klasik\u00a0\u00a0 dalam\u00a0\u00a0 rangka\u00a0\u00a0 pemenuhan kebutuhan\u00a0\u00a0 pokok\u00a0\u00a0 adalah\u00a0\u00a0 fluktuasi\u00a0\u00a0 harga\u00a0\u00a0 kebutuhan\u00a0\u00a0 pokok.\u00a0\u00a0 Kenaikan\u00a0\u00a0 harga kebutuhan\u00a0 pokok\u00a0 ini\u00a0 merupakan\u00a0 faktor\u00a0 pemicu\u00a0 utama\u00a0 inflasi. Untuk\u00a0 mengatasi permasalahan tersebut, salah satu upaya yang dilakukan pemerintah adalah dengan kebijakan\u00a0\u00a0 stabilisasi\u00a0\u00a0 harga\u00a0\u00a0 kebutuhan\u00a0\u00a0 pokok\u00a0\u00a0 agar\u00a0\u00a0 petani\u00a0\u00a0 sebagai\u00a0\u00a0 produsen mendapatkan\u00a0 hasil\u00a0\u00a0 yang\u00a0 menguntungkan\u00a0 dan\u00a0 masyarakat\u00a0 sebagai\u00a0 konsumen mampu\u00a0\u00a0 membeli\u00a0\u00a0 kebutuhan\u00a0\u00a0 pokok\u00a0\u00a0 dengan\u00a0\u00a0 harga\u00a0\u00a0 yang\u00a0\u00a0 terjangkau.Untuk mengakomodasi\u00a0\u00a0\u00a0 hal\u00a0\u00a0\u00a0 tersebut diperlukan\u00a0\u00a0\u00a0 suatu\u00a0\u00a0\u00a0 langkah\u00a0\u00a0\u00a0 peramalan\u00a0\u00a0\u00a0 untuk memprediksi harga kebutuhan pokok.Penelitian\u00a0 ini\u00a0 bertujuan\u00a0 untukmelakukanprediksi\u00a0 harga\u00a0 kebutuhan\u00a0 pokok Nasional menggunakanmetode Average\u00a0\u00a0 BasedFuzzy\u00a0\u00a0 Time\u00a0\u00a0 Seriesdengan pendekatan Song \u2013Chissomdan Markov Chain. Data yang digunakan adalah harga kebutuhan pokok Nasional periode mingguan dari tahun 2015s.d2017. Data dibagi menjadidua tahap:data trainingdan testingdengan rasio 90:10.Berdasarkan nilai MAPE\u00a0 dan\u00a0 uji\u00a0 kelayakan,\u00a0 diperoleh\u00a0 kesimpulan\u00a0 bahwa\u00a0 metode Average\u00a0 Based Fuzzy\u00a0 Time\u00a0 Seriesdengan\u00a0 pendekatanMarkov Chainlebih\u00a0 baik\u00a0 dibandingkan dengan\u00a0 pendekatan\u00a0 Song \u2013Chissom untuk melakukan prediksiharga\u00a0 kebutuhan pokok nasional.Kata\u00a0 kunci: average\u00a0 based\u00a0 interval, fuzzy\u00a0 time\u00a0 series,\u00a0 harga\u00a0 kebutuhan\u00a0 pokok nasional, markovchain, prediksi",
        "100"
    ],
    [
        "Penerapan metode hybrid collaborative filtering menggunakan nilai cosine dan missing value algorithm untuk memprediksi nilai rating",
        "Penelitian ini menggunakan metode algoritma cosine dan missing value algorithm (MVA) bertujuan untuk mencari nilai prediksi rating pada data Jester Recommender System. Data set yang didapatkan dari Jester Recommender System memiliki data user, data item, dan data rating didalamnya. Data tersebut akan dilakukan reduksi dengan menggunakan metode algoritma cosine. Penggunaan metode algoritma cosine bertujuan untuk mencari user dan item yang mempunyai nilai cosine yang tinggi. Setelah mendapat nilai cosine antar user dan item kemudian dilakukan reduksi data. Data yang sudah direduksi akan menjadi data yang akan diolah dengan menggunakan metode MVA untuk mencari nilai prediksi rating. Pengujian terhadap penelitian ini dilakukan dengan menggunakan Mean Absolute Error (MAE) dan menghitung nilai error dengan menggunakan Normalized Mean Absolute Error (NMAE). Perhitungan dilakukan dengan membandingan nilai rating prediksi dengan nilai rating sesungguhnya. Berdasarkan perhitungan evaluasi yang telah dilakukan untuk data simulasi didapatkan rata-rata nilai MAE sebesar 0.480964 dan nilai NMAE sebesar 0.025803, sedangkan untuk data eksperimen didapatkan rata-rata nilai MAE sebesar 0.32767 dan NMAE sebesar 0.01696. Hasil tersebut menunjukan bahwa nilai prediksi yang didapatkan memiliki tingkat error yang tidak terlalu tinggi.Kata Kunci : Nilai Cosine, Missing Value Algorithm, Prediction Rating\u00a0",
        "101"
    ],
    [
        "Simulasi Pemotongan Papan Kayu dengan Metode Full Taper Cant Sawing",
        "Kayu merupakan sumber bahan baku utama yang dibutuhkan oleh pabrik kayu. Proses awal pengolahan kayu adalah pemotongan dari kayu gelondangan menjadi papan. Permasalahan yang biasanya dihadapi pabrik kayu adalah pabrik menggunakan bahan baku secara tidak efisien. Hal ini karena terbatasnya pengetahuan dan informasi dalam pengolahan kayu seperti teknik pemotongan kayu.Dalam penelitian ini digunakan algoritma Greedy Integer knapsack dengan metode Full Taper Cant Sawing, untuk simulasi pemotongan kayu, ukuran kayu gelondongan radius kecil 6cm, 8cm,10cm radius besar 8cm, 10cm, 12cm.Sebuah ukuran cant dibatasi pada lebar 8cm, 10cm, 12cm dengan ketinggian 6cm, 8cm, 10cm sedangkan ukuran papan dihasilkan adalah lebar 3-5cm dan tinggi 2-3cm.Hasil simulasi menunjukkan bahwa hasil pemotongan kayu yang lebih optimal.\u00a0",
        "102"
    ],
    [
        "Sistem rekomendasi pariwisata dengan menggunakan algoritma apriori positif negatif dan binary hamming distance ",
        "ABSTRAKSaat ini banyak orang yang melakukan perjalanan wisata untuk mengisi liburan atau waktu kosong, dengan adanya sistem ini diharapkan dapat membantu pengguna dalam menentukan tempat wisata yang tepat agar tidak membuang waktu di perjalanan. Penelitian ini bertujuan untuk membuat sistem yang dapat merekomendasikan tempat wisata berdasarkan keadaan pengguna dan wisata yang terdekat dengan lokasi pengguna dan memberikan informasi tempat wisata yang akan dikunjungi. \u00a0Penelitian ini menggunakan algoritma apriori positif negative dan Binary Hamming distance dalam menentukan rekomendasi tempat wisata yang akan diberikan. Inputan user yang digunakan adalah berupa isian pada kuesioner yang kemudian akan diolah dengan menggunakan binary hamming distance untuk melihat kecocokan atau kedekatan dengan data yang sudah dimiliki sehingga sistem bisa memberikan rekomendasi yang sesuai. Sedangakan apriori positif negative digunakan untuk mendapatkan nilai untuk tiap kategori tempat wisata. Pengujian dilakukan dengan menggunakan UET (User Experience Training) dan didapat nilai kelayakan sistem oleh pengguna sebesar 75,2%\u00a0 sehingga sistem ini disebut layak digunakan dan mendapat nilai 78% untuk pengujian hasil rekomendasi sehingga dapat memberikan rekomendasi yang layak dan cukup sesuai.Kata Kunci: Rekomendasi, Tempat Wisata, Apriori Positif Negatif, Binary Hamming distance\u00a0",
        "103"
    ],
    [
        "Implementasi internet of things pada sistem monitoring temperatur dan kelembapan udara pada ruang server ",
        "ABSTRAKSistem monitoring suhu dan kelembaban untuk ruang server yang sudah dibuat adalah sistem berbasis IoT, yang memberikan informasi suhu dan kelembapan udara di dalam ruang server. Ada dua jenis sensor yang digunakan pada ruang server, yaitu suhu dan kelembaban. Sistem ini dapat digunakan untuk memonitor suhu atau kelembapan di ruang server. Sistem yang diusulkan terus mengirimkan data ke cloud untuk memantau data dari mana saja. Node atau Device yang digunakan adalah modul Raspberry dan Arduino. Sensor suhu dan kelembapan (DHT22) terhubung ke Raspberry. Setiap kali nilai sensor melebihi ambang batas yang dipilih, sistem akan memberikan notifikasi kepada pengguna melalui aplikasi telegram dengan memanfaatkan API Telegram dan dapat mengatur suhu pada ruang server dengan menggunakan Arduino. Sistem yang diajukan secara efektif dapat memonitor dan secara dinamis mengontrol perintah melalui aplikasi pada web server. Dalam pengujian kalibrasi, pada ruang server BAA-BAPSI rata-rata selisih suhu yang didapat antara sensor dengan thermometer adalah sebanyak 0.67 ? dan selisih kelembapan udara yang didapat antara sensor dengan hygrometer adalah sebanyak 29,88 %. Sedangkan pada ruang magang BAA-BAPSI rata-rata selisih suhu yang didapat antara sensor dengan thermometer adalah sebanyak 0.17 ? dan selisih kelembapan udara yang didapat antara sensor dengan hygrometer adalah sebanyak 27,66 %. Untuk pengujian respon aktuator, untuk ruang server BAA-BAPSI dalam waktu 20 menit dapat menaikkan suhu sebanyak 3,8 ?. sedangkan pada ruang magang BAA-BAPSI dapat menaikkan suhu sebanyak 0,8 ?. Pada simulation experiment sistem dilakukan dengan melakukan beberapa request yang diasumsikan sebagai jumlah node pada empat kasus. Pengujian pada kasus pertama, sistem dapat dipakai secara optimal hingga 300 node dengan menerapkan threshold 500ms. Pada kasus kedua, sistem dapat dipakai secara optimal sampai 300 node dengan menerapkan threshold 500 ms. Pada kasus ketiga, sistem dapat dipakai secara optimal sampai 300 node dengan menerapkan threshold 500 ms. Pada kasus keempat, sistem dapat dipakai secara optimal sampai 150 node dengan menerapkan threshold 400 ms.Kata kunci: IoT, Monitoring, Sensor, Aktuator\u00a0",
        "104"
    ],
    [
        "Safedio : Deteksi Konten Youtube Berunsur Pornografi dengan Judul yang Mengandung Bahasa Gaul (Alay) Menggunakan Pendekatan Query Expansion dan Rule Based",
        "ABSTRAKPendeteksian konten pornografi di internet masih jarang dilakukan di Indonesia dan belum bekerja dengan sangat baik. Portal video terbesar Youtube pun belum memiliki deteksi pornografi secara otomatis melalui kontennya. Beberapa website penyedia layanan pencegahan pornografi di Indonesia seperti Internet Positif dan Nawala Project mendeteksi pornografi menggunakan metode deteksi keyword dari suatu halaman web lalu memblokir halaman web tersebut dengan DNS filtering. Namun metode yang digunakan belum memperhatikan penggunaan bahasa Alay yang dapat digunakan untuk menyembunyikan kata berunsur pornografi. Penelitian ini membuat metasearch Safedio untuk mendeteksi pornografi pada konten Youtube melalui judul video yang mengandung bahasa Alay dengan menggunakan pendekatan Query Expansion dan Rule Based. Query Expansion adalah teknik perluasan kueri untuk mendapatkan aturan tambahan dalam pencarian. Rule Based merupakan metode yang membuat rule untuk menyelesaikan masalah sesuai dengan kebutuhan. Metasearch Safedio dapat mendeteksi konten pornografi melalui judul video baik dalam bahasa Indonesia standar maupun bahasa Alay. Hasil pengujian dari dataset random, dataset non Alay, dan dataset Alay mendapatkan hasil yang cukup baik dengan nilai precision sebesar 71%, nilai recall sebesar 46%, dan nilai accuracy sebesar 72%.Kata Kunci : Bahasa Alay, Deteksi pornografi, Konten Youtube, Rule Based, Query Expansion.",
        "105"
    ],
    [
        "FoFA: Penerapan Teknologi Semantik pada Aplikasi Berbasis Android Mengenai Informasi Diet untuk Penderita Autisme",
        "ABSTRAKJumlah penyandang autisme di Indonesia bertambah 0,15% atau 6.900 anak per tahun. Salah satu tindakan atau usaha yang dapat dilakukan untuk mengatasi gangguan perkembangan anak penyandang autisme yaitu dengan melakukan Feingold and Failsafe Diet, Specific Carbohydrate Diet (SCD diet) dan Casein Free Gluten Free diet (CFGF diet). Perlu adanya sosialisasi dan penyajian informasi terkait pengaturan bahan makanan dan minuman yang diberikan kepada anak penyandang autisme. Saat ini belum ada penyajian informasi dalam bentuk aplikasi berbasis mobile yang menjadi forum orang tua dalam bertukar informasi terlebih yang memanfaatkan teknologi semantik. Dengan memanfaatkan teknologi semantik, aplikasi Food For Autism (FoFA) dibuat untuk sharing knowledge bagi pengguna terkait menu diet makanan dan minuman bagi penderita autisme. Dari hasil pengujian black box dan pengujian performance menunjukkan bahwa aplikasi FoFA dapat menerapkan teknologi semantik terkait menu diet makanan dan minuman bagi penderita autisme. Aplikasi FoFA dapat mengakses ontologi, sharing knowledge dan menambah data ontologi.\u00a0Kata Kunci: Autisme, Feingold and Failsafe Diet, Spesific Carbohydrate Diet, Casein Free Gluten Free Diet, Mobile, Teknologi Semantik, Ontologi\u00a0",
        "106"
    ],
    [
        "Implementasi Vektor Space Model Dengan Metode Cosine Similarity Dan Conditional Probability Untuk Sistem Deteksi Plagiarisme Dokumen Skripsi Mahasiswa",
        "ABSTRAKPlagiarisme merupakan salah satu contoh dari dampak negatif yang muncul akibat perkembangan internet yang sangat cepat. Plagiarisme dapat terjadi di berbagai tempat, salah satu contohnya yaitu di Perguruan Tinggi. Hal ini tentunnya dapat merugikan berbagai pihak. Oleh karena itu, diperlukan sistem deteksi yang dapat mencegah terjadinya tindak plagiarisme. Pada penelitian ini, akan dibuat suatu sistem deteksi plagiarisme dengan mengimplementasikan Vector Space Model. Cosine Similarity digunakan untuk meranking paragraf-paragraf berdasarkan pada nilai sudut yang terbentuk antara vector query dan vector library. Banyak kata yang diambil oleh paragraf query akan dihitung dengan menggunakan teori Conditional Probability. Setelah dilakukan pengujian, maka dapat diambil kesimpulan bahwa VSM dapat diimplementasikan pada sistem. Terdapat 10 paragraf testing yang akan dibandingkan dengan paragraf koleksi. Hasil perbandingan menunjukkan nilai sebesar 65.05% untuk rata-rata nilai precision dan98.57% untuk rata-rata recall dengan threshold yang digunakan adalah 0.3 untukconditional probability dan 0.25 untuk Cosine Similarity.Kata\u00a0 Kunci\u00a0 :\u00a0 plagiarisme,\u00a0 paragraf,\u00a0 Vector\u00a0 Space\u00a0 Model,\u00a0 Cosine\u00a0 Similarity,Conditional Probability, precision, recall, threshold",
        "107"
    ],
    [
        "Penerapan group-average dan cosine similarity  untuk clustering dokumen (studi kasus: tugas akhir mahasiswa S1 informatika UNS)",
        "ABSTRAK\u00a0Jumlah koleksi dokumen tugas akhir di Program Studi Informatika UNS semakin bertambah, tetapi koleksi dokumen tugas akhir tersebut belum dimanfaatkan secara maksimal. Padahal jika diolah dengan mengelompokkan dokumen tugas akhir berdasarkan kemiripan topik, koleksi dokumen tugas akhir tersebut dapat memberikan manfaat bagi dosen maupun mahasiswa. Pada penelitian ini, dilakukan clustering terhadap dokumen tugas akhir di Program Studi Informatika UNS menggunakan metode Group-Average dan Cosine Similarity. Bagian dokumen yang diolah adalah bab 2 yang berisi tinjauan pustaka. Jumlah koleksi dokumen yang digunakan adalah 110 dokumen. Hasil clustering menggunakan metode Group-Average menghasilkan 10 cluster dengan ketidaksesuaian dokumen sebanyak 8 dokumen. Analisis dilakukan secara subyektif dengan melihat kemiripan topik berdasarkan judul antara dokumen yang satu dengan dokumen yang lain dalam satu cluster. Hasil analisis menunjukkan bahwa kemiripan metode yang digunakan dan studi kasus yang diangkat di dalam penelitian tugas akhir mempengaruhi hasil pembentukan cluster.\u00a0Kata Kunci : Clustering, Cosine Similarity, Group-Average, Text Preprocessing",
        "108"
    ],
    [
        "Automatic Text Summarization dengan kategorisasi pada berita online mengenai tokoh masyarakat indonesia dengan metode Fuzzy Logic",
        "Tokoh masyarakat adalah orang yang terkemuka dan memiliki nama besar dalam berbagai bidang kehidupan di masyarakat yang dapat dijadikan contoh serta diteladani sifat-sifat baiknya oleh masyarakat. Oleh karena itu, masyarakat memerlukan informasi yang cukup mengenai latar belakang seorang tokoh agar masyarakat dapat menilai apakah tokoh tersebut patut diteladani atau tidak. Media massa memiliki peran dalam menyediakan informasi bagi masyarakat, profil tokoh masyarakat menjadi salah satunya. Automatic text summarization dengan kategorisasi merupakan bentuk peringkasan teks secara otomatis dengan menggunakan sejumlah teks terstrukut dengan tata bahasa yang rapi dengan efisien dan cepat. Tujuan dari penelitian ini adalah membantu pengguna dalam mencari informasi mengenai profil tokoh masyarakat dari sekian banyak artikel berita yang tersedia agar dapat menghemat waktu dan mempermudah dalam memahami inti sebuah artikel berita.\u00a0 Penelitian ini menggunakan pendekatan Fuzzy Logic dengan metode Sugeno Orde-Nol untuk menarik kesimpulan berupa hasil ringkasan yang terdiri dari kalimat penting dalam sebuah artikel. Pengujian kepada pakar sastra Bahasa Indonesia menunjukan bahwa pengaplikasian automatic text summarization dengan kategorisasi terbukti sudah dapat memberikan ringkasan berita online yang sudah dapat dimengerti, mengandung informasi penting dari artikel terkait, kategorisasi berita dan kategorisasi tokoh sudah sesuai dan dinilai dapat menghemat waktu secara efisien",
        "109"
    ],
    [
        "Penerapan Jaro-Winkler Distance dan Na\u00efve Bayes Classifier untuk Sistem Identifikasi Hama dan Penyakit pada Tanaman Padi",
        "ABSTRAK\u00a0Identifikasi hama dan penyakit tanaman padi diperlukan untuk menentukan pengendalian yang dapat dilakukan. Pengendalian hama dan penyakit yang kurang tepat seperti penggunaan pestisida berlebihan dan berkepanjangan dapat menyebabkan dampak buruk bagi tanaman padi itu sendiri. Penelitian ini bertujuan untuk membuat sebuah sistem yang dapat mengidentifikasi hama dan penyakit tanaman padi serta memberikan solusi alternatif penanggulangan yang dapat dilakukan pada hama dan penyakit yang menyerang tanaman padi.Penelitian ini menggunakan metode Jaro-Winkler Distance dan Naive Bayes Classifier dalam mengidentifikasi hama dan penyakit tanaman padi. Dalam penelitian ini digunakan input tekstual berisi gejala penyakit sebagai input sistem. Metode Jaro-Winkler Distance digunakan untuk identifikasi input gejala dan metode Naive Bayes Classifier untuk identifikasi ouput hasil hama atau penyakit yang diderita tanaman padi. Pengujian dilakukan sebanyak sepuluh kali dengan metode k-fold cross validation dan didapatkan hasil akurasi keseluruhan sebesar93%, sedangkan untuk nilai precision sebesar 94?n recall sebesar 92%.Kata\u00a0 Kunci:\u00a0 Hama\u00a0 dan\u00a0 Penyakit\u00a0 Padi,\u00a0 Jaro-Winkler\u00a0 Distance,\u00a0 Naive\u00a0 BayesClassifier",
        "110"
    ],
    [
        "Association Rule untuk Menentukan Pola Pasien Rawat Inap Menggunakan Algoritma FP-Growth (Studi Kasus RSUD Sukoharjo)",
        "ABSTRAKRumah sakit setiap harinya mengumpulkan sejumlah besar data dengan berbagai atribut. Sejumlah besar data dengan berbagai atribut akan memiliki pola yang menarik. Dengan mengetahui polanya, ini dapat memberikan informasi tentang pola pasien rawat inap. Pola data dapat ditemukan dengan menggunakan teknik data mining. Association Rule merupakan salah satu teknik yang dapat digunakan untuk mencari pola data dalam data mining. Salah satu algoritma yang dapat digunakan untuk memecahkan masalah aturan asosiasi adalah FP-Growth. Penelitian ini difokuskan pada implementasi algoritma FP-Growth untuk menemukan pola Assocation antara atribut data rekam medis rawat inap. FP-Growth digunakan karena memiliki kinerja yang lebih baik dibanding apriori. Hasil dari penelitian ini berupa pola hubungan antar atribut data pasien rawat inap yang meliputi jenis kelamin, kelompok umur, pekerjaan, durasi dirawat di rumah sakit, kelas, dan diagnosa utama. Penelitian ini menghasilkan beberapa pola asosiasi pasien rawat inap. Pola asosiasi yang ditemukan ini memberikan informasi yang beraneka ragam mengenai pola pasien rawat inap. Dengan melakukan analisis secara subjektif terhadap informasi-informasi ini dapat menjadi pendukung keputusan untuk menjaga bahkan meningkatkan kualitas dari RSUD Sukoharjo.Kata kunci: Association Rule, FP-Growth, Pasien Rawat Inap, Rumah Sakit\u00a0",
        "111"
    ],
    [
        "Optimasi Fuzzy Tsukamoto Dua Tahap Menggunakan Algoritma Genetika Untuk Seleksi Calon Karyawan (Studi Kasus: Perusahaan Bio-2000) ",
        "ABSTRAKKaryawan merupakan elemen penting dalam suatu perusahaan yang menentukan kemajuan suatu perusahaan. Tanpa kualitas karyawan yang baik dalam suatu perusahaan, maka sulit bagi perusahaan tersebut untuk mendapatkan hasil yang optimal dalam menjalankan perusahaan tersebut. Diperlukan sebuah sistem untuk pendukung keputusan dalam proses seleksi calon karyawan dengan menggunakan Fuzzy Tsukamoto dua tahap dan Algoritma Genetika untuk optimasi fungsi keanggotaan Fuzzy. Sistem penerimaan calon karyawan ini berfungsi untuk mendapatkan hasil yang optimal dalam menentukan suatu karyawan perusahaan. Tugas akhir ini membahas mengenai sistem pendukung keputusan seleksi calon karyawan yang menggunakan metode Fuzzy Tsukamoto dua tahap dengan kriteria penilaian tes kecakapan, tes kepribadian, informasi biografi, wawancara, umur dan riwayat penyakit. Metode Fuzzy Tsukamoto dua tahap digunakan untuk melakukan proses perhitungan pendukung keputusan sedangkan Algoritma Genetika digunakan untuk optimalisasi fungsi keanggotaan Fuzzy. Berdasarkan hasil uji coba pada penelitian ini, sistem pendukung keputusan seleksi calon karyawan ini memiliki nilai akurasi yang signifikan sebesar 76?ngan ukuran populasi sebesar 80 individu dan nilai crossover rate dan mutation rate masing-masing sebesar 0.5 dan 0.5.Kata Kunci : Algoritma Genetika (AG), FIS Tsukamoto, Seleksi Karyawan\u00a0",
        "112"
    ],
    [
        "Analisis Perbandingan Metode Saw dan Topsis pada Pemilihan Open Source LMS Berdasarkan Faktor Kualitas Perangkat Lunak",
        "AbstrakSebagian\u00a0 implementasi\u00a0 Learning\u00a0 Management\u00a0 System\u00a0 (LMS)\u00a0 untuk\u00a0 e- learning mengalami kegagalan yang disebabkan pemilihan platform LMS yang tidak tepat oleh pemangku kepentingan. LMS sebagai perangkat lunak memiliki faktor kualitas seperti perangkat lunak lainnya. Permasalahannya, tidak semua pemangku kepentingan mengetahui mengenai pentingnya faktor kualitas sebagai parameter pemilihan platform LMS\u00a0 yang sesuai. Hal ini mendorong perlunya aplikasi untuk memilih LMS dengan faktor kualitas perangkat lunak sebagai parameter pemilihannya. Pada penelitian pemilihan LMS dilakukan dengan menerapkan metode SAW dan TOPSIS. Sebagai metode Multi Criteria Decision Making (MCDM) yang banyak digunakan, SAW dan TOPSIS diharapkan memberikan hasil keputusan yang konsisten. Sehingga pada penelitian ini dilakukan perbandingan metode SAW dan TOPSIS pada pemilihan LMS dengan analisis korelasi.Pada penelitian digunakan Top 8 Open Source LMS, antara lain : ATutor, Chamilo, Dokeos, eFront, FormaLMS, ILIAS, Moodle dan Opigno yang dipilih dengan parameter delapan Faktor Kualitas ISO/IEC 25010. Langkah awal adalah mengumpulkan kode sumber Open Source LMS untuk selanjutnya diukur faktor kualitasnya dengan menggunakan PhpMetrics tools. Selanjutnya dilakukan pemilihan\u00a0\u00a0 menggunakan\u00a0\u00a0 metode\u00a0\u00a0 SAW\u00a0\u00a0 dan\u00a0\u00a0 TOPSIS\u00a0\u00a0 dengan\u00a0\u00a0 menerapkan perubahan bobot kriteria. Hasil keputusan metode SAW dan TOPSIS dianalisis dengan Korelasi Pearson\u00a0 dan Korelasi Spearman untuk membandingkan kedua metode tersebut. Hasil pemilihan menunjukkan ILIAS menduduki peringkat pertama dan FormaLMS menduduki peringkat kedua. Sedangkan hasil analisis perbandingan menunjukkan bahwa Koefisien Korelasi Pearson adalah 0.90107 dan Koefisien Korelasi Spearman adalah 0,82440. Nilai koefisien tersebut menujukkan adanya hubungan yang erat antara metode SAW dan TOPSIS, yang berarti hasil keputusan kedua metode tersebut setara dan konsisten.Kata Kunci : Learning Management System (LMS), SAW, TOPSIS,\u00a0\u00a0 KorelasiPearson, Korelasi Spearman",
        "113"
    ],
    [
        "Rancang Bangun Aplikasi Manajemen Rapat di DPRD Kota Surakarta dengan Menggunakan Metode Scrum",
        "AbstrakSalah satu tugas pokok Sekretariat DPRD Kota Surakarta adalah melakukan persiapan pelaksanaan dan pelayanan administrasi di bidang rapat dan risalah. Saat ini dalam pelaksanan tugas tersebut terdapat beberapa kekurangan seperti pengelolaan hasil rapat yang masih dilakukan secara manual dan tidak terindeks dengan baik yang menyebabkan pengelolaan dokumentasi hasil rapat menjadi tidak efektif dan efesien. Untuk mengatasi permasalahan ini maka dibutuhkan Aplikasi Manajemen Rapat untuk mempermudah tugas pendamping rapat dan bagian rapat dan peraturan perundangan menjadi lebih efektif dan efisien. Pengembangan aplikasi ini menggunakan konsep Agile Process Development dengan menggunakan metode Scrum. Metode Scrum yang digunakan dapat menghasilkan produk yang sesuai dengan keinginan pengguna karena mendapatkan feedback secara kontinu. Tahapan pengembangan aplikasi meliputi: pembuatan product backlog, sprint backlog, pelaksanaan sprint, dan sprint review. Hasil dari penelitian ini adalah terbangunnya Aplikasi Manajemen Rapat yang memenuhi kebutuhan fungsional yang diinginkan oleh Sekretariat DPRD Kota Surakarta. Aplikasi Manajemen Rapat mampu memonitor rapat dan dokumentasinya sehingga mudah diakses dan diinformasikan kepada pihak-pihak terkait untuk dapat ditindaklanjuti. Dari hasil perhitungan rata-rata focus factor didapat nilai 0.78 atau 78%, sehingga tingkat presentase pengembang fokus mengerjakan aplikasi adalah 78%.Kata Kunci : Agile, Focus Factor, Process Development, Rapat, Scrum",
        "114"
    ]
]