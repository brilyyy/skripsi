{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all links to the detail page from digilib.uns.ac.id\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup as bs\n",
    "# import pyquery\n",
    "# import time\n",
    "# import json\n",
    "# import concurrent.futures\n",
    "\n",
    "# links = []\n",
    "\n",
    "# abstracts_data = []\n",
    "\n",
    "# pages = 1809\n",
    "\n",
    "# MAX_THREADS = 50\n",
    "\n",
    "# def get_link(page):\n",
    "#   res = requests.get(f'https://digilib.uns.ac.id/dokumen/fakultas/7/Fak-KIP/{page}')\n",
    "#   html_page = bs(res.content, 'html.parser')\n",
    "#   document_cards = html_page.select(\n",
    "#       '#digilib-body > div > div > div.col-md-8 > div.mb-5')\n",
    "#   for card in document_cards:\n",
    "#     document_type = card.select(\n",
    "#         '.dokumen-search-body .detail div:nth-child(2)')[0].text.strip().lower()\n",
    "#     if(document_type == 'skripsi'):\n",
    "#       anchor = card.find('a')\n",
    "#       if 'https://digilib.uns.ac.id/dokumen/detail/' in anchor.get('href'):\n",
    "#           links.append(anchor['href'])\n",
    "\n",
    "# def get_detail_links():\n",
    "#   with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "#       executor.map(get_link, range(1, pages + 1))\n",
    "#   with open('detail_links.json', 'w') as output:\n",
    "#     output.write(json.dumps(links, indent=4, sort_keys=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get abstract and title from detail page\n",
    "# def get_abstract_and_title(link):\n",
    "  \n",
    "#   res = requests.get(link)\n",
    "#   html_page = bs(res.content, 'html.parser')\n",
    "#   table = html_page.find('table', {'class': 'table table-responsive'})\n",
    "#   table_trs = table.find_all('tr')\n",
    "#   nim = table_trs[2].text.strip()\n",
    "#   if 'K35' in nim or 'K.35' in nim or 'K. 35' in nim or 'K 35' in nim:\n",
    "#     print('==============================')\n",
    "#     print(\n",
    "#         f'Getting abstract from link: {link} \\n')\n",
    "#     tdabstrak = table_trs[13].find_all('td')\n",
    "#     tdjudul = table_trs[4].find_all('td')\n",
    "#     abstract = tdabstrak[2].get_text()\n",
    "#     title = tdjudul[2].get_text()\n",
    "\n",
    "#     abstracts_data.append({\n",
    "#         'title': title,\n",
    "#         'abstract': abstract,\n",
    "#     })\n",
    "#   else:\n",
    "#     print('==============================')\n",
    "#     print(\n",
    "#         f'Link skipped: {link} \\n')\n",
    "#     time.sleep(1)\n",
    "\n",
    "\n",
    "# def add_id_to_abstract(i):\n",
    "#   abstracts_data[i]['id'] = i + 1\n",
    "\n",
    "\n",
    "# def get_abstracts():\n",
    "#   with open('detail_links.json', 'r') as input:\n",
    "#     links_from_json = json.load(input)\n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "#         executor.map(get_abstract_and_title, (link for link in links_from_json))\n",
    "#     with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "#         executor.map(add_id_to_abstract,\n",
    "#                      (i for i in range(len(abstracts_data))))\n",
    "#     with open('abstracts_data.json', 'w') as output:\n",
    "#       output.write(json.dumps(abstracts_data, indent=4, sort_keys=True))\n",
    "\n",
    "\n",
    "# get_abstracts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "\n",
    "def progress_bar():\n",
    "    return progressbar.ProgressBar(maxval=78, widgets=[\n",
    "        ' [', progressbar.Timer(), '] ',\n",
    "        progressbar.Bar(marker='0', left='[', right=']'),\n",
    "        ' (', progressbar.ETA(), ') ',\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " [Elapsed Time: 0:00:00] [00000000000000000000000000000000000] (Time: 0:00:00) \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case folding done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# case folding\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "import concurrent.futures\n",
    "import progressbar\n",
    "\n",
    "\n",
    "processed = []\n",
    "count = 0\n",
    "with open('data/abstracts_data.json') as abstracts_json:\n",
    "  abstracts = json.load(abstracts_json)\n",
    "\n",
    "bar = progress_bar()\n",
    "bar.start()\n",
    "\n",
    "for i, abstract in enumerate(abstracts):\n",
    "  bar.update(i + 1)\n",
    "  answer = re.sub('[^a-z]+', ' ', abstract['abstract'].casefold())\n",
    "  abstracts[i]['abstract'] = answer\n",
    "\n",
    "with open('data/case_folded.json', 'w') as outfile:\n",
    "\toutfile.write(json.dumps(abstracts, sort_keys=True, indent=4))\n",
    "  \n",
    "bar.finish()\n",
    "print('Case folding done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " [Elapsed Time: 0:00:02] [00000000000000000000000000000000000] (Time: 0:00:02) \n"
     ]
    }
   ],
   "source": [
    "# translate if english\n",
    "import json\n",
    "from langdetect import detect\n",
    "import progressbar\n",
    "import translators as ts\n",
    "\n",
    "with open('data/case_folded.json') as case_folded_json:\n",
    "  abstracts = json.load(case_folded_json)\n",
    "\n",
    "bar = progress_bar().start()\n",
    "\n",
    "for i, abstract in enumerate(abstracts):\n",
    "  bar.update(i + 1)\n",
    "  detector = detect(abstract['abstract'])\n",
    "  if detector == 'en':\n",
    "    translation = ts.google(abstract['abstract'], from_language='en', to_language='id')\n",
    "    abstracts[i]['abstract'] = translation\n",
    "\n",
    "\n",
    "with open('data/translated.json', 'w') as outfile:\n",
    "  outfile.write(json.dumps(abstracts, sort_keys=True, indent=4))\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " [Elapsed Time: 0:00:00] [00000000000000000000000000000000000] (Time: 0:00:00) \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case folding done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# case folding again\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import sys\n",
    "import concurrent.futures\n",
    "import progressbar\n",
    "\n",
    "\n",
    "processed = []\n",
    "count = 0\n",
    "with open('data/translated.json') as abstracts_json:\n",
    "  abstracts = json.load(abstracts_json)\n",
    "\n",
    "bar = progress_bar().start()\n",
    "\n",
    "for i, abstract in enumerate(abstracts):\n",
    "  bar.update(i + 1)\n",
    "  answer = re.sub('[^a-z]+', ' ', abstract['abstract'].casefold())\n",
    "  abstracts[i]['abstract'] = answer\n",
    "\n",
    "with open('data/case_folded.json', 'w') as outfile:\n",
    "\toutfile.write(json.dumps(abstracts, sort_keys=True, indent=4))\n",
    "\n",
    "bar.finish()\n",
    "print('Case folding done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " [Elapsed Time: 0:00:41] [00000000000000000000000000000000000] (Time: 0:00:41) \n"
     ]
    }
   ],
   "source": [
    "# stemming\n",
    "import json\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import progressbar\n",
    "\n",
    "with open('data/case_folded.json') as case_folded_json:\n",
    "  abstracts = json.load(case_folded_json)\n",
    "\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "\n",
    "bar = progress_bar()\n",
    "bar.start()\n",
    "\n",
    "for i, abstract in enumerate(abstracts):\n",
    "  bar.update(i + 1)\n",
    "  stemmed = stemmer.stem(abstract['abstract'])\n",
    "  abstracts[i]['abstract'] = stemmed\n",
    "\n",
    "\n",
    "with open('data/stemmed_abstracts.json', 'w') as outfile:\n",
    "  outfile.write(json.dumps(abstracts, sort_keys=True, indent=4))\n",
    "\n",
    "bar.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95334295d287576637839bb6c89b1e9ed45a51d991237be8e658a0ed30ccbece"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
